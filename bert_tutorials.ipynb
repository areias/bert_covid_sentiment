{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_tutorials.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyM+Y/EzQGaG5AsQMnYqkSvy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "766ff190835644fc9dd4fc6290f822b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2f5eb8c605fb4704900d7890568dae38",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ee0158b8885c4d78b76a41f1c18ee847",
              "IPY_MODEL_62231e1486ba41258eda21530a8022ce",
              "IPY_MODEL_9e8a50f55c21407cb5b9d7a719fa0282"
            ]
          }
        },
        "2f5eb8c605fb4704900d7890568dae38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ee0158b8885c4d78b76a41f1c18ee847": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_557b905b882640ffb7641dd222c8e245",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0fc39b0ff546404d94dd814ee780f02a"
          }
        },
        "62231e1486ba41258eda21530a8022ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_75ac83c505ef4e0e906caaad542f8558",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 62,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 62,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cebeb3eaeffe47aebac9342d9537c882"
          }
        },
        "9e8a50f55c21407cb5b9d7a719fa0282": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_65cf1e9f0fcd4d078f7c6b6efc18a95d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 62.0/62.0 [00:00&lt;00:00, 1.85kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5f945203e6cc4ac0b49e8bc42df1cb1e"
          }
        },
        "557b905b882640ffb7641dd222c8e245": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0fc39b0ff546404d94dd814ee780f02a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "75ac83c505ef4e0e906caaad542f8558": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cebeb3eaeffe47aebac9342d9537c882": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "65cf1e9f0fcd4d078f7c6b6efc18a95d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5f945203e6cc4ac0b49e8bc42df1cb1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f7f21177566f4843a537b35fcb9a6262": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_779e227c04b34497a3b8d07545bbdf49",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4ed1096c4a734168a11dd7b376512812",
              "IPY_MODEL_8f63791e54cf42b38469c8cfdf6240c6",
              "IPY_MODEL_fa125b59b35544ec9ea726bba63ce19d"
            ]
          }
        },
        "779e227c04b34497a3b8d07545bbdf49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4ed1096c4a734168a11dd7b376512812": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2f331367eb3b470a988cff2e1eb2d915",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e2529816d28f4b71891ee2ead46a371b"
          }
        },
        "8f63791e54cf42b38469c8cfdf6240c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8a76f48ad2e4432dbf51e9f1eb2857a7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 421,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 421,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c829a367e1c4424da55a1056d1504cd7"
          }
        },
        "fa125b59b35544ec9ea726bba63ce19d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5c506c889bca452aaa722cb8cf0af3c0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 421/421 [00:00&lt;00:00, 12.0kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4de390814a4042cda5a4e5cf54d373a1"
          }
        },
        "2f331367eb3b470a988cff2e1eb2d915": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e2529816d28f4b71891ee2ead46a371b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8a76f48ad2e4432dbf51e9f1eb2857a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c829a367e1c4424da55a1056d1504cd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5c506c889bca452aaa722cb8cf0af3c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4de390814a4042cda5a4e5cf54d373a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4ac7fea6317843c0b087959ac9421858": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8fc21e7113714ba19a424f8ec412b228",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1457400ef12647d2b30b0a69a6db0c5e",
              "IPY_MODEL_ac9e70c0c8ed467796925581f3596319",
              "IPY_MODEL_d9a0a1fffde84c7ba2508ce854679556"
            ]
          }
        },
        "8fc21e7113714ba19a424f8ec412b228": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1457400ef12647d2b30b0a69a6db0c5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1e32c52837824dcd9918e48158babd6d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4e5bad03b79143f28a2924a6e8256af6"
          }
        },
        "ac9e70c0c8ed467796925581f3596319": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_557fa130ac0241beaf29dd3bee693ccf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6039f76fd6284cc180749d2a9a05956c"
          }
        },
        "d9a0a1fffde84c7ba2508ce854679556": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_218adeb692f74d5ea05a0d1c5300f117",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 226k/226k [00:00&lt;00:00, 905kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7cebd0245bf14472bd825c4f7804aa71"
          }
        },
        "1e32c52837824dcd9918e48158babd6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4e5bad03b79143f28a2924a6e8256af6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "557fa130ac0241beaf29dd3bee693ccf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6039f76fd6284cc180749d2a9a05956c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "218adeb692f74d5ea05a0d1c5300f117": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7cebd0245bf14472bd825c4f7804aa71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2c43e16ef7a94cf0aa6636e830033730": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_acd6f5e6af4742fe873cb7dc8c330802",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1679058352d34a3f81a27cdcf15b04fb",
              "IPY_MODEL_9e16fb4a1b114a569adf3ec800a3c5ee",
              "IPY_MODEL_ac43e257560a4008b17c7cc387f7bc0a"
            ]
          }
        },
        "acd6f5e6af4742fe873cb7dc8c330802": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1679058352d34a3f81a27cdcf15b04fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0d8ff8cb9a674e9c8a33879442653cfd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_104c176ee6b441b1a3d5908fe07f6376"
          }
        },
        "9e16fb4a1b114a569adf3ec800a3c5ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ba9542d9ad2b4df595b846e2be96d3c9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 112,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 112,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4fab76c85b544f4bb488e9b4d4628826"
          }
        },
        "ac43e257560a4008b17c7cc387f7bc0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e0a299537e16410f97592e7300abd923",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 112/112 [00:00&lt;00:00, 3.08kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2d0eef7c2a1b4cf2b4d22f8f7bdc23aa"
          }
        },
        "0d8ff8cb9a674e9c8a33879442653cfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "104c176ee6b441b1a3d5908fe07f6376": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ba9542d9ad2b4df595b846e2be96d3c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4fab76c85b544f4bb488e9b4d4628826": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e0a299537e16410f97592e7300abd923": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2d0eef7c2a1b4cf2b4d22f8f7bdc23aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/areias/bert_covid_sentiment/blob/main/bert_tutorials.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bNzcqBKwX5S",
        "outputId": "3804244e-480a-427f-91b4-d5812abcaef6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65oksFt0urfB"
      },
      "source": [
        "https://www.tensorflow.org/text/tutorials/fine_tune_bert\n",
        "\n",
        "https://skimai.com/fine-tuning-bert-for-sentiment-analysis/\n",
        "\n",
        "http://mccormickml.com/2019/07/22/BERT-fine-tuning/\n",
        "\n",
        "https://www.thepythoncode.com/article/finetuning-bert-using-huggingface-transformers-python\n",
        "\n",
        "https://colab.research.google.com/github/digitalepidemiologylab/covid-twitter-bert/blob/master/CT_BERT_Huggingface_(GPU_training).ipynb\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6Me4R7VvWU6"
      },
      "source": [
        "## http://mccormickml.com/2019/07/22/BERT-fine-tuning/ 22 Jul 2019, Revised on 3/20/20"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsa9GKKdu_Mg",
        "outputId": "66bd9dd3-a181-4735-ea4a-d2ae045b3036"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPLfMB-rvUZZ",
        "outputId": "980d1424-77e5-4e7b-f373-8d71a3d3a4eb"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNLxGXx8vpEo",
        "outputId": "72dc04e7-6032-45b4-ec19-5d80e152d4b7"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 7.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 56.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.1.2-py3-none-any.whl (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 7.3 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 60.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 40.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.1.2 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.12.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaqM05qpv0eY"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"drive/MyDrive/covid-twitter-bert/data/finetune/originals/crowdbreaks/train.tsv\", delimiter='\\t', header=0, names=['id', 'label', 'sentence'])\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwFCHE7cTp0C",
        "outputId": "b73bb581-fc84-4833-a8c2-a2982521d494"
      },
      "source": [
        "df['label'].value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 0    686\n",
              "-1    678\n",
              " 1    677\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIiNk_AiTwQx"
      },
      "source": [
        "df.loc[df['label']==-1,'label']=2"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rm7WtcvQT7Cy",
        "outputId": "06c156af-34e3-4d78-f6ab-d007f12484fb"
      },
      "source": [
        "df['label'].value_counts()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    686\n",
              "2    678\n",
              "1    677\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "VjKLan4hxNsx",
        "outputId": "e9a96755-09f7-450f-b918-4b3cd6234328"
      },
      "source": [
        "df.sample(10)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>879</th>\n",
              "      <td>435638533626540032</td>\n",
              "      <td>1</td>\n",
              "      <td>how many kids aren't getting vaccinated? http:...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>991</th>\n",
              "      <td>394477949019505024</td>\n",
              "      <td>1</td>\n",
              "      <td>@ChilledChaos I have Autism and yet I hardly e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1120</th>\n",
              "      <td>440543774817923008</td>\n",
              "      <td>1</td>\n",
              "      <td>Baby's doctor appointment he's got some vaccin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>510808840737419008</td>\n",
              "      <td>1</td>\n",
              "      <td>Attend Health&amp;amp;Safety mtg discussion on HPV...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>834</th>\n",
              "      <td>562694415115096000</td>\n",
              "      <td>0</td>\n",
              "      <td>FFS --&amp;gt;  RT @thinkprogress: Congressman: Me...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>108227844164944000</td>\n",
              "      <td>0</td>\n",
              "      <td>Listening to Pierre Robert on MMR while eating...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>689</th>\n",
              "      <td>468869706292945024</td>\n",
              "      <td>1</td>\n",
              "      <td>\"@HuffingtonPost: 300 million children could b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1127</th>\n",
              "      <td>467011773736825024</td>\n",
              "      <td>1</td>\n",
              "      <td>\"@TeamMorgan2014: Woman's cancer wiped out by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1016</th>\n",
              "      <td>247112733944860992</td>\n",
              "      <td>0</td>\n",
              "      <td>Mmr go gett em</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>831</th>\n",
              "      <td>509696511559864000</td>\n",
              "      <td>1</td>\n",
              "      <td>The Case for Vaccinating Your Kids, in One Ala...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      id  ...                                           sentence\n",
              "879   435638533626540032  ...  how many kids aren't getting vaccinated? http:...\n",
              "991   394477949019505024  ...  @ChilledChaos I have Autism and yet I hardly e...\n",
              "1120  440543774817923008  ...  Baby's doctor appointment he's got some vaccin...\n",
              "997   510808840737419008  ...  Attend Health&amp;Safety mtg discussion on HPV...\n",
              "834   562694415115096000  ...  FFS --&gt;  RT @thinkprogress: Congressman: Me...\n",
              "1997  108227844164944000  ...  Listening to Pierre Robert on MMR while eating...\n",
              "689   468869706292945024  ...  \"@HuffingtonPost: 300 million children could b...\n",
              "1127  467011773736825024  ...  \"@TeamMorgan2014: Woman's cancer wiped out by ...\n",
              "1016  247112733944860992  ...                                     Mmr go gett em\n",
              "831   509696511559864000  ...  The Case for Vaccinating Your Kids, in One Ala...\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xWkElDJy8Dc"
      },
      "source": [
        "## Pre-processing Tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzKmqk1py5GD"
      },
      "source": [
        "import sys\n",
        "sys.path.append('drive/MyDrive/covid-twitter-bert')\n",
        "sys.path.append('drive/MyDrive/covid-twitter-bert/tensorflow_models')\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bT0n2mAwzxi1",
        "outputId": "ea08d366-4a4c-4e23-b54a-1e480ea5cdf2"
      },
      "source": [
        "!pip install emoji"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emoji\n",
            "  Downloading emoji-1.6.1.tar.gz (170 kB)\n",
            "\u001b[?25l\r\u001b[K     |██                              | 10 kB 31.0 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 20 kB 27.8 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 30 kB 19.2 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 40 kB 16.8 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 51 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 61 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 71 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 81 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 92 kB 10.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 102 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 112 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 122 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 133 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 143 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 153 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 163 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 170 kB 8.0 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.6.1-py3-none-any.whl size=169314 sha256=2526d39968094a824a6717f6e6b2dd82841a231a4d95bdc440dedf60ddfc7e80\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/5f/d3/03d313ddb3c2a1a427bb4690f1621eea60fe6f2a30cc95940f\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-1.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRihfV5_z3lu",
        "outputId": "b68b3893-4683-4e81-bab0-bedeb05476d2"
      },
      "source": [
        "!pip install unidecode"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.2-py3-none-any.whl (235 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▍                              | 10 kB 26.6 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 20 kB 31.9 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 30 kB 20.0 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 40 kB 17.2 MB/s eta 0:00:01\r\u001b[K     |███████                         | 51 kB 10.5 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 61 kB 10.4 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 71 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 81 kB 10.5 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 92 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 102 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 112 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 122 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 133 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 143 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 153 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 163 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 174 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 184 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 194 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 204 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 215 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 225 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 235 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 235 kB 9.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAHi3mt-z-I_",
        "outputId": "475d77ce-542f-4859-c5d5-81b14b9f847a"
      },
      "source": [
        "!pip install spacy==3"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting spacy==3\n",
            "  Downloading spacy-3.0.0-cp37-cp37m-manylinux2014_x86_64.whl (12.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.7 MB 7.8 MB/s \n",
            "\u001b[?25hCollecting pathy\n",
            "  Downloading pathy-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3) (4.62.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==3) (2.0.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3) (2.23.0)\n",
            "Collecting catalogue<2.1.0,>=2.0.1\n",
            "  Downloading catalogue-2.0.6-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3) (1.0.6)\n",
            "Collecting thinc<8.1.0,>=8.0.0\n",
            "  Downloading thinc-8.0.13-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (628 kB)\n",
            "\u001b[K     |████████████████████████████████| 628 kB 50.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy==3) (3.10.0.2)\n",
            "Collecting srsly<3.0.0,>=2.4.0\n",
            "  Downloading srsly-2.4.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (451 kB)\n",
            "\u001b[K     |████████████████████████████████| 451 kB 49.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy==3) (2.11.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3) (1.19.5)\n",
            "Collecting pydantic<1.8.0,>=1.7.1\n",
            "  Downloading pydantic-1.7.4-cp37-cp37m-manylinux2014_x86_64.whl (9.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.1 MB 51.0 MB/s \n",
            "\u001b[?25hCollecting typer<0.4.0,>=0.3.0\n",
            "  Downloading typer-0.3.2-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy==3) (57.4.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3) (0.4.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from spacy==3) (4.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3) (21.3)\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.0\n",
            "  Downloading spacy_legacy-3.0.8-py2.py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==3) (3.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy==3) (0.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.1->spacy==3) (3.6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy==3) (3.0.6)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3) (2021.10.8)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy==3) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy==3) (2.0.1)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy->spacy==3) (5.2.1)\n",
            "Installing collected packages: catalogue, typer, srsly, pydantic, thinc, spacy-legacy, pathy, spacy\n",
            "  Attempting uninstall: catalogue\n",
            "    Found existing installation: catalogue 1.0.0\n",
            "    Uninstalling catalogue-1.0.0:\n",
            "      Successfully uninstalled catalogue-1.0.0\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 1.0.5\n",
            "    Uninstalling srsly-1.0.5:\n",
            "      Successfully uninstalled srsly-1.0.5\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "Successfully installed catalogue-2.0.6 pathy-0.6.1 pydantic-1.7.4 spacy-3.0.0 spacy-legacy-3.0.8 srsly-2.4.2 thinc-8.0.13 typer-0.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtE1WcY6znBL"
      },
      "source": [
        "from utils.preprocess import preprocess_bert"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ck8SbYD0Qqz",
        "outputId": "a62b7741-5d66-4838-9848-407726e2c5d5"
      },
      "source": [
        "from collections import namedtuple\n",
        "arguments = namedtuple('arguments', ['run_prefix','finetune_datasets','model_class',\n",
        "                                     'max_seq_length', 'asciify_emojis','username_filler',\n",
        "                                    'url_filler', 'replace_multiple_usernames','replace_multiple_urls',\n",
        "                                      'remove_unicode_symbols','replace_usernames','replace_urls',\n",
        "                                     'standardize_punctuation','remove_accented_characters'])\n",
        "\n",
        "args = arguments(\"test_run\",[\"crowdbreaks\"],\"covid-twitter-bert-2\",\n",
        "                 96, True, \"twitteruser\", \n",
        "                 \"twitterurl\", True,True,\n",
        "                 True, True, True,\n",
        "                 True, True)\n",
        "args\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "arguments(run_prefix='test_run', finetune_datasets=['crowdbreaks'], model_class='covid-twitter-bert-2', max_seq_length=96, asciify_emojis=True, username_filler='twitteruser', url_filler='twitterurl', replace_multiple_usernames=True, replace_multiple_urls=True, remove_unicode_symbols=True, replace_usernames=True, replace_urls=True, standardize_punctuation=True, remove_accented_characters=True)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvgKvfbM1w8O"
      },
      "source": [
        "df['sentence'] = df['sentence'].apply(lambda x: preprocess_bert(x,args,do_lower_case=True))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lcl3ByvV1Pae"
      },
      "source": [
        "#Let’s extract the sentences and labels of our training set as numpy ndarrays.\n",
        "\n",
        "# Get the lists of sentences and their labels.\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9y7BzNKf1m87",
        "outputId": "42210173-9819-4298-f841-13ea30ad1882"
      },
      "source": [
        "sentences[0]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'arizona classrooms vulnerable to measles outbreak: the arizona department of health services looked at herd... twitterurl'"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHucOLrN2IMW",
        "outputId": "6bd0b580-f5cb-428f-966f-7559e89fc70b"
      },
      "source": [
        "type(labels[0])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.int64"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmdq4f38xt8C"
      },
      "source": [
        "## BERT Tokenizer\n",
        "\n",
        "To feed our text to BERT, it must be split into tokens, and then these tokens must be mapped to their index in the tokenizer vocabulary.\n",
        "\n",
        "The tokenization must be performed by the tokenizer included with BERT–the below cell will download this for us. We’ll be using the “uncased” version here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162,
          "referenced_widgets": [
            "766ff190835644fc9dd4fc6290f822b9",
            "2f5eb8c605fb4704900d7890568dae38",
            "ee0158b8885c4d78b76a41f1c18ee847",
            "62231e1486ba41258eda21530a8022ce",
            "9e8a50f55c21407cb5b9d7a719fa0282",
            "557b905b882640ffb7641dd222c8e245",
            "0fc39b0ff546404d94dd814ee780f02a",
            "75ac83c505ef4e0e906caaad542f8558",
            "cebeb3eaeffe47aebac9342d9537c882",
            "65cf1e9f0fcd4d078f7c6b6efc18a95d",
            "5f945203e6cc4ac0b49e8bc42df1cb1e",
            "f7f21177566f4843a537b35fcb9a6262",
            "779e227c04b34497a3b8d07545bbdf49",
            "4ed1096c4a734168a11dd7b376512812",
            "8f63791e54cf42b38469c8cfdf6240c6",
            "fa125b59b35544ec9ea726bba63ce19d",
            "2f331367eb3b470a988cff2e1eb2d915",
            "e2529816d28f4b71891ee2ead46a371b",
            "8a76f48ad2e4432dbf51e9f1eb2857a7",
            "c829a367e1c4424da55a1056d1504cd7",
            "5c506c889bca452aaa722cb8cf0af3c0",
            "4de390814a4042cda5a4e5cf54d373a1",
            "4ac7fea6317843c0b087959ac9421858",
            "8fc21e7113714ba19a424f8ec412b228",
            "1457400ef12647d2b30b0a69a6db0c5e",
            "ac9e70c0c8ed467796925581f3596319",
            "d9a0a1fffde84c7ba2508ce854679556",
            "1e32c52837824dcd9918e48158babd6d",
            "4e5bad03b79143f28a2924a6e8256af6",
            "557fa130ac0241beaf29dd3bee693ccf",
            "6039f76fd6284cc180749d2a9a05956c",
            "218adeb692f74d5ea05a0d1c5300f117",
            "7cebd0245bf14472bd825c4f7804aa71",
            "2c43e16ef7a94cf0aa6636e830033730",
            "acd6f5e6af4742fe873cb7dc8c330802",
            "1679058352d34a3f81a27cdcf15b04fb",
            "9e16fb4a1b114a569adf3ec800a3c5ee",
            "ac43e257560a4008b17c7cc387f7bc0a",
            "0d8ff8cb9a674e9c8a33879442653cfd",
            "104c176ee6b441b1a3d5908fe07f6376",
            "ba9542d9ad2b4df595b846e2be96d3c9",
            "4fab76c85b544f4bb488e9b4d4628826",
            "e0a299537e16410f97592e7300abd923",
            "2d0eef7c2a1b4cf2b4d22f8f7bdc23aa"
          ]
        },
        "id": "d2czgaHdxpOI",
        "outputId": "589ec08e-ce36-4784-ee49-9dba69cdda05"
      },
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "model_name = 'digitalepidemiologylab/covid-twitter-bert-v2'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, do_lower_case=True)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "766ff190835644fc9dd4fc6290f822b9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/62.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f7f21177566f4843a537b35fcb9a6262",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/421 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4ac7fea6317843c0b087959ac9421858",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c43e16ef7a94cf0aa6636e830033730",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MroUDOty2Hv",
        "outputId": "98954cf0-7d7c-400d-d968-ed9b798e83b6"
      },
      "source": [
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Original:  arizona classrooms vulnerable to measles outbreak: the arizona department of health services looked at herd... twitterurl\n",
            "Tokenized:  ['arizona', 'classrooms', 'vulnerable', 'to', 'me', '##as', '##les', 'outbreak', ':', 'the', 'arizona', 'department', 'of', 'health', 'services', 'looked', 'at', 'herd', '.', '.', '.', 'twitter', '##ur', '##l']\n",
            "Token IDs:  [5334, 12463, 8211, 2000, 2033, 3022, 4244, 8293, 1024, 1996, 5334, 2533, 1997, 2740, 2578, 2246, 2012, 14906, 1012, 1012, 1012, 10474, 3126, 2140]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsI_tXGz3YuJ"
      },
      "source": [
        "The above code left out a few required formatting steps:\n",
        "* Add special tokens to the start and end of each sentence.\n",
        "* Pad & truncate all sentences to a single constant length.\n",
        "* Explicitly differentiate real tokens from padding tokens with the “attention mask”.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dl6Anl_3hMH",
        "outputId": "2aa8f567-46f0-4685-a03f-d31c8f966404"
      },
      "source": [
        "tokenizer.encode_plus(sentences[0],                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 96,           # Pad & truncate all sentences.\n",
        "                        padding= True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                      truncation=True,\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  101,  5334, 12463,  8211,  2000,  2033,  3022,  4244,  8293,  1024,\n",
              "          1996,  5334,  2533,  1997,  2740,  2578,  2246,  2012, 14906,  1012,\n",
              "          1012,  1012, 10474,  3126,  2140,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9LhhqFE35PU",
        "outputId": "5b6a9bc9-e559-4654-e660-572c2acce3ac"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 96,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt', \n",
        "                        truncation=True    # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8GiVyYP4niK"
      },
      "source": [
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLIpto5h4t0C"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "train_dataset = TensorDataset(input_ids, attention_masks, labels)\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXJX6WYy6OCg"
      },
      "source": [
        "# do all above for validation dataset\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df2 = pd.read_csv(\"drive/MyDrive/covid-twitter-bert/data/finetune/originals/crowdbreaks/dev.tsv\", delimiter='\\t', header=0, names=['id', 'label', 'sentence'])\n",
        "df2.loc[df2['label']==-1,'label']=2\n",
        "\n",
        "# pre-processes special characters\n",
        "df2['sentence'] = df2['sentence'].apply(lambda x: preprocess_bert(x,args,do_lower_case=True))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "lKzOaXFp6rf-",
        "outputId": "19cc14d3-df8a-4c30-b041-1ad306065051"
      },
      "source": [
        "df2.head()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>522873565969150016</td>\n",
              "      <td>1</td>\n",
              "      <td>flu shot, got. #vaccinated #flushot #diseasepr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>371691166674451968</td>\n",
              "      <td>1</td>\n",
              "      <td>idiots. twitteruser : texas measles outbreak t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>70612980194226200</td>\n",
              "      <td>1</td>\n",
              "      <td>at the vet my baby is getting a vaccination aw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>562391001118289984</td>\n",
              "      <td>2</td>\n",
              "      <td>today in journalism my professor said friend's...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>239016379901177984</td>\n",
              "      <td>2</td>\n",
              "      <td>twitteruser and children getting vaccinated st...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   id  label                                           sentence\n",
              "0  522873565969150016      1  flu shot, got. #vaccinated #flushot #diseasepr...\n",
              "1  371691166674451968      1  idiots. twitteruser : texas measles outbreak t...\n",
              "2   70612980194226200      1  at the vet my baby is getting a vaccination aw...\n",
              "3  562391001118289984      2  today in journalism my professor said friend's...\n",
              "4  239016379901177984      2  twitteruser and children getting vaccinated st..."
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KudewtW-6sdR"
      },
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "test_sentences = df2.sentence.values\n",
        "test_labels = df2.label.values"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9D2C0d-697A",
        "outputId": "1e8e87c5-e545-4c9b-e8b4-cf1a701c815c"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "test_input_ids = []\n",
        "test_attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in test_sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 96,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    test_input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    test_attention_masks.append(encoded_dict['attention_mask'])\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jO8BiGSJSq4W",
        "outputId": "a8738018-2e27-4326-88c1-ede8008eba2e"
      },
      "source": [
        "test_labels[0].item()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMOeOBCN7PaM"
      },
      "source": [
        "# Convert the lists into tensors.\n",
        "test_input_ids = torch.cat(test_input_ids, dim=0)\n",
        "test_attention_masks = torch.cat(test_attention_masks, dim=0)\n",
        "test_labels = torch.tensor(test_labels)\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9losOzcp7atF"
      },
      "source": [
        "val_dataset = TensorDataset(test_input_ids, test_attention_masks, test_labels)\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrtyu9wV7pLD"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 8\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxBpU1Bs71gB"
      },
      "source": [
        "## Fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmHtDn4X7zV5",
        "outputId": "ffec41ac-fae4-493d-a480-907fd7db3103"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(  \n",
        "    'digitalepidemiologylab/covid-twitter-bert-v2', # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 3, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        "     return_dict=False)\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at digitalepidemiologylab/covid-twitter-bert-v2 were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at digitalepidemiologylab/covid-twitter-bert-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 1024)\n",
              "      (token_type_embeddings): Embedding(2, 1024)\n",
              "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (12): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (13): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (14): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (15): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (16): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (17): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (18): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (19): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (20): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (21): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (22): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (23): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=1024, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaXJyp7V8Q3q"
      },
      "source": [
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBvN8r5Q8U8i"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqUBzeqX8dmY"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XO7427a8nay"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dtoxpP0IP9B"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfFm5LZq8q9o",
        "outputId": "55dba145-df66-492e-a2c0-c03e34f51e38"
      },
      "source": [
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        loss, logits = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            (loss, logits) = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    256.    Elapsed: 0:00:13.\n",
            "  Batch    80  of    256.    Elapsed: 0:00:25.\n",
            "  Batch   120  of    256.    Elapsed: 0:00:38.\n",
            "  Batch   160  of    256.    Elapsed: 0:00:50.\n",
            "  Batch   200  of    256.    Elapsed: 0:01:03.\n",
            "  Batch   240  of    256.    Elapsed: 0:01:15.\n",
            "\n",
            "  Average training loss: 0.57\n",
            "  Training epcoh took: 0:01:20\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.71\n",
            "  Validation took: 0:00:07\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    256.    Elapsed: 0:00:13.\n",
            "  Batch    80  of    256.    Elapsed: 0:00:25.\n",
            "  Batch   120  of    256.    Elapsed: 0:00:38.\n",
            "  Batch   160  of    256.    Elapsed: 0:00:50.\n",
            "  Batch   200  of    256.    Elapsed: 0:01:03.\n",
            "  Batch   240  of    256.    Elapsed: 0:01:15.\n",
            "\n",
            "  Average training loss: 0.46\n",
            "  Training epcoh took: 0:01:20\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.72\n",
            "  Validation took: 0:00:07\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    256.    Elapsed: 0:00:13.\n",
            "  Batch    80  of    256.    Elapsed: 0:00:25.\n",
            "  Batch   120  of    256.    Elapsed: 0:00:38.\n",
            "  Batch   160  of    256.    Elapsed: 0:00:50.\n",
            "  Batch   200  of    256.    Elapsed: 0:01:03.\n",
            "  Batch   240  of    256.    Elapsed: 0:01:15.\n",
            "\n",
            "  Average training loss: 0.32\n",
            "  Training epcoh took: 0:01:20\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.85\n",
            "  Validation took: 0:00:07\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    256.    Elapsed: 0:00:13.\n",
            "  Batch    80  of    256.    Elapsed: 0:00:25.\n",
            "  Batch   120  of    256.    Elapsed: 0:00:38.\n",
            "  Batch   160  of    256.    Elapsed: 0:00:50.\n",
            "  Batch   200  of    256.    Elapsed: 0:01:03.\n",
            "  Batch   240  of    256.    Elapsed: 0:01:15.\n",
            "\n",
            "  Average training loss: 0.23\n",
            "  Training epcoh took: 0:01:20\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.79\n",
            "  Validation Loss: 0.86\n",
            "  Validation took: 0:00:07\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:05:53 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "qDejhFUhR8I5",
        "outputId": "77b6ffc3-d4df-4a8d-b4e7-49fe9a8ae081"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.57</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.78</td>\n",
              "      <td>0:01:20</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.46</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.78</td>\n",
              "      <td>0:01:20</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.32</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0.78</td>\n",
              "      <td>0:01:20</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.23</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0:01:20</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.57         0.71           0.78       0:01:20         0:00:07\n",
              "2               0.46         0.72           0.78       0:01:20         0:00:07\n",
              "3               0.32         0.85           0.78       0:01:20         0:00:07\n",
              "4               0.23         0.86           0.79       0:01:20         0:00:07"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "YMeY1Yq_V2Bq",
        "outputId": "77ddd3c2-ae8a-4a84-d578-38c74323f67a"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5u0KsRVkV14B"
      },
      "source": [
        "## Performance on test set\n",
        "df3 = pd.read_csv(\"drive/MyDrive/covid-twitter-bert/data/finetune/originals/crowdbreaks/test.tsv\", delimiter='\\t', header=0, names=['id', 'label', 'sentence'])\n",
        "df3.loc[df3['label']==-1,'label']=2\n",
        "# pre-processes special characters\n",
        "df3['sentence'] = df3['sentence'].apply(lambda x: preprocess_bert(x,args,do_lower_case=True))"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4XJRd9EWVK4",
        "outputId": "feae9214-dd51-4573-d5a0-5ca7a1839401"
      },
      "source": [
        "df3['label'].value_counts()"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    237\n",
              "1    225\n",
              "0    219\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2cumvgZWXrM",
        "outputId": "74125ee8-f712-4e22-f399-bc8b43a4a6c3"
      },
      "source": [
        "test_sentences = df3.sentence.values\n",
        "test_labels = df3.label.values\n",
        "\n",
        "test_input_ids = []\n",
        "test_attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in test_sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 96,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    test_input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    test_attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "batch_size=8\n",
        "\n",
        "input_ids = torch.cat(test_input_ids, dim=0)\n",
        "attention_masks = torch.cat(test_attention_masks, dim=0)\n",
        "labels = torch.tensor(test_labels)\n",
        "\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igvfT1qhceAi"
      },
      "source": [
        "## Prediction on test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaa8VSUIdlQC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpW1yPXyXt3v",
        "outputId": "a6473ade-d0cb-4ab8-8179-6f4b704c982b"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions.\n",
        "      result = model(b_input_ids, \n",
        "                     token_type_ids=None, \n",
        "                     attention_mask=b_input_mask,\n",
        "                     return_dict=True)\n",
        "\n",
        "  logits = result.logits\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for 681 test sentences...\n",
            "    DONE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjA9VyOTX1g_",
        "outputId": "08ca1341-0def-4cb2-e745-85fafcb0614a"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating F1 Score. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "  \n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  \n",
        "  # Calculate and store the coef for this batch.  \n",
        "  f1 = f1_score(true_labels[i], pred_labels_i, average=None)                \n",
        "  f1_set.append(f1)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating F1 Score. Coef. for each batch...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8tyGdHvY_zR",
        "outputId": "4c4cf969-3397-439a-ebb7-504faad46e78"
      },
      "source": [
        "len(f1_set)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "86"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8puCnvCZCJ0",
        "outputId": "7113672e-4cab-48ec-9aa4-34c2e26e104d"
      },
      "source": [
        "f1_set"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0.85714286, 0.5       , 0.8       ]),\n",
              " array([0.        , 0.85714286, 0.66666667]),\n",
              " array([1.        , 0.66666667, 0.85714286]),\n",
              " array([0.66666667, 0.66666667, 0.5       ]),\n",
              " array([0.4, 0.5, 0. ]),\n",
              " array([0.57142857, 0.66666667]),\n",
              " array([0.5       , 0.66666667, 1.        ]),\n",
              " array([1., 1., 1.]),\n",
              " array([0. , 0.6, 0. ]),\n",
              " array([0.85714286, 0.88888889]),\n",
              " array([0.57142857, 0.5       , 0.4       ]),\n",
              " array([1.        , 0.90909091, 0.        ]),\n",
              " array([1.        , 0.8       , 0.88888889]),\n",
              " array([0.5 , 0.75, 0.5 ]),\n",
              " array([0.75, 0.4 , 0.  ]),\n",
              " array([0.66666667, 0.5       , 0.66666667]),\n",
              " array([1. , 0.8, 0.8]),\n",
              " array([0.        , 0.66666667, 0.83333333]),\n",
              " array([1.        , 0.8       , 0.66666667]),\n",
              " array([0.66666667, 0.33333333, 0.57142857]),\n",
              " array([0.5       , 0.85714286, 0.8       ]),\n",
              " array([0.        , 0.85714286, 0.85714286]),\n",
              " array([0.85714286, 0.8       , 1.        ]),\n",
              " array([0.8       , 0.85714286, 1.        ]),\n",
              " array([0.90909091, 0.        , 0.66666667]),\n",
              " array([1.        , 0.8       , 0.85714286]),\n",
              " array([0.75      , 0.66666667, 0.        ]),\n",
              " array([0.8, 0. , 0.8]),\n",
              " array([0.75, 0.  , 0.4 ]),\n",
              " array([0.85714286, 0.5       , 0.8       ]),\n",
              " array([0.8, 1. , 0.8]),\n",
              " array([1., 1., 1.]),\n",
              " array([0.88888889, 1.        , 0.8       ]),\n",
              " array([1.        , 0.66666667, 0.85714286]),\n",
              " array([0.8, 1. , 0.8]),\n",
              " array([0.5, 0. , 0.5]),\n",
              " array([0.4       , 0.75      , 0.66666667]),\n",
              " array([0.75, 0.5 , 0.5 ]),\n",
              " array([0.8       , 0.        , 0.88888889]),\n",
              " array([0.85714286, 0.5       , 0.8       ]),\n",
              " array([0.66666667, 0.5       , 0.66666667]),\n",
              " array([0.75, 0.75]),\n",
              " array([1., 1., 1.]),\n",
              " array([0.        , 0.66666667, 0.33333333]),\n",
              " array([1. , 0.8, 0.8]),\n",
              " array([1. , 0.8, 0.8]),\n",
              " array([0.66666667, 0.92307692]),\n",
              " array([0.        , 0.57142857, 0.85714286]),\n",
              " array([1.        , 0.66666667, 0.85714286]),\n",
              " array([0.66666667, 0.8       , 0.66666667]),\n",
              " array([1.        , 0.        , 0.83333333]),\n",
              " array([1.        , 0.66666667, 0.66666667]),\n",
              " array([1.        , 0.8       , 0.88888889]),\n",
              " array([0.5       , 0.57142857, 0.8       ]),\n",
              " array([0.90909091, 0.8       ]),\n",
              " array([0.90909091, 0.8       ]),\n",
              " array([0.4       , 0.75      , 0.66666667]),\n",
              " array([0.66666667, 0.5       , 0.88888889]),\n",
              " array([0.66666667, 0.8       , 0.66666667]),\n",
              " array([0.85714286, 0.88888889]),\n",
              " array([1., 1., 1.]),\n",
              " array([1. , 0.8, 0.5]),\n",
              " array([0.        , 0.66666667, 0.72727273]),\n",
              " array([0.8, 0.8, 1. ]),\n",
              " array([0.8, 0.8, 1. ]),\n",
              " array([0.66666667, 0.4       , 0.8       ]),\n",
              " array([0.66666667, 1.        , 0.75      ]),\n",
              " array([0.8       , 0.85714286, 1.        ]),\n",
              " array([0.8       , 0.66666667, 1.        ]),\n",
              " array([0.66666667, 1.        , 0.85714286]),\n",
              " array([1., 1., 1.]),\n",
              " array([0.        , 0.88888889, 0.4       ]),\n",
              " array([1., 1., 1.]),\n",
              " array([0.88888889, 1.        , 0.8       ]),\n",
              " array([0.66666667, 0.4       , 0.8       ]),\n",
              " array([0.8       , 0.57142857, 0.5       ]),\n",
              " array([0.66666667, 0.57142857, 0.66666667]),\n",
              " array([1., 1., 1.]),\n",
              " array([1.  , 0.75, 0.5 ]),\n",
              " array([0.        , 0.33333333, 0.66666667]),\n",
              " array([1. , 0.4, 0.4]),\n",
              " array([0.85714286, 0.66666667, 1.        ]),\n",
              " array([0.8       , 1.        , 0.85714286]),\n",
              " array([0.66666667, 0.75      , 0.8       ]),\n",
              " array([0.66666667, 0.75      , 1.        ]),\n",
              " array([1.])]"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQwMcZEzZSx4",
        "outputId": "eaf43a90-c5b2-4a48-8e65-a4c05cdc749e"
      },
      "source": [
        "true_labels[0]"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 1, 1, 0, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wl7wdJYBZV9c",
        "outputId": "67bc2626-82e2-4128-f1b6-2b60e6e337eb"
      },
      "source": [
        "predictions[0]"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 3.6149707, -2.5169702, -2.319315 ],\n",
              "       [ 2.8493059, -1.9107704, -2.3156106],\n",
              "       [ 3.4547439, -2.2807326, -2.3502448],\n",
              "       [-1.0161924, -1.6066909,  3.2713308],\n",
              "       [-1.4951551,  4.14966  , -2.4093778],\n",
              "       [ 0.7124895,  1.0357994, -1.9097619],\n",
              "       [-1.3797809, -2.2380972,  4.3564124],\n",
              "       [-1.6483228, -2.155723 ,  4.359962 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oV6pyByGZcN9"
      },
      "source": [
        "# Combine the results across all batches. \n",
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "# For each sample, pick the label (0 or 1) with the higher score.\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m57dVWbDbn-l"
      },
      "source": [
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fk6QM0hfboz1",
        "outputId": "369e4545-61a7-4a3e-e9ce-89c8a109b451"
      },
      "source": [
        "# Calculate the f1 for each class\n",
        "f1 = f1_score(flat_true_labels, flat_predictions, average=None)\n",
        "\n",
        "print(f1)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.78239609 0.725      0.76109937]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTNxxVdneecV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bYjpHW_cEBh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}