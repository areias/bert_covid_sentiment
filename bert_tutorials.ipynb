{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_tutorials.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOZAPbkMU/tqsA1tZxj/74F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "766ff190835644fc9dd4fc6290f822b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2f5eb8c605fb4704900d7890568dae38",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ee0158b8885c4d78b76a41f1c18ee847",
              "IPY_MODEL_62231e1486ba41258eda21530a8022ce",
              "IPY_MODEL_9e8a50f55c21407cb5b9d7a719fa0282"
            ]
          }
        },
        "2f5eb8c605fb4704900d7890568dae38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ee0158b8885c4d78b76a41f1c18ee847": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_557b905b882640ffb7641dd222c8e245",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0fc39b0ff546404d94dd814ee780f02a"
          }
        },
        "62231e1486ba41258eda21530a8022ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_75ac83c505ef4e0e906caaad542f8558",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 62,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 62,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cebeb3eaeffe47aebac9342d9537c882"
          }
        },
        "9e8a50f55c21407cb5b9d7a719fa0282": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_65cf1e9f0fcd4d078f7c6b6efc18a95d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 62.0/62.0 [00:00&lt;00:00, 1.85kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5f945203e6cc4ac0b49e8bc42df1cb1e"
          }
        },
        "557b905b882640ffb7641dd222c8e245": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0fc39b0ff546404d94dd814ee780f02a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "75ac83c505ef4e0e906caaad542f8558": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cebeb3eaeffe47aebac9342d9537c882": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "65cf1e9f0fcd4d078f7c6b6efc18a95d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5f945203e6cc4ac0b49e8bc42df1cb1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f7f21177566f4843a537b35fcb9a6262": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_779e227c04b34497a3b8d07545bbdf49",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4ed1096c4a734168a11dd7b376512812",
              "IPY_MODEL_8f63791e54cf42b38469c8cfdf6240c6",
              "IPY_MODEL_fa125b59b35544ec9ea726bba63ce19d"
            ]
          }
        },
        "779e227c04b34497a3b8d07545bbdf49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4ed1096c4a734168a11dd7b376512812": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2f331367eb3b470a988cff2e1eb2d915",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e2529816d28f4b71891ee2ead46a371b"
          }
        },
        "8f63791e54cf42b38469c8cfdf6240c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8a76f48ad2e4432dbf51e9f1eb2857a7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 421,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 421,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c829a367e1c4424da55a1056d1504cd7"
          }
        },
        "fa125b59b35544ec9ea726bba63ce19d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5c506c889bca452aaa722cb8cf0af3c0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 421/421 [00:00&lt;00:00, 12.0kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4de390814a4042cda5a4e5cf54d373a1"
          }
        },
        "2f331367eb3b470a988cff2e1eb2d915": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e2529816d28f4b71891ee2ead46a371b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8a76f48ad2e4432dbf51e9f1eb2857a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c829a367e1c4424da55a1056d1504cd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5c506c889bca452aaa722cb8cf0af3c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4de390814a4042cda5a4e5cf54d373a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4ac7fea6317843c0b087959ac9421858": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8fc21e7113714ba19a424f8ec412b228",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1457400ef12647d2b30b0a69a6db0c5e",
              "IPY_MODEL_ac9e70c0c8ed467796925581f3596319",
              "IPY_MODEL_d9a0a1fffde84c7ba2508ce854679556"
            ]
          }
        },
        "8fc21e7113714ba19a424f8ec412b228": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1457400ef12647d2b30b0a69a6db0c5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1e32c52837824dcd9918e48158babd6d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4e5bad03b79143f28a2924a6e8256af6"
          }
        },
        "ac9e70c0c8ed467796925581f3596319": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_557fa130ac0241beaf29dd3bee693ccf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6039f76fd6284cc180749d2a9a05956c"
          }
        },
        "d9a0a1fffde84c7ba2508ce854679556": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_218adeb692f74d5ea05a0d1c5300f117",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 226k/226k [00:00&lt;00:00, 905kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7cebd0245bf14472bd825c4f7804aa71"
          }
        },
        "1e32c52837824dcd9918e48158babd6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4e5bad03b79143f28a2924a6e8256af6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "557fa130ac0241beaf29dd3bee693ccf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6039f76fd6284cc180749d2a9a05956c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "218adeb692f74d5ea05a0d1c5300f117": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7cebd0245bf14472bd825c4f7804aa71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2c43e16ef7a94cf0aa6636e830033730": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_acd6f5e6af4742fe873cb7dc8c330802",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1679058352d34a3f81a27cdcf15b04fb",
              "IPY_MODEL_9e16fb4a1b114a569adf3ec800a3c5ee",
              "IPY_MODEL_ac43e257560a4008b17c7cc387f7bc0a"
            ]
          }
        },
        "acd6f5e6af4742fe873cb7dc8c330802": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1679058352d34a3f81a27cdcf15b04fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0d8ff8cb9a674e9c8a33879442653cfd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_104c176ee6b441b1a3d5908fe07f6376"
          }
        },
        "9e16fb4a1b114a569adf3ec800a3c5ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ba9542d9ad2b4df595b846e2be96d3c9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 112,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 112,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4fab76c85b544f4bb488e9b4d4628826"
          }
        },
        "ac43e257560a4008b17c7cc387f7bc0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e0a299537e16410f97592e7300abd923",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 112/112 [00:00&lt;00:00, 3.08kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2d0eef7c2a1b4cf2b4d22f8f7bdc23aa"
          }
        },
        "0d8ff8cb9a674e9c8a33879442653cfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "104c176ee6b441b1a3d5908fe07f6376": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ba9542d9ad2b4df595b846e2be96d3c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4fab76c85b544f4bb488e9b4d4628826": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e0a299537e16410f97592e7300abd923": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2d0eef7c2a1b4cf2b4d22f8f7bdc23aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/areias/bert_covid_sentiment/blob/main/bert_tutorials.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bNzcqBKwX5S",
        "outputId": "3804244e-480a-427f-91b4-d5812abcaef6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65oksFt0urfB"
      },
      "source": [
        "https://www.tensorflow.org/text/tutorials/fine_tune_bert\n",
        "\n",
        "https://skimai.com/fine-tuning-bert-for-sentiment-analysis/\n",
        "\n",
        "http://mccormickml.com/2019/07/22/BERT-fine-tuning/\n",
        "\n",
        "https://www.thepythoncode.com/article/finetuning-bert-using-huggingface-transformers-python\n",
        "\n",
        "https://colab.research.google.com/github/digitalepidemiologylab/covid-twitter-bert/blob/master/CT_BERT_Huggingface_(GPU_training).ipynb\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6Me4R7VvWU6"
      },
      "source": [
        "## http://mccormickml.com/2019/07/22/BERT-fine-tuning/ 22 Jul 2019, Revised on 3/20/20"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsa9GKKdu_Mg",
        "outputId": "66bd9dd3-a181-4735-ea4a-d2ae045b3036"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPLfMB-rvUZZ",
        "outputId": "980d1424-77e5-4e7b-f373-8d71a3d3a4eb"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNLxGXx8vpEo",
        "outputId": "72dc04e7-6032-45b4-ec19-5d80e152d4b7"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 7.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 56.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.1.2-py3-none-any.whl (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 7.3 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 60.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 40.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.1.2 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.12.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-Mqqci-evqe"
      },
      "source": [
        "## Load train data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uc833ZYCevnK"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaqM05qpv0eY"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"drive/MyDrive/covid-twitter-bert/data/finetune/originals/crowdbreaks/train.tsv\", delimiter='\\t', header=0, names=['id', 'label', 'sentence'])\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwFCHE7cTp0C",
        "outputId": "b73bb581-fc84-4833-a8c2-a2982521d494"
      },
      "source": [
        "df['label'].value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 0    686\n",
              "-1    678\n",
              " 1    677\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIiNk_AiTwQx"
      },
      "source": [
        "df.loc[df['label']==-1,'label']=2"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rm7WtcvQT7Cy",
        "outputId": "06c156af-34e3-4d78-f6ab-d007f12484fb"
      },
      "source": [
        "df['label'].value_counts()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    686\n",
              "2    678\n",
              "1    677\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "VjKLan4hxNsx",
        "outputId": "e9a96755-09f7-450f-b918-4b3cd6234328"
      },
      "source": [
        "df.sample(10)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>879</th>\n",
              "      <td>435638533626540032</td>\n",
              "      <td>1</td>\n",
              "      <td>how many kids aren't getting vaccinated? http:...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>991</th>\n",
              "      <td>394477949019505024</td>\n",
              "      <td>1</td>\n",
              "      <td>@ChilledChaos I have Autism and yet I hardly e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1120</th>\n",
              "      <td>440543774817923008</td>\n",
              "      <td>1</td>\n",
              "      <td>Baby's doctor appointment he's got some vaccin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>510808840737419008</td>\n",
              "      <td>1</td>\n",
              "      <td>Attend Health&amp;amp;Safety mtg discussion on HPV...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>834</th>\n",
              "      <td>562694415115096000</td>\n",
              "      <td>0</td>\n",
              "      <td>FFS --&amp;gt;  RT @thinkprogress: Congressman: Me...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>108227844164944000</td>\n",
              "      <td>0</td>\n",
              "      <td>Listening to Pierre Robert on MMR while eating...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>689</th>\n",
              "      <td>468869706292945024</td>\n",
              "      <td>1</td>\n",
              "      <td>\"@HuffingtonPost: 300 million children could b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1127</th>\n",
              "      <td>467011773736825024</td>\n",
              "      <td>1</td>\n",
              "      <td>\"@TeamMorgan2014: Woman's cancer wiped out by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1016</th>\n",
              "      <td>247112733944860992</td>\n",
              "      <td>0</td>\n",
              "      <td>Mmr go gett em</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>831</th>\n",
              "      <td>509696511559864000</td>\n",
              "      <td>1</td>\n",
              "      <td>The Case for Vaccinating Your Kids, in One Ala...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      id  ...                                           sentence\n",
              "879   435638533626540032  ...  how many kids aren't getting vaccinated? http:...\n",
              "991   394477949019505024  ...  @ChilledChaos I have Autism and yet I hardly e...\n",
              "1120  440543774817923008  ...  Baby's doctor appointment he's got some vaccin...\n",
              "997   510808840737419008  ...  Attend Health&amp;Safety mtg discussion on HPV...\n",
              "834   562694415115096000  ...  FFS --&gt;  RT @thinkprogress: Congressman: Me...\n",
              "1997  108227844164944000  ...  Listening to Pierre Robert on MMR while eating...\n",
              "689   468869706292945024  ...  \"@HuffingtonPost: 300 million children could b...\n",
              "1127  467011773736825024  ...  \"@TeamMorgan2014: Woman's cancer wiped out by ...\n",
              "1016  247112733944860992  ...                                     Mmr go gett em\n",
              "831   509696511559864000  ...  The Case for Vaccinating Your Kids, in One Ala...\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xWkElDJy8Dc"
      },
      "source": [
        "## Pre-processing Tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzKmqk1py5GD"
      },
      "source": [
        "import sys\n",
        "sys.path.append('drive/MyDrive/covid-twitter-bert')\n",
        "sys.path.append('drive/MyDrive/covid-twitter-bert/tensorflow_models')\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bT0n2mAwzxi1",
        "outputId": "ea08d366-4a4c-4e23-b54a-1e480ea5cdf2"
      },
      "source": [
        "!pip install emoji"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emoji\n",
            "  Downloading emoji-1.6.1.tar.gz (170 kB)\n",
            "\u001b[?25l\r\u001b[K     |██                              | 10 kB 31.0 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 20 kB 27.8 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 30 kB 19.2 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 40 kB 16.8 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 51 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 61 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 71 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 81 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 92 kB 10.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 102 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 112 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 122 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 133 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 143 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 153 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 163 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 170 kB 8.0 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.6.1-py3-none-any.whl size=169314 sha256=2526d39968094a824a6717f6e6b2dd82841a231a4d95bdc440dedf60ddfc7e80\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/5f/d3/03d313ddb3c2a1a427bb4690f1621eea60fe6f2a30cc95940f\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-1.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRihfV5_z3lu",
        "outputId": "b68b3893-4683-4e81-bab0-bedeb05476d2"
      },
      "source": [
        "!pip install unidecode"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.2-py3-none-any.whl (235 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▍                              | 10 kB 26.6 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 20 kB 31.9 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 30 kB 20.0 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 40 kB 17.2 MB/s eta 0:00:01\r\u001b[K     |███████                         | 51 kB 10.5 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 61 kB 10.4 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 71 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 81 kB 10.5 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 92 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 102 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 112 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 122 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 133 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 143 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 153 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 163 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 174 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 184 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 194 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 204 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 215 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 225 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 235 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 235 kB 9.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAHi3mt-z-I_",
        "outputId": "475d77ce-542f-4859-c5d5-81b14b9f847a"
      },
      "source": [
        "!pip install spacy==3"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting spacy==3\n",
            "  Downloading spacy-3.0.0-cp37-cp37m-manylinux2014_x86_64.whl (12.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.7 MB 7.8 MB/s \n",
            "\u001b[?25hCollecting pathy\n",
            "  Downloading pathy-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3) (4.62.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==3) (2.0.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3) (2.23.0)\n",
            "Collecting catalogue<2.1.0,>=2.0.1\n",
            "  Downloading catalogue-2.0.6-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3) (1.0.6)\n",
            "Collecting thinc<8.1.0,>=8.0.0\n",
            "  Downloading thinc-8.0.13-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (628 kB)\n",
            "\u001b[K     |████████████████████████████████| 628 kB 50.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy==3) (3.10.0.2)\n",
            "Collecting srsly<3.0.0,>=2.4.0\n",
            "  Downloading srsly-2.4.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (451 kB)\n",
            "\u001b[K     |████████████████████████████████| 451 kB 49.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy==3) (2.11.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3) (1.19.5)\n",
            "Collecting pydantic<1.8.0,>=1.7.1\n",
            "  Downloading pydantic-1.7.4-cp37-cp37m-manylinux2014_x86_64.whl (9.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.1 MB 51.0 MB/s \n",
            "\u001b[?25hCollecting typer<0.4.0,>=0.3.0\n",
            "  Downloading typer-0.3.2-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy==3) (57.4.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3) (0.4.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from spacy==3) (4.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3) (21.3)\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.0\n",
            "  Downloading spacy_legacy-3.0.8-py2.py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==3) (3.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy==3) (0.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.1->spacy==3) (3.6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy==3) (3.0.6)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3) (2021.10.8)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy==3) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy==3) (2.0.1)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy->spacy==3) (5.2.1)\n",
            "Installing collected packages: catalogue, typer, srsly, pydantic, thinc, spacy-legacy, pathy, spacy\n",
            "  Attempting uninstall: catalogue\n",
            "    Found existing installation: catalogue 1.0.0\n",
            "    Uninstalling catalogue-1.0.0:\n",
            "      Successfully uninstalled catalogue-1.0.0\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 1.0.5\n",
            "    Uninstalling srsly-1.0.5:\n",
            "      Successfully uninstalled srsly-1.0.5\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "Successfully installed catalogue-2.0.6 pathy-0.6.1 pydantic-1.7.4 spacy-3.0.0 spacy-legacy-3.0.8 srsly-2.4.2 thinc-8.0.13 typer-0.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtE1WcY6znBL"
      },
      "source": [
        "from utils.preprocess import preprocess_bert"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ck8SbYD0Qqz",
        "outputId": "a62b7741-5d66-4838-9848-407726e2c5d5"
      },
      "source": [
        "from collections import namedtuple\n",
        "arguments = namedtuple('arguments', ['run_prefix','finetune_datasets','model_class',\n",
        "                                     'max_seq_length', 'asciify_emojis','username_filler',\n",
        "                                    'url_filler', 'replace_multiple_usernames','replace_multiple_urls',\n",
        "                                      'remove_unicode_symbols','replace_usernames','replace_urls',\n",
        "                                     'standardize_punctuation','remove_accented_characters'])\n",
        "\n",
        "args = arguments(\"test_run\",[\"crowdbreaks\"],\"covid-twitter-bert-2\",\n",
        "                 96, True, \"twitteruser\", \n",
        "                 \"twitterurl\", True,True,\n",
        "                 True, True, True,\n",
        "                 True, True)\n",
        "args\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "arguments(run_prefix='test_run', finetune_datasets=['crowdbreaks'], model_class='covid-twitter-bert-2', max_seq_length=96, asciify_emojis=True, username_filler='twitteruser', url_filler='twitterurl', replace_multiple_usernames=True, replace_multiple_urls=True, remove_unicode_symbols=True, replace_usernames=True, replace_urls=True, standardize_punctuation=True, remove_accented_characters=True)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvgKvfbM1w8O"
      },
      "source": [
        "df['sentence'] = df['sentence'].apply(lambda x: preprocess_bert(x,args,do_lower_case=True))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lcl3ByvV1Pae"
      },
      "source": [
        "#Let’s extract the sentences and labels of our training set as numpy ndarrays.\n",
        "\n",
        "# Get the lists of sentences and their labels.\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9y7BzNKf1m87",
        "outputId": "42210173-9819-4298-f841-13ea30ad1882"
      },
      "source": [
        "sentences[0]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'arizona classrooms vulnerable to measles outbreak: the arizona department of health services looked at herd... twitterurl'"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHucOLrN2IMW",
        "outputId": "6bd0b580-f5cb-428f-966f-7559e89fc70b"
      },
      "source": [
        "type(labels[0])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.int64"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmdq4f38xt8C"
      },
      "source": [
        "## BERT Tokenizer\n",
        "\n",
        "To feed our text to BERT, it must be split into tokens, and then these tokens must be mapped to their index in the tokenizer vocabulary.\n",
        "\n",
        "The tokenization must be performed by the tokenizer included with BERT–the below cell will download this for us. We’ll be using the “uncased” version here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162,
          "referenced_widgets": [
            "766ff190835644fc9dd4fc6290f822b9",
            "2f5eb8c605fb4704900d7890568dae38",
            "ee0158b8885c4d78b76a41f1c18ee847",
            "62231e1486ba41258eda21530a8022ce",
            "9e8a50f55c21407cb5b9d7a719fa0282",
            "557b905b882640ffb7641dd222c8e245",
            "0fc39b0ff546404d94dd814ee780f02a",
            "75ac83c505ef4e0e906caaad542f8558",
            "cebeb3eaeffe47aebac9342d9537c882",
            "65cf1e9f0fcd4d078f7c6b6efc18a95d",
            "5f945203e6cc4ac0b49e8bc42df1cb1e",
            "f7f21177566f4843a537b35fcb9a6262",
            "779e227c04b34497a3b8d07545bbdf49",
            "4ed1096c4a734168a11dd7b376512812",
            "8f63791e54cf42b38469c8cfdf6240c6",
            "fa125b59b35544ec9ea726bba63ce19d",
            "2f331367eb3b470a988cff2e1eb2d915",
            "e2529816d28f4b71891ee2ead46a371b",
            "8a76f48ad2e4432dbf51e9f1eb2857a7",
            "c829a367e1c4424da55a1056d1504cd7",
            "5c506c889bca452aaa722cb8cf0af3c0",
            "4de390814a4042cda5a4e5cf54d373a1",
            "4ac7fea6317843c0b087959ac9421858",
            "8fc21e7113714ba19a424f8ec412b228",
            "1457400ef12647d2b30b0a69a6db0c5e",
            "ac9e70c0c8ed467796925581f3596319",
            "d9a0a1fffde84c7ba2508ce854679556",
            "1e32c52837824dcd9918e48158babd6d",
            "4e5bad03b79143f28a2924a6e8256af6",
            "557fa130ac0241beaf29dd3bee693ccf",
            "6039f76fd6284cc180749d2a9a05956c",
            "218adeb692f74d5ea05a0d1c5300f117",
            "7cebd0245bf14472bd825c4f7804aa71",
            "2c43e16ef7a94cf0aa6636e830033730",
            "acd6f5e6af4742fe873cb7dc8c330802",
            "1679058352d34a3f81a27cdcf15b04fb",
            "9e16fb4a1b114a569adf3ec800a3c5ee",
            "ac43e257560a4008b17c7cc387f7bc0a",
            "0d8ff8cb9a674e9c8a33879442653cfd",
            "104c176ee6b441b1a3d5908fe07f6376",
            "ba9542d9ad2b4df595b846e2be96d3c9",
            "4fab76c85b544f4bb488e9b4d4628826",
            "e0a299537e16410f97592e7300abd923",
            "2d0eef7c2a1b4cf2b4d22f8f7bdc23aa"
          ]
        },
        "id": "d2czgaHdxpOI",
        "outputId": "589ec08e-ce36-4784-ee49-9dba69cdda05"
      },
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "model_name = 'digitalepidemiologylab/covid-twitter-bert-v2'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, do_lower_case=True)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "766ff190835644fc9dd4fc6290f822b9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/62.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f7f21177566f4843a537b35fcb9a6262",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/421 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4ac7fea6317843c0b087959ac9421858",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c43e16ef7a94cf0aa6636e830033730",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MroUDOty2Hv",
        "outputId": "98954cf0-7d7c-400d-d968-ed9b798e83b6"
      },
      "source": [
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Original:  arizona classrooms vulnerable to measles outbreak: the arizona department of health services looked at herd... twitterurl\n",
            "Tokenized:  ['arizona', 'classrooms', 'vulnerable', 'to', 'me', '##as', '##les', 'outbreak', ':', 'the', 'arizona', 'department', 'of', 'health', 'services', 'looked', 'at', 'herd', '.', '.', '.', 'twitter', '##ur', '##l']\n",
            "Token IDs:  [5334, 12463, 8211, 2000, 2033, 3022, 4244, 8293, 1024, 1996, 5334, 2533, 1997, 2740, 2578, 2246, 2012, 14906, 1012, 1012, 1012, 10474, 3126, 2140]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsI_tXGz3YuJ"
      },
      "source": [
        "The above code left out a few required formatting steps:\n",
        "* Add special tokens to the start and end of each sentence.\n",
        "* Pad & truncate all sentences to a single constant length.\n",
        "* Explicitly differentiate real tokens from padding tokens with the “attention mask”.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dl6Anl_3hMH",
        "outputId": "2aa8f567-46f0-4685-a03f-d31c8f966404"
      },
      "source": [
        "tokenizer.encode_plus(sentences[0],                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 96,           # Pad & truncate all sentences.\n",
        "                        padding= True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                      truncation=True,\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  101,  5334, 12463,  8211,  2000,  2033,  3022,  4244,  8293,  1024,\n",
              "          1996,  5334,  2533,  1997,  2740,  2578,  2246,  2012, 14906,  1012,\n",
              "          1012,  1012, 10474,  3126,  2140,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9LhhqFE35PU",
        "outputId": "5b6a9bc9-e559-4654-e660-572c2acce3ac"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 96,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt', \n",
        "                        truncation=True    # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8GiVyYP4niK"
      },
      "source": [
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLIpto5h4t0C"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "train_dataset = TensorDataset(input_ids, attention_masks, labels)\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyeIeypee6Pe"
      },
      "source": [
        "## Load validation data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXJX6WYy6OCg"
      },
      "source": [
        "# do all above for validation dataset\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df2 = pd.read_csv(\"drive/MyDrive/covid-twitter-bert/data/finetune/originals/crowdbreaks/dev.tsv\", delimiter='\\t', header=0, names=['id', 'label', 'sentence'])\n",
        "df2.loc[df2['label']==-1,'label']=2\n",
        "\n",
        "# pre-processes special characters\n",
        "df2['sentence'] = df2['sentence'].apply(lambda x: preprocess_bert(x,args,do_lower_case=True))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "lKzOaXFp6rf-",
        "outputId": "19cc14d3-df8a-4c30-b041-1ad306065051"
      },
      "source": [
        "df2.head()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>522873565969150016</td>\n",
              "      <td>1</td>\n",
              "      <td>flu shot, got. #vaccinated #flushot #diseasepr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>371691166674451968</td>\n",
              "      <td>1</td>\n",
              "      <td>idiots. twitteruser : texas measles outbreak t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>70612980194226200</td>\n",
              "      <td>1</td>\n",
              "      <td>at the vet my baby is getting a vaccination aw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>562391001118289984</td>\n",
              "      <td>2</td>\n",
              "      <td>today in journalism my professor said friend's...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>239016379901177984</td>\n",
              "      <td>2</td>\n",
              "      <td>twitteruser and children getting vaccinated st...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   id  label                                           sentence\n",
              "0  522873565969150016      1  flu shot, got. #vaccinated #flushot #diseasepr...\n",
              "1  371691166674451968      1  idiots. twitteruser : texas measles outbreak t...\n",
              "2   70612980194226200      1  at the vet my baby is getting a vaccination aw...\n",
              "3  562391001118289984      2  today in journalism my professor said friend's...\n",
              "4  239016379901177984      2  twitteruser and children getting vaccinated st..."
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KudewtW-6sdR"
      },
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "test_sentences = df2.sentence.values\n",
        "test_labels = df2.label.values"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9D2C0d-697A",
        "outputId": "1e8e87c5-e545-4c9b-e8b4-cf1a701c815c"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "test_input_ids = []\n",
        "test_attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in test_sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 96,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    test_input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    test_attention_masks.append(encoded_dict['attention_mask'])\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jO8BiGSJSq4W",
        "outputId": "a8738018-2e27-4326-88c1-ede8008eba2e"
      },
      "source": [
        "test_labels[0].item()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMOeOBCN7PaM"
      },
      "source": [
        "# Convert the lists into tensors.\n",
        "test_input_ids = torch.cat(test_input_ids, dim=0)\n",
        "test_attention_masks = torch.cat(test_attention_masks, dim=0)\n",
        "test_labels = torch.tensor(test_labels)\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9losOzcp7atF"
      },
      "source": [
        "val_dataset = TensorDataset(test_input_ids, test_attention_masks, test_labels)\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrtyu9wV7pLD"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxBpU1Bs71gB"
      },
      "source": [
        "## Fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmHtDn4X7zV5",
        "outputId": "c95e6450-2337-4a01-aa27-930f3eccef83"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(  \n",
        "    'digitalepidemiologylab/covid-twitter-bert-v2', # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 3, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        "     return_dict=False)\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()\n"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at digitalepidemiologylab/covid-twitter-bert-v2 were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at digitalepidemiologylab/covid-twitter-bert-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 1024)\n",
              "      (token_type_embeddings): Embedding(2, 1024)\n",
              "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (12): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (13): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (14): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (15): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (16): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (17): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (18): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (19): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (20): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (21): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (22): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (23): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=1024, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaXJyp7V8Q3q"
      },
      "source": [
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBvN8r5Q8U8i"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqUBzeqX8dmY"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XO7427a8nay"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dtoxpP0IP9B"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfFm5LZq8q9o",
        "outputId": "cc25cc5c-86f6-4527-da50-205d65514d7f"
      },
      "source": [
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        loss, logits = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            (loss, logits) = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    128.    Elapsed: 0:00:21.\n",
            "  Batch    80  of    128.    Elapsed: 0:00:42.\n",
            "  Batch   120  of    128.    Elapsed: 0:01:03.\n",
            "\n",
            "  Average training loss: 0.98\n",
            "  Training epcoh took: 0:01:07\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.76\n",
            "  Validation Loss: 0.72\n",
            "  Validation took: 0:00:07\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    128.    Elapsed: 0:00:21.\n",
            "  Batch    80  of    128.    Elapsed: 0:00:42.\n",
            "  Batch   120  of    128.    Elapsed: 0:01:03.\n",
            "\n",
            "  Average training loss: 0.59\n",
            "  Training epcoh took: 0:01:07\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.79\n",
            "  Validation Loss: 0.60\n",
            "  Validation took: 0:00:07\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    128.    Elapsed: 0:00:21.\n",
            "  Batch    80  of    128.    Elapsed: 0:00:42.\n",
            "  Batch   120  of    128.    Elapsed: 0:01:03.\n",
            "\n",
            "  Average training loss: 0.39\n",
            "  Training epcoh took: 0:01:07\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.66\n",
            "  Validation took: 0:00:07\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    128.    Elapsed: 0:00:21.\n",
            "  Batch    80  of    128.    Elapsed: 0:00:42.\n",
            "  Batch   120  of    128.    Elapsed: 0:01:03.\n",
            "\n",
            "  Average training loss: 0.25\n",
            "  Training epcoh took: 0:01:07\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.72\n",
            "  Validation took: 0:00:07\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:04:58 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "qDejhFUhR8I5",
        "outputId": "97021927-7676-46c1-ca05-d15def79c711"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.98</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0:01:07</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.59</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0:01:07</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.39</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.78</td>\n",
              "      <td>0:01:07</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.25</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.78</td>\n",
              "      <td>0:01:07</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.98         0.72           0.76       0:01:07         0:00:07\n",
              "2               0.59         0.60           0.79       0:01:07         0:00:07\n",
              "3               0.39         0.66           0.78       0:01:07         0:00:07\n",
              "4               0.25         0.72           0.78       0:01:07         0:00:07"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "YMeY1Yq_V2Bq",
        "outputId": "1117b3b3-c7ec-40ae-e965-e2862b7037a2"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NE1BkmVZgvPZ"
      },
      "source": [
        "## Loading test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5u0KsRVkV14B"
      },
      "source": [
        "## Performance on test set\n",
        "df3 = pd.read_csv(\"drive/MyDrive/covid-twitter-bert/data/finetune/originals/crowdbreaks/test.tsv\", delimiter='\\t', header=0, names=['id', 'label', 'sentence'])\n",
        "df3.loc[df3['label']==-1,'label']=2\n",
        "# pre-processes special characters\n",
        "df3['sentence'] = df3['sentence'].apply(lambda x: preprocess_bert(x,args,do_lower_case=True))"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4XJRd9EWVK4",
        "outputId": "afc5dbff-5bcd-476a-fd4e-079c431385e1"
      },
      "source": [
        "df3['label'].value_counts()"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    237\n",
              "1    225\n",
              "0    219\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2cumvgZWXrM",
        "outputId": "556d7205-f569-4bb6-a8d5-6ea6afc24689"
      },
      "source": [
        "test_sentences = df3.sentence.values\n",
        "test_labels = df3.label.values\n",
        "\n",
        "test_input_ids = []\n",
        "test_attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in test_sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 96,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    test_input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    test_attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "batch_size=16\n",
        "\n",
        "input_ids = torch.cat(test_input_ids, dim=0)\n",
        "attention_masks = torch.cat(test_attention_masks, dim=0)\n",
        "labels = torch.tensor(test_labels)\n",
        "\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igvfT1qhceAi"
      },
      "source": [
        "## Prediction on test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaa8VSUIdlQC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpW1yPXyXt3v",
        "outputId": "63d9ec2a-ec27-4227-ca01-74d2b2a43efc"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions.\n",
        "      result = model(b_input_ids, \n",
        "                     token_type_ids=None, \n",
        "                     attention_mask=b_input_mask,\n",
        "                     return_dict=True)\n",
        "\n",
        "  logits = result.logits\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for 681 test sentences...\n",
            "    DONE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjA9VyOTX1g_",
        "outputId": "fcaa80be-4d4d-45c8-cada-bcf70d08466c"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating F1 Score. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "  \n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  \n",
        "  # Calculate and store the coef for this batch.  \n",
        "  f1 = f1_score(true_labels[i], pred_labels_i, average=None)                \n",
        "  f1_set.append(f1)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating F1 Score. Coef. for each batch...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8tyGdHvY_zR",
        "outputId": "3e4eb47e-7511-4694-dee1-09cf6cdb2bb7"
      },
      "source": [
        "len(f1_set)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8puCnvCZCJ0",
        "outputId": "47176f8f-ca40-4bb0-9cfb-7981e67dbc62"
      },
      "source": [
        "f1_set"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0.6       , 0.72727273, 0.72727273]),\n",
              " array([0.8       , 0.66666667, 0.76923077]),\n",
              " array([0.5       , 0.70588235, 0.72727273]),\n",
              " array([0.8 , 0.75, 1.  ]),\n",
              " array([0.66666667, 0.6       , 0.61538462]),\n",
              " array([0.71428571, 0.92307692, 0.4       ]),\n",
              " array([0.66666667, 0.76923077, 0.76923077]),\n",
              " array([0.71428571, 0.5       , 0.6       ]),\n",
              " array([0.85714286, 0.75      , 0.82352941]),\n",
              " array([0.83333333, 0.54545455, 0.66666667]),\n",
              " array([0.5       , 0.93333333, 0.92307692]),\n",
              " array([0.92307692, 0.90909091, 1.        ]),\n",
              " array([0.93333333, 0.57142857, 0.8       ]),\n",
              " array([0.85714286, 0.66666667, 0.83333333]),\n",
              " array([0.8       , 0.28571429, 0.6       ]),\n",
              " array([0.8       , 0.92307692, 0.88888889]),\n",
              " array([1., 1., 1.]),\n",
              " array([0.75      , 0.72727273, 0.61538462]),\n",
              " array([0.5       , 0.66666667, 0.75      ]),\n",
              " array([0.83333333, 0.4       , 0.93333333]),\n",
              " array([0.66666667, 0.83333333, 0.85714286]),\n",
              " array([1.        , 0.66666667, 0.8       ]),\n",
              " array([0.92307692, 0.88888889, 0.8       ]),\n",
              " array([0.4       , 0.66666667, 0.66666667]),\n",
              " array([0.88888889, 0.76923077, 0.8       ]),\n",
              " array([0.85714286, 0.28571429, 0.77777778]),\n",
              " array([0.66666667, 0.6       , 0.75      ]),\n",
              " array([0.90909091, 1.        , 0.90909091]),\n",
              " array([0.5       , 0.76923077, 0.90909091]),\n",
              " array([0.72727273, 0.70588235, 0.5       ]),\n",
              " array([1.  , 0.9 , 0.75]),\n",
              " array([0.66666667, 0.88888889, 0.82352941]),\n",
              " array([0.83333333, 0.66666667, 0.90909091]),\n",
              " array([0.83333333, 0.88888889, 0.90909091]),\n",
              " array([0.75      , 0.88888889, 0.93333333]),\n",
              " array([0.66666667, 0.94117647, 0.66666667]),\n",
              " array([0.88888889, 1.        , 0.75      ]),\n",
              " array([0.66666667, 0.54545455, 0.88888889]),\n",
              " array([0.66666667, 0.66666667, 0.71428571]),\n",
              " array([0.66666667, 0.66666667, 0.71428571]),\n",
              " array([0.85714286, 0.8       , 0.76923077]),\n",
              " array([0.75      , 0.83333333, 0.83333333]),\n",
              " array([0.66666667, 0.57142857, 0.8       ])]"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQwMcZEzZSx4",
        "outputId": "eaf43a90-c5b2-4a48-8e65-a4c05cdc749e"
      },
      "source": [
        "true_labels[0]"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 1, 1, 0, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wl7wdJYBZV9c",
        "outputId": "67bc2626-82e2-4128-f1b6-2b60e6e337eb"
      },
      "source": [
        "predictions[0]"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 3.6149707, -2.5169702, -2.319315 ],\n",
              "       [ 2.8493059, -1.9107704, -2.3156106],\n",
              "       [ 3.4547439, -2.2807326, -2.3502448],\n",
              "       [-1.0161924, -1.6066909,  3.2713308],\n",
              "       [-1.4951551,  4.14966  , -2.4093778],\n",
              "       [ 0.7124895,  1.0357994, -1.9097619],\n",
              "       [-1.3797809, -2.2380972,  4.3564124],\n",
              "       [-1.6483228, -2.155723 ,  4.359962 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oV6pyByGZcN9"
      },
      "source": [
        "# Combine the results across all batches. \n",
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "# For each sample, pick the label (0 or 1) with the higher score.\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m57dVWbDbn-l"
      },
      "source": [
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fk6QM0hfboz1",
        "outputId": "f886c9ea-ffc6-4474-eb84-629594851415"
      },
      "source": [
        "# Calculate the f1 for each class\n",
        "f1 = f1_score(flat_true_labels, flat_predictions, average=None)\n",
        "\n",
        "print(f1)"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.78072289 0.74725275 0.79674797]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTNxxVdneecV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bYjpHW_cEBh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}