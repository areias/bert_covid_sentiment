{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_tutorials.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOlxI11AfrdSxIN2pj9f6iK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "766ff190835644fc9dd4fc6290f822b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2f5eb8c605fb4704900d7890568dae38",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ee0158b8885c4d78b76a41f1c18ee847",
              "IPY_MODEL_62231e1486ba41258eda21530a8022ce",
              "IPY_MODEL_9e8a50f55c21407cb5b9d7a719fa0282"
            ]
          }
        },
        "2f5eb8c605fb4704900d7890568dae38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ee0158b8885c4d78b76a41f1c18ee847": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_557b905b882640ffb7641dd222c8e245",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0fc39b0ff546404d94dd814ee780f02a"
          }
        },
        "62231e1486ba41258eda21530a8022ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_75ac83c505ef4e0e906caaad542f8558",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 62,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 62,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cebeb3eaeffe47aebac9342d9537c882"
          }
        },
        "9e8a50f55c21407cb5b9d7a719fa0282": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_65cf1e9f0fcd4d078f7c6b6efc18a95d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 62.0/62.0 [00:00&lt;00:00, 1.85kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5f945203e6cc4ac0b49e8bc42df1cb1e"
          }
        },
        "557b905b882640ffb7641dd222c8e245": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0fc39b0ff546404d94dd814ee780f02a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "75ac83c505ef4e0e906caaad542f8558": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cebeb3eaeffe47aebac9342d9537c882": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "65cf1e9f0fcd4d078f7c6b6efc18a95d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5f945203e6cc4ac0b49e8bc42df1cb1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f7f21177566f4843a537b35fcb9a6262": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_779e227c04b34497a3b8d07545bbdf49",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4ed1096c4a734168a11dd7b376512812",
              "IPY_MODEL_8f63791e54cf42b38469c8cfdf6240c6",
              "IPY_MODEL_fa125b59b35544ec9ea726bba63ce19d"
            ]
          }
        },
        "779e227c04b34497a3b8d07545bbdf49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4ed1096c4a734168a11dd7b376512812": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2f331367eb3b470a988cff2e1eb2d915",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e2529816d28f4b71891ee2ead46a371b"
          }
        },
        "8f63791e54cf42b38469c8cfdf6240c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8a76f48ad2e4432dbf51e9f1eb2857a7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 421,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 421,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c829a367e1c4424da55a1056d1504cd7"
          }
        },
        "fa125b59b35544ec9ea726bba63ce19d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5c506c889bca452aaa722cb8cf0af3c0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 421/421 [00:00&lt;00:00, 12.0kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4de390814a4042cda5a4e5cf54d373a1"
          }
        },
        "2f331367eb3b470a988cff2e1eb2d915": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e2529816d28f4b71891ee2ead46a371b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8a76f48ad2e4432dbf51e9f1eb2857a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c829a367e1c4424da55a1056d1504cd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5c506c889bca452aaa722cb8cf0af3c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4de390814a4042cda5a4e5cf54d373a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4ac7fea6317843c0b087959ac9421858": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8fc21e7113714ba19a424f8ec412b228",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1457400ef12647d2b30b0a69a6db0c5e",
              "IPY_MODEL_ac9e70c0c8ed467796925581f3596319",
              "IPY_MODEL_d9a0a1fffde84c7ba2508ce854679556"
            ]
          }
        },
        "8fc21e7113714ba19a424f8ec412b228": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1457400ef12647d2b30b0a69a6db0c5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1e32c52837824dcd9918e48158babd6d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4e5bad03b79143f28a2924a6e8256af6"
          }
        },
        "ac9e70c0c8ed467796925581f3596319": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_557fa130ac0241beaf29dd3bee693ccf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6039f76fd6284cc180749d2a9a05956c"
          }
        },
        "d9a0a1fffde84c7ba2508ce854679556": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_218adeb692f74d5ea05a0d1c5300f117",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 226k/226k [00:00&lt;00:00, 905kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7cebd0245bf14472bd825c4f7804aa71"
          }
        },
        "1e32c52837824dcd9918e48158babd6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4e5bad03b79143f28a2924a6e8256af6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "557fa130ac0241beaf29dd3bee693ccf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6039f76fd6284cc180749d2a9a05956c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "218adeb692f74d5ea05a0d1c5300f117": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7cebd0245bf14472bd825c4f7804aa71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2c43e16ef7a94cf0aa6636e830033730": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_acd6f5e6af4742fe873cb7dc8c330802",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1679058352d34a3f81a27cdcf15b04fb",
              "IPY_MODEL_9e16fb4a1b114a569adf3ec800a3c5ee",
              "IPY_MODEL_ac43e257560a4008b17c7cc387f7bc0a"
            ]
          }
        },
        "acd6f5e6af4742fe873cb7dc8c330802": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1679058352d34a3f81a27cdcf15b04fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0d8ff8cb9a674e9c8a33879442653cfd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_104c176ee6b441b1a3d5908fe07f6376"
          }
        },
        "9e16fb4a1b114a569adf3ec800a3c5ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ba9542d9ad2b4df595b846e2be96d3c9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 112,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 112,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4fab76c85b544f4bb488e9b4d4628826"
          }
        },
        "ac43e257560a4008b17c7cc387f7bc0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e0a299537e16410f97592e7300abd923",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 112/112 [00:00&lt;00:00, 3.08kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2d0eef7c2a1b4cf2b4d22f8f7bdc23aa"
          }
        },
        "0d8ff8cb9a674e9c8a33879442653cfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "104c176ee6b441b1a3d5908fe07f6376": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ba9542d9ad2b4df595b846e2be96d3c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4fab76c85b544f4bb488e9b4d4628826": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e0a299537e16410f97592e7300abd923": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2d0eef7c2a1b4cf2b4d22f8f7bdc23aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/areias/bert_covid_sentiment/blob/main/bert_tutorials.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bNzcqBKwX5S",
        "outputId": "3804244e-480a-427f-91b4-d5812abcaef6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65oksFt0urfB"
      },
      "source": [
        "https://www.tensorflow.org/text/tutorials/fine_tune_bert\n",
        "\n",
        "https://skimai.com/fine-tuning-bert-for-sentiment-analysis/\n",
        "\n",
        "http://mccormickml.com/2019/07/22/BERT-fine-tuning/\n",
        "\n",
        "https://www.thepythoncode.com/article/finetuning-bert-using-huggingface-transformers-python\n",
        "\n",
        "https://colab.research.google.com/github/digitalepidemiologylab/covid-twitter-bert/blob/master/CT_BERT_Huggingface_(GPU_training).ipynb\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6Me4R7VvWU6"
      },
      "source": [
        "## http://mccormickml.com/2019/07/22/BERT-fine-tuning/ 22 Jul 2019, Revised on 3/20/20"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsa9GKKdu_Mg",
        "outputId": "66bd9dd3-a181-4735-ea4a-d2ae045b3036"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPLfMB-rvUZZ",
        "outputId": "980d1424-77e5-4e7b-f373-8d71a3d3a4eb"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNLxGXx8vpEo",
        "outputId": "72dc04e7-6032-45b4-ec19-5d80e152d4b7"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 7.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 56.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.1.2-py3-none-any.whl (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 7.3 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 60.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 40.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.1.2 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.12.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaqM05qpv0eY"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"drive/MyDrive/covid-twitter-bert/data/finetune/originals/crowdbreaks/train.tsv\", delimiter='\\t', header=0, names=['id', 'label', 'sentence'])\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwFCHE7cTp0C",
        "outputId": "b73bb581-fc84-4833-a8c2-a2982521d494"
      },
      "source": [
        "df['label'].value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 0    686\n",
              "-1    678\n",
              " 1    677\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIiNk_AiTwQx"
      },
      "source": [
        "df.loc[df['label']==-1,'label']=2"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rm7WtcvQT7Cy",
        "outputId": "06c156af-34e3-4d78-f6ab-d007f12484fb"
      },
      "source": [
        "df['label'].value_counts()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    686\n",
              "2    678\n",
              "1    677\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "VjKLan4hxNsx",
        "outputId": "e9a96755-09f7-450f-b918-4b3cd6234328"
      },
      "source": [
        "df.sample(10)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>879</th>\n",
              "      <td>435638533626540032</td>\n",
              "      <td>1</td>\n",
              "      <td>how many kids aren't getting vaccinated? http:...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>991</th>\n",
              "      <td>394477949019505024</td>\n",
              "      <td>1</td>\n",
              "      <td>@ChilledChaos I have Autism and yet I hardly e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1120</th>\n",
              "      <td>440543774817923008</td>\n",
              "      <td>1</td>\n",
              "      <td>Baby's doctor appointment he's got some vaccin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>510808840737419008</td>\n",
              "      <td>1</td>\n",
              "      <td>Attend Health&amp;amp;Safety mtg discussion on HPV...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>834</th>\n",
              "      <td>562694415115096000</td>\n",
              "      <td>0</td>\n",
              "      <td>FFS --&amp;gt;  RT @thinkprogress: Congressman: Me...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>108227844164944000</td>\n",
              "      <td>0</td>\n",
              "      <td>Listening to Pierre Robert on MMR while eating...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>689</th>\n",
              "      <td>468869706292945024</td>\n",
              "      <td>1</td>\n",
              "      <td>\"@HuffingtonPost: 300 million children could b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1127</th>\n",
              "      <td>467011773736825024</td>\n",
              "      <td>1</td>\n",
              "      <td>\"@TeamMorgan2014: Woman's cancer wiped out by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1016</th>\n",
              "      <td>247112733944860992</td>\n",
              "      <td>0</td>\n",
              "      <td>Mmr go gett em</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>831</th>\n",
              "      <td>509696511559864000</td>\n",
              "      <td>1</td>\n",
              "      <td>The Case for Vaccinating Your Kids, in One Ala...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      id  ...                                           sentence\n",
              "879   435638533626540032  ...  how many kids aren't getting vaccinated? http:...\n",
              "991   394477949019505024  ...  @ChilledChaos I have Autism and yet I hardly e...\n",
              "1120  440543774817923008  ...  Baby's doctor appointment he's got some vaccin...\n",
              "997   510808840737419008  ...  Attend Health&amp;Safety mtg discussion on HPV...\n",
              "834   562694415115096000  ...  FFS --&gt;  RT @thinkprogress: Congressman: Me...\n",
              "1997  108227844164944000  ...  Listening to Pierre Robert on MMR while eating...\n",
              "689   468869706292945024  ...  \"@HuffingtonPost: 300 million children could b...\n",
              "1127  467011773736825024  ...  \"@TeamMorgan2014: Woman's cancer wiped out by ...\n",
              "1016  247112733944860992  ...                                     Mmr go gett em\n",
              "831   509696511559864000  ...  The Case for Vaccinating Your Kids, in One Ala...\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xWkElDJy8Dc"
      },
      "source": [
        "## Pre-processing Tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzKmqk1py5GD"
      },
      "source": [
        "import sys\n",
        "sys.path.append('drive/MyDrive/covid-twitter-bert')\n",
        "sys.path.append('drive/MyDrive/covid-twitter-bert/tensorflow_models')\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bT0n2mAwzxi1",
        "outputId": "ea08d366-4a4c-4e23-b54a-1e480ea5cdf2"
      },
      "source": [
        "!pip install emoji"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emoji\n",
            "  Downloading emoji-1.6.1.tar.gz (170 kB)\n",
            "\u001b[?25l\r\u001b[K     |██                              | 10 kB 31.0 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 20 kB 27.8 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 30 kB 19.2 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 40 kB 16.8 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 51 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 61 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 71 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 81 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 92 kB 10.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 102 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 112 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 122 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 133 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 143 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 153 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 163 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 170 kB 8.0 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.6.1-py3-none-any.whl size=169314 sha256=2526d39968094a824a6717f6e6b2dd82841a231a4d95bdc440dedf60ddfc7e80\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/5f/d3/03d313ddb3c2a1a427bb4690f1621eea60fe6f2a30cc95940f\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-1.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRihfV5_z3lu",
        "outputId": "b68b3893-4683-4e81-bab0-bedeb05476d2"
      },
      "source": [
        "!pip install unidecode"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.2-py3-none-any.whl (235 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▍                              | 10 kB 26.6 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 20 kB 31.9 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 30 kB 20.0 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 40 kB 17.2 MB/s eta 0:00:01\r\u001b[K     |███████                         | 51 kB 10.5 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 61 kB 10.4 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 71 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 81 kB 10.5 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 92 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 102 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 112 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 122 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 133 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 143 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 153 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 163 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 174 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 184 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 194 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 204 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 215 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 225 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 235 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 235 kB 9.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAHi3mt-z-I_",
        "outputId": "475d77ce-542f-4859-c5d5-81b14b9f847a"
      },
      "source": [
        "!pip install spacy==3"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting spacy==3\n",
            "  Downloading spacy-3.0.0-cp37-cp37m-manylinux2014_x86_64.whl (12.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.7 MB 7.8 MB/s \n",
            "\u001b[?25hCollecting pathy\n",
            "  Downloading pathy-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3) (4.62.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==3) (2.0.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3) (2.23.0)\n",
            "Collecting catalogue<2.1.0,>=2.0.1\n",
            "  Downloading catalogue-2.0.6-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3) (1.0.6)\n",
            "Collecting thinc<8.1.0,>=8.0.0\n",
            "  Downloading thinc-8.0.13-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (628 kB)\n",
            "\u001b[K     |████████████████████████████████| 628 kB 50.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy==3) (3.10.0.2)\n",
            "Collecting srsly<3.0.0,>=2.4.0\n",
            "  Downloading srsly-2.4.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (451 kB)\n",
            "\u001b[K     |████████████████████████████████| 451 kB 49.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy==3) (2.11.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3) (1.19.5)\n",
            "Collecting pydantic<1.8.0,>=1.7.1\n",
            "  Downloading pydantic-1.7.4-cp37-cp37m-manylinux2014_x86_64.whl (9.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.1 MB 51.0 MB/s \n",
            "\u001b[?25hCollecting typer<0.4.0,>=0.3.0\n",
            "  Downloading typer-0.3.2-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy==3) (57.4.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3) (0.4.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from spacy==3) (4.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3) (21.3)\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.0\n",
            "  Downloading spacy_legacy-3.0.8-py2.py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==3) (3.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy==3) (0.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.1->spacy==3) (3.6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy==3) (3.0.6)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3) (2021.10.8)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy==3) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy==3) (2.0.1)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy->spacy==3) (5.2.1)\n",
            "Installing collected packages: catalogue, typer, srsly, pydantic, thinc, spacy-legacy, pathy, spacy\n",
            "  Attempting uninstall: catalogue\n",
            "    Found existing installation: catalogue 1.0.0\n",
            "    Uninstalling catalogue-1.0.0:\n",
            "      Successfully uninstalled catalogue-1.0.0\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 1.0.5\n",
            "    Uninstalling srsly-1.0.5:\n",
            "      Successfully uninstalled srsly-1.0.5\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "Successfully installed catalogue-2.0.6 pathy-0.6.1 pydantic-1.7.4 spacy-3.0.0 spacy-legacy-3.0.8 srsly-2.4.2 thinc-8.0.13 typer-0.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtE1WcY6znBL"
      },
      "source": [
        "from utils.preprocess import preprocess_bert"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ck8SbYD0Qqz",
        "outputId": "a62b7741-5d66-4838-9848-407726e2c5d5"
      },
      "source": [
        "from collections import namedtuple\n",
        "arguments = namedtuple('arguments', ['run_prefix','finetune_datasets','model_class',\n",
        "                                     'max_seq_length', 'asciify_emojis','username_filler',\n",
        "                                    'url_filler', 'replace_multiple_usernames','replace_multiple_urls',\n",
        "                                      'remove_unicode_symbols','replace_usernames','replace_urls',\n",
        "                                     'standardize_punctuation','remove_accented_characters'])\n",
        "\n",
        "args = arguments(\"test_run\",[\"crowdbreaks\"],\"covid-twitter-bert-2\",\n",
        "                 96, True, \"twitteruser\", \n",
        "                 \"twitterurl\", True,True,\n",
        "                 True, True, True,\n",
        "                 True, True)\n",
        "args\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "arguments(run_prefix='test_run', finetune_datasets=['crowdbreaks'], model_class='covid-twitter-bert-2', max_seq_length=96, asciify_emojis=True, username_filler='twitteruser', url_filler='twitterurl', replace_multiple_usernames=True, replace_multiple_urls=True, remove_unicode_symbols=True, replace_usernames=True, replace_urls=True, standardize_punctuation=True, remove_accented_characters=True)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvgKvfbM1w8O"
      },
      "source": [
        "df['sentence'] = df['sentence'].apply(lambda x: preprocess_bert(x,args,do_lower_case=True))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lcl3ByvV1Pae"
      },
      "source": [
        "#Let’s extract the sentences and labels of our training set as numpy ndarrays.\n",
        "\n",
        "# Get the lists of sentences and their labels.\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9y7BzNKf1m87",
        "outputId": "42210173-9819-4298-f841-13ea30ad1882"
      },
      "source": [
        "sentences[0]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'arizona classrooms vulnerable to measles outbreak: the arizona department of health services looked at herd... twitterurl'"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHucOLrN2IMW",
        "outputId": "6bd0b580-f5cb-428f-966f-7559e89fc70b"
      },
      "source": [
        "type(labels[0])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.int64"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmdq4f38xt8C"
      },
      "source": [
        "## BERT Tokenizer\n",
        "\n",
        "To feed our text to BERT, it must be split into tokens, and then these tokens must be mapped to their index in the tokenizer vocabulary.\n",
        "\n",
        "The tokenization must be performed by the tokenizer included with BERT–the below cell will download this for us. We’ll be using the “uncased” version here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162,
          "referenced_widgets": [
            "766ff190835644fc9dd4fc6290f822b9",
            "2f5eb8c605fb4704900d7890568dae38",
            "ee0158b8885c4d78b76a41f1c18ee847",
            "62231e1486ba41258eda21530a8022ce",
            "9e8a50f55c21407cb5b9d7a719fa0282",
            "557b905b882640ffb7641dd222c8e245",
            "0fc39b0ff546404d94dd814ee780f02a",
            "75ac83c505ef4e0e906caaad542f8558",
            "cebeb3eaeffe47aebac9342d9537c882",
            "65cf1e9f0fcd4d078f7c6b6efc18a95d",
            "5f945203e6cc4ac0b49e8bc42df1cb1e",
            "f7f21177566f4843a537b35fcb9a6262",
            "779e227c04b34497a3b8d07545bbdf49",
            "4ed1096c4a734168a11dd7b376512812",
            "8f63791e54cf42b38469c8cfdf6240c6",
            "fa125b59b35544ec9ea726bba63ce19d",
            "2f331367eb3b470a988cff2e1eb2d915",
            "e2529816d28f4b71891ee2ead46a371b",
            "8a76f48ad2e4432dbf51e9f1eb2857a7",
            "c829a367e1c4424da55a1056d1504cd7",
            "5c506c889bca452aaa722cb8cf0af3c0",
            "4de390814a4042cda5a4e5cf54d373a1",
            "4ac7fea6317843c0b087959ac9421858",
            "8fc21e7113714ba19a424f8ec412b228",
            "1457400ef12647d2b30b0a69a6db0c5e",
            "ac9e70c0c8ed467796925581f3596319",
            "d9a0a1fffde84c7ba2508ce854679556",
            "1e32c52837824dcd9918e48158babd6d",
            "4e5bad03b79143f28a2924a6e8256af6",
            "557fa130ac0241beaf29dd3bee693ccf",
            "6039f76fd6284cc180749d2a9a05956c",
            "218adeb692f74d5ea05a0d1c5300f117",
            "7cebd0245bf14472bd825c4f7804aa71",
            "2c43e16ef7a94cf0aa6636e830033730",
            "acd6f5e6af4742fe873cb7dc8c330802",
            "1679058352d34a3f81a27cdcf15b04fb",
            "9e16fb4a1b114a569adf3ec800a3c5ee",
            "ac43e257560a4008b17c7cc387f7bc0a",
            "0d8ff8cb9a674e9c8a33879442653cfd",
            "104c176ee6b441b1a3d5908fe07f6376",
            "ba9542d9ad2b4df595b846e2be96d3c9",
            "4fab76c85b544f4bb488e9b4d4628826",
            "e0a299537e16410f97592e7300abd923",
            "2d0eef7c2a1b4cf2b4d22f8f7bdc23aa"
          ]
        },
        "id": "d2czgaHdxpOI",
        "outputId": "589ec08e-ce36-4784-ee49-9dba69cdda05"
      },
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "model_name = 'digitalepidemiologylab/covid-twitter-bert-v2'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, do_lower_case=True)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "766ff190835644fc9dd4fc6290f822b9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/62.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f7f21177566f4843a537b35fcb9a6262",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/421 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4ac7fea6317843c0b087959ac9421858",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c43e16ef7a94cf0aa6636e830033730",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MroUDOty2Hv",
        "outputId": "98954cf0-7d7c-400d-d968-ed9b798e83b6"
      },
      "source": [
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Original:  arizona classrooms vulnerable to measles outbreak: the arizona department of health services looked at herd... twitterurl\n",
            "Tokenized:  ['arizona', 'classrooms', 'vulnerable', 'to', 'me', '##as', '##les', 'outbreak', ':', 'the', 'arizona', 'department', 'of', 'health', 'services', 'looked', 'at', 'herd', '.', '.', '.', 'twitter', '##ur', '##l']\n",
            "Token IDs:  [5334, 12463, 8211, 2000, 2033, 3022, 4244, 8293, 1024, 1996, 5334, 2533, 1997, 2740, 2578, 2246, 2012, 14906, 1012, 1012, 1012, 10474, 3126, 2140]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsI_tXGz3YuJ"
      },
      "source": [
        "The above code left out a few required formatting steps:\n",
        "* Add special tokens to the start and end of each sentence.\n",
        "* Pad & truncate all sentences to a single constant length.\n",
        "* Explicitly differentiate real tokens from padding tokens with the “attention mask”.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dl6Anl_3hMH",
        "outputId": "2aa8f567-46f0-4685-a03f-d31c8f966404"
      },
      "source": [
        "tokenizer.encode_plus(sentences[0],                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 96,           # Pad & truncate all sentences.\n",
        "                        padding= True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                      truncation=True,\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  101,  5334, 12463,  8211,  2000,  2033,  3022,  4244,  8293,  1024,\n",
              "          1996,  5334,  2533,  1997,  2740,  2578,  2246,  2012, 14906,  1012,\n",
              "          1012,  1012, 10474,  3126,  2140,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9LhhqFE35PU",
        "outputId": "5b6a9bc9-e559-4654-e660-572c2acce3ac"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 96,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt', \n",
        "                        truncation=True    # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8GiVyYP4niK"
      },
      "source": [
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLIpto5h4t0C"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "train_dataset = TensorDataset(input_ids, attention_masks, labels)\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXJX6WYy6OCg"
      },
      "source": [
        "# do all above for validation dataset\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df2 = pd.read_csv(\"drive/MyDrive/covid-twitter-bert/data/finetune/originals/crowdbreaks/dev.tsv\", delimiter='\\t', header=0, names=['id', 'label', 'sentence'])\n",
        "df2.loc[df2['label']==-1,'label']=2\n",
        "\n",
        "# pre-processes special characters\n",
        "df2['sentence'] = df2['sentence'].apply(lambda x: preprocess_bert(x,args,do_lower_case=True))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "lKzOaXFp6rf-",
        "outputId": "19cc14d3-df8a-4c30-b041-1ad306065051"
      },
      "source": [
        "df2.head()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>522873565969150016</td>\n",
              "      <td>1</td>\n",
              "      <td>flu shot, got. #vaccinated #flushot #diseasepr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>371691166674451968</td>\n",
              "      <td>1</td>\n",
              "      <td>idiots. twitteruser : texas measles outbreak t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>70612980194226200</td>\n",
              "      <td>1</td>\n",
              "      <td>at the vet my baby is getting a vaccination aw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>562391001118289984</td>\n",
              "      <td>2</td>\n",
              "      <td>today in journalism my professor said friend's...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>239016379901177984</td>\n",
              "      <td>2</td>\n",
              "      <td>twitteruser and children getting vaccinated st...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   id  label                                           sentence\n",
              "0  522873565969150016      1  flu shot, got. #vaccinated #flushot #diseasepr...\n",
              "1  371691166674451968      1  idiots. twitteruser : texas measles outbreak t...\n",
              "2   70612980194226200      1  at the vet my baby is getting a vaccination aw...\n",
              "3  562391001118289984      2  today in journalism my professor said friend's...\n",
              "4  239016379901177984      2  twitteruser and children getting vaccinated st..."
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KudewtW-6sdR"
      },
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "test_sentences = df2.sentence.values\n",
        "test_labels = df2.label.values"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9D2C0d-697A",
        "outputId": "1e8e87c5-e545-4c9b-e8b4-cf1a701c815c"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "test_input_ids = []\n",
        "test_attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in test_sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 96,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    test_input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    test_attention_masks.append(encoded_dict['attention_mask'])\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jO8BiGSJSq4W",
        "outputId": "a8738018-2e27-4326-88c1-ede8008eba2e"
      },
      "source": [
        "test_labels[0].item()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMOeOBCN7PaM"
      },
      "source": [
        "# Convert the lists into tensors.\n",
        "test_input_ids = torch.cat(test_input_ids, dim=0)\n",
        "test_attention_masks = torch.cat(test_attention_masks, dim=0)\n",
        "test_labels = torch.tensor(test_labels)\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9losOzcp7atF"
      },
      "source": [
        "val_dataset = TensorDataset(test_input_ids, test_attention_masks, test_labels)\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrtyu9wV7pLD"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 8\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxBpU1Bs71gB"
      },
      "source": [
        "## Fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmHtDn4X7zV5",
        "outputId": "ffec41ac-fae4-493d-a480-907fd7db3103"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(  \n",
        "    'digitalepidemiologylab/covid-twitter-bert-v2', # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 3, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        "     return_dict=False)\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at digitalepidemiologylab/covid-twitter-bert-v2 were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at digitalepidemiologylab/covid-twitter-bert-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 1024)\n",
              "      (token_type_embeddings): Embedding(2, 1024)\n",
              "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (12): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (13): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (14): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (15): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (16): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (17): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (18): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (19): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (20): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (21): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (22): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (23): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=1024, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaXJyp7V8Q3q"
      },
      "source": [
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBvN8r5Q8U8i"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 1\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqUBzeqX8dmY"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XO7427a8nay"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dtoxpP0IP9B"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfFm5LZq8q9o",
        "outputId": "4bb4b1bc-c025-4607-d43c-17d605984619"
      },
      "source": [
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        loss, logits = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            (loss, logits) = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 1 ========\n",
            "Training...\n",
            "  Batch    40  of    256.    Elapsed: 0:00:13.\n",
            "  Batch    80  of    256.    Elapsed: 0:00:25.\n",
            "  Batch   120  of    256.    Elapsed: 0:00:38.\n",
            "  Batch   160  of    256.    Elapsed: 0:00:50.\n",
            "  Batch   200  of    256.    Elapsed: 0:01:03.\n",
            "  Batch   240  of    256.    Elapsed: 0:01:16.\n",
            "\n",
            "  Average training loss: 0.85\n",
            "  Training epcoh took: 0:01:20\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.76\n",
            "  Validation Loss: 0.66\n",
            "  Validation took: 0:00:07\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:01:28 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "qDejhFUhR8I5",
        "outputId": "3591b0a4-69fa-4636-d7cc-df35501f1284"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.85</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0:01:20</td>\n",
              "      <td>0:00:07</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.85         0.66           0.76       0:01:20         0:00:07"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "YMeY1Yq_V2Bq",
        "outputId": "841712e5-cb24-4845-d566-9c5e04bde8e1"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5u0KsRVkV14B"
      },
      "source": [
        "## Performance on test set\n",
        "df3 = pd.read_csv(\"drive/MyDrive/covid-twitter-bert/data/finetune/originals/crowdbreaks/test.tsv\", delimiter='\\t', header=0, names=['id', 'label', 'sentence'])\n",
        "df3.loc[df3['label']==-1,'label']=2"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4XJRd9EWVK4",
        "outputId": "b5cee65a-9110-4383-aeed-277eba0dd849"
      },
      "source": [
        "df3['label'].value_counts()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    237\n",
              "1    225\n",
              "0    219\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2cumvgZWXrM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}