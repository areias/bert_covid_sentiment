{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_tutorials.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNFGLd+qIzDNOlfabJN18GH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7a9f2ea9f5944f1c817102476dadb521": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_35bda5d729bd4191b76b462894b395d5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cedd250dea84479d88d97014125e11cf",
              "IPY_MODEL_f3484d1b212141d185082655dd8466ed",
              "IPY_MODEL_98a0e5330947436abbe1c766becd9a51"
            ]
          }
        },
        "35bda5d729bd4191b76b462894b395d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cedd250dea84479d88d97014125e11cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ee37d360a0d9440aaaac3f2a34d2e458",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_337368e37dab4bf0931b3d152c05d5d6"
          }
        },
        "f3484d1b212141d185082655dd8466ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_119eff81a7bc422bbaa05c14a267c6f1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 62,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 62,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2504886f03574adc8aadfa22db612743"
          }
        },
        "98a0e5330947436abbe1c766becd9a51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_78a349b9ac8f4896baf2e5ea3e4d6ef6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 62.0/62.0 [00:00&lt;00:00, 2.29kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ca962f6eb69a45e398f787b730b173b4"
          }
        },
        "ee37d360a0d9440aaaac3f2a34d2e458": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "337368e37dab4bf0931b3d152c05d5d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "119eff81a7bc422bbaa05c14a267c6f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2504886f03574adc8aadfa22db612743": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "78a349b9ac8f4896baf2e5ea3e4d6ef6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ca962f6eb69a45e398f787b730b173b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f8879561123c49ad806978b770a6071d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e8b1ab4605d14cf88303b62c403d8837",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_123b0c42d84e48a0adc7bab5d32c3182",
              "IPY_MODEL_1539325dcfef4fdb9f74ab306458b22f",
              "IPY_MODEL_a475449285b848f0ad6fc88c079b67db"
            ]
          }
        },
        "e8b1ab4605d14cf88303b62c403d8837": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "123b0c42d84e48a0adc7bab5d32c3182": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f25e33f7feb64cb99dfc9e441bbc5039",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_db78eea7bebb4f7c882ecca0c1e3a659"
          }
        },
        "1539325dcfef4fdb9f74ab306458b22f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e17f567616c640d9807ff77d6f5e8a54",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 421,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 421,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f526b2369e1340bb8fea05313a632007"
          }
        },
        "a475449285b848f0ad6fc88c079b67db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_63f8afa9ea6042a9977a1206647cbc83",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 421/421 [00:00&lt;00:00, 17.4kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ec6faff373a14508b26c631a211123e6"
          }
        },
        "f25e33f7feb64cb99dfc9e441bbc5039": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "db78eea7bebb4f7c882ecca0c1e3a659": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e17f567616c640d9807ff77d6f5e8a54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f526b2369e1340bb8fea05313a632007": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "63f8afa9ea6042a9977a1206647cbc83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ec6faff373a14508b26c631a211123e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c416c6f45853448ea01369096721852c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0035934e24054ce28de9bb7fcf44318e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b3b8c4e44ec94bae92d74ae20b16d8a1",
              "IPY_MODEL_963a0d977f814def9b32ce8b6725c272",
              "IPY_MODEL_13118043b5a64227aa77064221edb0ea"
            ]
          }
        },
        "0035934e24054ce28de9bb7fcf44318e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b3b8c4e44ec94bae92d74ae20b16d8a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ff1ea32e682b423798d968e759196b0d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_19b161296baa48759279ba1cdcbd6a2e"
          }
        },
        "963a0d977f814def9b32ce8b6725c272": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4c9358320fa34e9f81ae5830148f0e86",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fc565cbc5f2e4ccd80a7d4aaffe9578f"
          }
        },
        "13118043b5a64227aa77064221edb0ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0492b574e2c848f7ba7ee3702e6695e8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 226k/226k [00:00&lt;00:00, 891kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e4ce94ffe0bb439f8f00b6823b049632"
          }
        },
        "ff1ea32e682b423798d968e759196b0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "19b161296baa48759279ba1cdcbd6a2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4c9358320fa34e9f81ae5830148f0e86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fc565cbc5f2e4ccd80a7d4aaffe9578f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0492b574e2c848f7ba7ee3702e6695e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e4ce94ffe0bb439f8f00b6823b049632": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2ba7cd370524488e904bf17408068e76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a968372187d6438a9ef1e5ef26957cbd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2d0d9337ebda40518a35d781f9ad8272",
              "IPY_MODEL_8786a1cbebf0477da5eea870bb684a7c",
              "IPY_MODEL_934220ec49f74deca8364879b9d98604"
            ]
          }
        },
        "a968372187d6438a9ef1e5ef26957cbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2d0d9337ebda40518a35d781f9ad8272": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3e21432d7617499ea29b513f9ccd3fe6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cdb47e075e7349d8b872d3cbcf55567a"
          }
        },
        "8786a1cbebf0477da5eea870bb684a7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3b013f5812fb42a89fa552077508bfb8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 112,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 112,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_634a04d04d7c41ec8d8668afb55fc194"
          }
        },
        "934220ec49f74deca8364879b9d98604": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_258baa903526445791b7356eafc6a6b4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 112/112 [00:00&lt;00:00, 4.49kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f530cb360e73467eb73463c02ccc426d"
          }
        },
        "3e21432d7617499ea29b513f9ccd3fe6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cdb47e075e7349d8b872d3cbcf55567a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3b013f5812fb42a89fa552077508bfb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "634a04d04d7c41ec8d8668afb55fc194": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "258baa903526445791b7356eafc6a6b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f530cb360e73467eb73463c02ccc426d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "16e3119b45ce4f87bf5e7af9a745d62a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_14c483648ee147a6b70b5957adb6c5f2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ceaf5979716544eea19389852cb8fa55",
              "IPY_MODEL_58716c8524564ceaa3f4b025667b7fd6",
              "IPY_MODEL_1fbf2176ec4846e490d22ca9dd4b7f91"
            ]
          }
        },
        "14c483648ee147a6b70b5957adb6c5f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ceaf5979716544eea19389852cb8fa55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1cdf0d4271e941fa9c95b7a97576604f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b4c398b44c104adf8359312399e653aa"
          }
        },
        "58716c8524564ceaa3f4b025667b7fd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9de9667844304f79934a0c5a3d39b167",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1345068539,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1345068539,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f24d9e99b5304ce89b3663c6375f6b35"
          }
        },
        "1fbf2176ec4846e490d22ca9dd4b7f91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2896b145c18d4730913fc84cb5cc9293",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.25G/1.25G [00:22&lt;00:00, 60.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_25715a9babcf44e28cbfe03004ed70b2"
          }
        },
        "1cdf0d4271e941fa9c95b7a97576604f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b4c398b44c104adf8359312399e653aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9de9667844304f79934a0c5a3d39b167": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f24d9e99b5304ce89b3663c6375f6b35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2896b145c18d4730913fc84cb5cc9293": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "25715a9babcf44e28cbfe03004ed70b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "586a6c603b86434f9ed6eea3525f1f5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c7bfdea8715b42f6af75006fe0e94ef2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_da274e51284c46f6a821e9786befa444",
              "IPY_MODEL_24376e15d6dc4214aee7f057cbef5809",
              "IPY_MODEL_8a2c207e7bed4b5886ff827d769d2110"
            ]
          }
        },
        "c7bfdea8715b42f6af75006fe0e94ef2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "da274e51284c46f6a821e9786befa444": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_37c44222573c473d8590d3106cb2d109",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_af4c59f74c0649dc9d88cde63cb2bb0f"
          }
        },
        "24376e15d6dc4214aee7f057cbef5809": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_91ab071374f2427bb5b2382597e1a3ac",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 62,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 62,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_54f55e680b554e22bbd8d51273747a68"
          }
        },
        "8a2c207e7bed4b5886ff827d769d2110": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_55f5a2ac4628403aaac968cdc4c754c9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 62.0/62.0 [00:00&lt;00:00, 1.93kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1aee9cd2512644ac859ac23709af1c4d"
          }
        },
        "37c44222573c473d8590d3106cb2d109": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "af4c59f74c0649dc9d88cde63cb2bb0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "91ab071374f2427bb5b2382597e1a3ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "54f55e680b554e22bbd8d51273747a68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "55f5a2ac4628403aaac968cdc4c754c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1aee9cd2512644ac859ac23709af1c4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "73d74be2a6f649f3b3ff12253a85dd75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_183ec665162240ad9f72263a15f6186c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1f4e5b5411ad4d01a129a21b2486f3ae",
              "IPY_MODEL_7a90d565f9c046fc9bc265eda6664193",
              "IPY_MODEL_67465051fc704058ab38bfd431e2a192"
            ]
          }
        },
        "183ec665162240ad9f72263a15f6186c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1f4e5b5411ad4d01a129a21b2486f3ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_881d3cbc510242a98632784784b35c02",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c62c9d5ea90748408d50df94132e4387"
          }
        },
        "7a90d565f9c046fc9bc265eda6664193": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8c81f28f97a34b9aa69c758b0ff7f2ce",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 421,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 421,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f6ab4c40143b4198a7988c84884ba50a"
          }
        },
        "67465051fc704058ab38bfd431e2a192": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1997ecb0ecd94480a757e91c9614dfa3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 421/421 [00:00&lt;00:00, 12.8kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e8fa9b690c8747039cd8e673baea0435"
          }
        },
        "881d3cbc510242a98632784784b35c02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c62c9d5ea90748408d50df94132e4387": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8c81f28f97a34b9aa69c758b0ff7f2ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f6ab4c40143b4198a7988c84884ba50a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1997ecb0ecd94480a757e91c9614dfa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e8fa9b690c8747039cd8e673baea0435": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3538607d8ecb42fb8eca5162be3c6d0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9c46c25a3e16400aacf62e7237b7bd10",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d2b1754986ee42b0aa3bff70bdf2f342",
              "IPY_MODEL_922a33ae2d86467888c416a958e917d0",
              "IPY_MODEL_4eec8c6cf8ab4b32b3bad40c2267a0c9"
            ]
          }
        },
        "9c46c25a3e16400aacf62e7237b7bd10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d2b1754986ee42b0aa3bff70bdf2f342": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c0261d8fb5bf4d28ae3a7f366505aaad",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_72dd60eec15b42f28cbc7078d0649495"
          }
        },
        "922a33ae2d86467888c416a958e917d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0dbc675437c148c9b491a5cd73d9d2a8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2e9df63f0ca8442c9b6a7efd4b5573cd"
          }
        },
        "4eec8c6cf8ab4b32b3bad40c2267a0c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d9057ee5952849acb086834f2970b76c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 226k/226k [00:00&lt;00:00, 2.03MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e85588cb398b42cab82323ebd580bfa8"
          }
        },
        "c0261d8fb5bf4d28ae3a7f366505aaad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "72dd60eec15b42f28cbc7078d0649495": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0dbc675437c148c9b491a5cd73d9d2a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2e9df63f0ca8442c9b6a7efd4b5573cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d9057ee5952849acb086834f2970b76c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e85588cb398b42cab82323ebd580bfa8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "07537ac5ad0f46ae97ebed023b1ac7ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bf40c3db5ea14626b635b573d82c465b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3d904236d3304db49fa0ea707cf47cd4",
              "IPY_MODEL_41b0de6e9156499a8fddff85fce0a126",
              "IPY_MODEL_73265974f5d94c3bb4d70fa9dfcadd27"
            ]
          }
        },
        "bf40c3db5ea14626b635b573d82c465b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3d904236d3304db49fa0ea707cf47cd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7bbd2f535b8d4f319e11e10ecd4d1747",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ddd2ce97589d4a13a6bff6e48ab70e8d"
          }
        },
        "41b0de6e9156499a8fddff85fce0a126": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8774baf30b7546c48bc9527e4c5cb72c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 112,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 112,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_258c5a16e6344198aeb05eeb1e45ae43"
          }
        },
        "73265974f5d94c3bb4d70fa9dfcadd27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4093e33adf9d4ee4b0f20edc0f8275ed",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 112/112 [00:00&lt;00:00, 3.54kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_632077d8c13d4a9899e0171a1021c1bd"
          }
        },
        "7bbd2f535b8d4f319e11e10ecd4d1747": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ddd2ce97589d4a13a6bff6e48ab70e8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8774baf30b7546c48bc9527e4c5cb72c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "258c5a16e6344198aeb05eeb1e45ae43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4093e33adf9d4ee4b0f20edc0f8275ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "632077d8c13d4a9899e0171a1021c1bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5ac3444c5c8d45ce98b36478b5eda5f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_007fdcfb04324a8f9d90774630aade21",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0c8ce004315944a39d784fdc8ea02fdc",
              "IPY_MODEL_49b95d20386742e2a87d06c34eab1f19",
              "IPY_MODEL_d1eaf7ec92ba408395e77e024d455e27"
            ]
          }
        },
        "007fdcfb04324a8f9d90774630aade21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0c8ce004315944a39d784fdc8ea02fdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d19471b5950542bf850868607a3d9b26",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3401bddabe3f4dfd9dda7f4ff5dc6d61"
          }
        },
        "49b95d20386742e2a87d06c34eab1f19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b966e01d246346a996428654c1531938",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1345068539,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1345068539,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_67420fbffe3d4890bbade1f35f7190bc"
          }
        },
        "d1eaf7ec92ba408395e77e024d455e27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4d47f6677a6e49048bfe6d54f8186c48",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.25G/1.25G [00:36&lt;00:00, 35.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bdb1f336c9824460b43ad4812aeb59ef"
          }
        },
        "d19471b5950542bf850868607a3d9b26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3401bddabe3f4dfd9dda7f4ff5dc6d61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b966e01d246346a996428654c1531938": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "67420fbffe3d4890bbade1f35f7190bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4d47f6677a6e49048bfe6d54f8186c48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bdb1f336c9824460b43ad4812aeb59ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/areias/bert_covid_sentiment/blob/main/bert_tutorials.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bNzcqBKwX5S",
        "outputId": "2390b3e7-8784-4c49-e649-45c108c5b58c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65oksFt0urfB"
      },
      "source": [
        "https://www.tensorflow.org/text/tutorials/fine_tune_bert\n",
        "\n",
        "https://skimai.com/fine-tuning-bert-for-sentiment-analysis/\n",
        "\n",
        "http://mccormickml.com/2019/07/22/BERT-fine-tuning/\n",
        "\n",
        "https://www.thepythoncode.com/article/finetuning-bert-using-huggingface-transformers-python\n",
        "\n",
        "https://colab.research.google.com/github/digitalepidemiologylab/covid-twitter-bert/blob/master/CT_BERT_Huggingface_(GPU_training).ipynb\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6Me4R7VvWU6"
      },
      "source": [
        "## http://mccormickml.com/2019/07/22/BERT-fine-tuning/ 22 Jul 2019, Revised on 3/20/20"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsa9GKKdu_Mg",
        "outputId": "1fd96f29-312f-4880-dc45-0cd0e1faf636"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPLfMB-rvUZZ",
        "outputId": "433ff768-4ed9-407c-bb93-87124d5b1ad6"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNLxGXx8vpEo",
        "outputId": "9cf28787-fc83-4743-a230-e5b0db688a2a"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 7.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 78.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 69.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.1.2-py3-none-any.whl (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 9.1 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 69.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.1.2 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.12.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-Mqqci-evqe"
      },
      "source": [
        "## Load train data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uc833ZYCevnK"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaqM05qpv0eY"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"drive/MyDrive/covid-twitter-bert/data/finetune/originals/crowdbreaks/train.tsv\", delimiter='\\t', header=0, names=['id', 'label', 'sentence'])\n"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwFCHE7cTp0C",
        "outputId": "0a92a603-6e86-45e9-836b-4b3a2e164c49"
      },
      "source": [
        "df['label'].value_counts()"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 0    686\n",
              "-1    678\n",
              " 1    677\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIiNk_AiTwQx"
      },
      "source": [
        "df.loc[df['label']==-1,'label']=2"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rm7WtcvQT7Cy",
        "outputId": "5f6537ba-c0c3-4211-dd93-2b59ea4b3921"
      },
      "source": [
        "df['label'].value_counts()"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    686\n",
              "2    678\n",
              "1    677\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "VjKLan4hxNsx",
        "outputId": "4d726e12-972e-4274-c222-6921a647eaae"
      },
      "source": [
        "df.sample(10)"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1316</th>\n",
              "      <td>486569831039107008</td>\n",
              "      <td>0</td>\n",
              "      <td>@ALILOVESCK @mamajo76 @carolinaava2 @GabrieLyn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1000</th>\n",
              "      <td>446589281638056000</td>\n",
              "      <td>2</td>\n",
              "      <td>IDIOT \"@peoplemag: Kristin Cavallari defends h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1068</th>\n",
              "      <td>475720024158908032</td>\n",
              "      <td>2</td>\n",
              "      <td>Prayer is the immunity system of the body of C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1968</th>\n",
              "      <td>563753514409545984</td>\n",
              "      <td>2</td>\n",
              "      <td>“@timothycsimons: A handy guide on how vaccine...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>529</th>\n",
              "      <td>563557576114060992</td>\n",
              "      <td>1</td>\n",
              "      <td>@mattadore @paulawagnon let's look at this dif...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2003</th>\n",
              "      <td>520637371545838016</td>\n",
              "      <td>2</td>\n",
              "      <td>http://t.co/3yIs0CTqPU @RonanFarrow outbreak l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>414</th>\n",
              "      <td>519279889241752000</td>\n",
              "      <td>2</td>\n",
              "      <td>@jwyllys If your kid is vaccinated, why are yo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>982</th>\n",
              "      <td>43064217154236400</td>\n",
              "      <td>0</td>\n",
              "      <td>Should all Children in Daycare be Vaccinated A...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416</th>\n",
              "      <td>577603222019293056</td>\n",
              "      <td>0</td>\n",
              "      <td>can I please go to school in LA where people w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1471</th>\n",
              "      <td>551144160028537024</td>\n",
              "      <td>2</td>\n",
              "      <td>May child was dx 6/15/04 the CDC already knew ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      id  ...                                           sentence\n",
              "1316  486569831039107008  ...  @ALILOVESCK @mamajo76 @carolinaava2 @GabrieLyn...\n",
              "1000  446589281638056000  ...  IDIOT \"@peoplemag: Kristin Cavallari defends h...\n",
              "1068  475720024158908032  ...  Prayer is the immunity system of the body of C...\n",
              "1968  563753514409545984  ...  “@timothycsimons: A handy guide on how vaccine...\n",
              "529   563557576114060992  ...  @mattadore @paulawagnon let's look at this dif...\n",
              "2003  520637371545838016  ...  http://t.co/3yIs0CTqPU @RonanFarrow outbreak l...\n",
              "414   519279889241752000  ...  @jwyllys If your kid is vaccinated, why are yo...\n",
              "982    43064217154236400  ...  Should all Children in Daycare be Vaccinated A...\n",
              "416   577603222019293056  ...  can I please go to school in LA where people w...\n",
              "1471  551144160028537024  ...  May child was dx 6/15/04 the CDC already knew ...\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xWkElDJy8Dc"
      },
      "source": [
        "## Pre-processing Tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzKmqk1py5GD"
      },
      "source": [
        "import sys\n",
        "sys.path.append('drive/MyDrive/covid-twitter-bert')\n",
        "sys.path.append('drive/MyDrive/covid-twitter-bert/tensorflow_models')\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bT0n2mAwzxi1",
        "outputId": "227e13d9-e01e-4677-b300-060f91e831c5"
      },
      "source": [
        "!pip install emoji"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emoji\n",
            "  Downloading emoji-1.6.1.tar.gz (170 kB)\n",
            "\u001b[?25l\r\u001b[K     |██                              | 10 kB 35.3 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 20 kB 38.5 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 30 kB 21.7 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 40 kB 18.6 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 51 kB 10.3 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 61 kB 10.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 71 kB 10.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 81 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 92 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 102 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 112 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 122 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 133 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 143 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 153 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 163 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 170 kB 9.8 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.6.1-py3-none-any.whl size=169314 sha256=975b17bfd52e8892937f154c324698db0c5cf8addf4a8967018828c581c40b5e\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/5f/d3/03d313ddb3c2a1a427bb4690f1621eea60fe6f2a30cc95940f\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-1.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRihfV5_z3lu",
        "outputId": "122f63e8-d7c1-473c-c524-20a39f86e5bf"
      },
      "source": [
        "!pip install unidecode"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.2-py3-none-any.whl (235 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▍                              | 10 kB 22.9 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 20 kB 30.2 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 30 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 40 kB 17.2 MB/s eta 0:00:01\r\u001b[K     |███████                         | 51 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 61 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 71 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 81 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 92 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 102 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 112 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 122 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 133 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 143 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 153 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 163 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 174 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 184 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 194 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 204 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 215 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 225 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 235 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 235 kB 8.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAHi3mt-z-I_",
        "outputId": "f6f4bacd-8332-442a-f1fa-9d56e3c1cdda"
      },
      "source": [
        "!pip install spacy==3"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting spacy==3\n",
            "  Downloading spacy-3.0.0-cp37-cp37m-manylinux2014_x86_64.whl (12.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.7 MB 7.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy==3) (2.11.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==3) (2.0.6)\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.0\n",
            "  Downloading spacy_legacy-3.0.8-py2.py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==3) (3.0.6)\n",
            "Collecting typer<0.4.0,>=0.3.0\n",
            "  Downloading typer-0.3.2-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3) (21.3)\n",
            "Collecting srsly<3.0.0,>=2.4.0\n",
            "  Downloading srsly-2.4.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (451 kB)\n",
            "\u001b[K     |████████████████████████████████| 451 kB 81.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy==3) (3.10.0.2)\n",
            "Collecting thinc<8.1.0,>=8.0.0\n",
            "  Downloading thinc-8.0.13-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (628 kB)\n",
            "\u001b[K     |████████████████████████████████| 628 kB 83.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3) (1.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy==3) (0.8.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from spacy==3) (4.8.2)\n",
            "Collecting pathy\n",
            "  Downloading pathy-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.8 MB/s \n",
            "\u001b[?25hCollecting catalogue<2.1.0,>=2.0.1\n",
            "  Downloading catalogue-2.0.6-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3) (4.62.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy==3) (57.4.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3) (0.4.1)\n",
            "Collecting pydantic<1.8.0,>=1.7.1\n",
            "  Downloading pydantic-1.7.4-cp37-cp37m-manylinux2014_x86_64.whl (9.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.1 MB 28.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.1->spacy==3) (3.6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy==3) (3.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3) (2.10)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy==3) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy==3) (2.0.1)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy->spacy==3) (5.2.1)\n",
            "Installing collected packages: catalogue, typer, srsly, pydantic, thinc, spacy-legacy, pathy, spacy\n",
            "  Attempting uninstall: catalogue\n",
            "    Found existing installation: catalogue 1.0.0\n",
            "    Uninstalling catalogue-1.0.0:\n",
            "      Successfully uninstalled catalogue-1.0.0\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 1.0.5\n",
            "    Uninstalling srsly-1.0.5:\n",
            "      Successfully uninstalled srsly-1.0.5\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "Successfully installed catalogue-2.0.6 pathy-0.6.1 pydantic-1.7.4 spacy-3.0.0 spacy-legacy-3.0.8 srsly-2.4.2 thinc-8.0.13 typer-0.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtE1WcY6znBL"
      },
      "source": [
        "from utils.preprocess import preprocess_bert"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ck8SbYD0Qqz",
        "outputId": "22491e4f-a84c-4f4c-cf53-94574919e85d"
      },
      "source": [
        "from collections import namedtuple\n",
        "arguments = namedtuple('arguments', ['run_prefix','finetune_datasets','model_class',\n",
        "                                     'max_seq_length', 'asciify_emojis','username_filler',\n",
        "                                    'url_filler', 'replace_multiple_usernames','replace_multiple_urls',\n",
        "                                      'remove_unicode_symbols','replace_usernames','replace_urls',\n",
        "                                     'standardize_punctuation','remove_accented_characters'])\n",
        "\n",
        "args = arguments(\"test_run\",[\"crowdbreaks\"],\"covid-twitter-bert-2\",\n",
        "                 96, True, \"twitteruser\", \n",
        "                 \"twitterurl\", True,True,\n",
        "                 True, True, True,\n",
        "                 True, True)\n",
        "args\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "arguments(run_prefix='test_run', finetune_datasets=['crowdbreaks'], model_class='covid-twitter-bert-2', max_seq_length=96, asciify_emojis=True, username_filler='twitteruser', url_filler='twitterurl', replace_multiple_usernames=True, replace_multiple_urls=True, remove_unicode_symbols=True, replace_usernames=True, replace_urls=True, standardize_punctuation=True, remove_accented_characters=True)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvgKvfbM1w8O"
      },
      "source": [
        "df['sentence'] = df['sentence'].apply(lambda x: preprocess_bert(x,args,do_lower_case=True))"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lcl3ByvV1Pae"
      },
      "source": [
        "#Let’s extract the sentences and labels of our training set as numpy ndarrays.\n",
        "\n",
        "# Get the lists of sentences and their labels.\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values\n"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9y7BzNKf1m87",
        "outputId": "c66a5a8b-7b70-4535-ba4a-b720c7c57a85"
      },
      "source": [
        "sentences[0]"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'arizona classrooms vulnerable to measles outbreak: the arizona department of health services looked at herd... twitterurl'"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHucOLrN2IMW",
        "outputId": "6d282675-bec6-483e-bbf2-60faa80c00ac"
      },
      "source": [
        "type(labels[0])"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.int64"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmdq4f38xt8C"
      },
      "source": [
        "## BERT Tokenizer\n",
        "\n",
        "To feed our text to BERT, it must be split into tokens, and then these tokens must be mapped to their index in the tokenizer vocabulary.\n",
        "\n",
        "The tokenization must be performed by the tokenizer included with BERT–the below cell will download this for us. We’ll be using the “uncased” version here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162,
          "referenced_widgets": [
            "7a9f2ea9f5944f1c817102476dadb521",
            "35bda5d729bd4191b76b462894b395d5",
            "cedd250dea84479d88d97014125e11cf",
            "f3484d1b212141d185082655dd8466ed",
            "98a0e5330947436abbe1c766becd9a51",
            "ee37d360a0d9440aaaac3f2a34d2e458",
            "337368e37dab4bf0931b3d152c05d5d6",
            "119eff81a7bc422bbaa05c14a267c6f1",
            "2504886f03574adc8aadfa22db612743",
            "78a349b9ac8f4896baf2e5ea3e4d6ef6",
            "ca962f6eb69a45e398f787b730b173b4",
            "f8879561123c49ad806978b770a6071d",
            "e8b1ab4605d14cf88303b62c403d8837",
            "123b0c42d84e48a0adc7bab5d32c3182",
            "1539325dcfef4fdb9f74ab306458b22f",
            "a475449285b848f0ad6fc88c079b67db",
            "f25e33f7feb64cb99dfc9e441bbc5039",
            "db78eea7bebb4f7c882ecca0c1e3a659",
            "e17f567616c640d9807ff77d6f5e8a54",
            "f526b2369e1340bb8fea05313a632007",
            "63f8afa9ea6042a9977a1206647cbc83",
            "ec6faff373a14508b26c631a211123e6",
            "c416c6f45853448ea01369096721852c",
            "0035934e24054ce28de9bb7fcf44318e",
            "b3b8c4e44ec94bae92d74ae20b16d8a1",
            "963a0d977f814def9b32ce8b6725c272",
            "13118043b5a64227aa77064221edb0ea",
            "ff1ea32e682b423798d968e759196b0d",
            "19b161296baa48759279ba1cdcbd6a2e",
            "4c9358320fa34e9f81ae5830148f0e86",
            "fc565cbc5f2e4ccd80a7d4aaffe9578f",
            "0492b574e2c848f7ba7ee3702e6695e8",
            "e4ce94ffe0bb439f8f00b6823b049632",
            "2ba7cd370524488e904bf17408068e76",
            "a968372187d6438a9ef1e5ef26957cbd",
            "2d0d9337ebda40518a35d781f9ad8272",
            "8786a1cbebf0477da5eea870bb684a7c",
            "934220ec49f74deca8364879b9d98604",
            "3e21432d7617499ea29b513f9ccd3fe6",
            "cdb47e075e7349d8b872d3cbcf55567a",
            "3b013f5812fb42a89fa552077508bfb8",
            "634a04d04d7c41ec8d8668afb55fc194",
            "258baa903526445791b7356eafc6a6b4",
            "f530cb360e73467eb73463c02ccc426d"
          ]
        },
        "id": "d2czgaHdxpOI",
        "outputId": "f6b66abd-1e79-4edf-b81a-2abc51cda938"
      },
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "model_name = 'digitalepidemiologylab/covid-twitter-bert-v2'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, do_lower_case=True)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7a9f2ea9f5944f1c817102476dadb521",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/62.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f8879561123c49ad806978b770a6071d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/421 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c416c6f45853448ea01369096721852c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2ba7cd370524488e904bf17408068e76",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MroUDOty2Hv",
        "outputId": "d8ca8e8c-b922-4bb9-9499-7a0e218ef4f2"
      },
      "source": [
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Original:  arizona classrooms vulnerable to measles outbreak: the arizona department of health services looked at herd... twitterurl\n",
            "Tokenized:  ['arizona', 'classrooms', 'vulnerable', 'to', 'me', '##as', '##les', 'outbreak', ':', 'the', 'arizona', 'department', 'of', 'health', 'services', 'looked', 'at', 'herd', '.', '.', '.', 'twitter', '##ur', '##l']\n",
            "Token IDs:  [5334, 12463, 8211, 2000, 2033, 3022, 4244, 8293, 1024, 1996, 5334, 2533, 1997, 2740, 2578, 2246, 2012, 14906, 1012, 1012, 1012, 10474, 3126, 2140]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsI_tXGz3YuJ"
      },
      "source": [
        "The above code left out a few required formatting steps:\n",
        "* Add special tokens to the start and end of each sentence.\n",
        "* Pad & truncate all sentences to a single constant length.\n",
        "* Explicitly differentiate real tokens from padding tokens with the “attention mask”.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dl6Anl_3hMH",
        "outputId": "bae9ff52-4a13-4fac-deb7-bb544f1c2cad"
      },
      "source": [
        "tokenizer.encode_plus(sentences[0],                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 96,           # Pad & truncate all sentences.\n",
        "                        padding= True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                      truncation=True,\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  101,  5334, 12463,  8211,  2000,  2033,  3022,  4244,  8293,  1024,\n",
              "          1996,  5334,  2533,  1997,  2740,  2578,  2246,  2012, 14906,  1012,\n",
              "          1012,  1012, 10474,  3126,  2140,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9LhhqFE35PU",
        "outputId": "da499ab2-239b-4205-c11b-3c8254797226"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 96,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt', \n",
        "                        truncation=True    # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8GiVyYP4niK"
      },
      "source": [
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLIpto5h4t0C"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "train_dataset = TensorDataset(input_ids, attention_masks, labels)\n"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyeIeypee6Pe"
      },
      "source": [
        "## Load validation data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXJX6WYy6OCg"
      },
      "source": [
        "# do all above for validation dataset\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df2 = pd.read_csv(\"drive/MyDrive/covid-twitter-bert/data/finetune/originals/crowdbreaks/dev.tsv\", delimiter='\\t', header=0, names=['id', 'label', 'sentence'])\n",
        "df2.loc[df2['label']==-1,'label']=2\n",
        "\n",
        "# pre-processes special characters\n",
        "df2['sentence'] = df2['sentence'].apply(lambda x: preprocess_bert(x,args,do_lower_case=True))"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "lKzOaXFp6rf-",
        "outputId": "028c8e35-2e97-41da-a14b-efe2941aebaf"
      },
      "source": [
        "df2.head()"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>522873565969150016</td>\n",
              "      <td>1</td>\n",
              "      <td>flu shot, got. #vaccinated #flushot #diseasepr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>371691166674451968</td>\n",
              "      <td>1</td>\n",
              "      <td>idiots. twitteruser : texas measles outbreak t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>70612980194226200</td>\n",
              "      <td>1</td>\n",
              "      <td>at the vet my baby is getting a vaccination aw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>562391001118289984</td>\n",
              "      <td>2</td>\n",
              "      <td>today in journalism my professor said friend's...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>239016379901177984</td>\n",
              "      <td>2</td>\n",
              "      <td>twitteruser and children getting vaccinated st...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   id  label                                           sentence\n",
              "0  522873565969150016      1  flu shot, got. #vaccinated #flushot #diseasepr...\n",
              "1  371691166674451968      1  idiots. twitteruser : texas measles outbreak t...\n",
              "2   70612980194226200      1  at the vet my baby is getting a vaccination aw...\n",
              "3  562391001118289984      2  today in journalism my professor said friend's...\n",
              "4  239016379901177984      2  twitteruser and children getting vaccinated st..."
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KudewtW-6sdR"
      },
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "test_sentences = df2.sentence.values\n",
        "test_labels = df2.label.values"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9D2C0d-697A",
        "outputId": "6ad82e47-8884-4307-acc5-a23c2df05388"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "test_input_ids = []\n",
        "test_attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in test_sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 96,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    test_input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    test_attention_masks.append(encoded_dict['attention_mask'])\n"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jO8BiGSJSq4W",
        "outputId": "c0d3feb8-20a6-4568-b3a8-8e4f8b9c4b96"
      },
      "source": [
        "test_labels[0].item()"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMOeOBCN7PaM"
      },
      "source": [
        "# Convert the lists into tensors.\n",
        "test_input_ids = torch.cat(test_input_ids, dim=0)\n",
        "test_attention_masks = torch.cat(test_attention_masks, dim=0)\n",
        "test_labels = torch.tensor(test_labels)\n"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9losOzcp7atF"
      },
      "source": [
        "val_dataset = TensorDataset(test_input_ids, test_attention_masks, test_labels)\n"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrtyu9wV7pLD"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxBpU1Bs71gB"
      },
      "source": [
        "## Fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "16e3119b45ce4f87bf5e7af9a745d62a",
            "14c483648ee147a6b70b5957adb6c5f2",
            "ceaf5979716544eea19389852cb8fa55",
            "58716c8524564ceaa3f4b025667b7fd6",
            "1fbf2176ec4846e490d22ca9dd4b7f91",
            "1cdf0d4271e941fa9c95b7a97576604f",
            "b4c398b44c104adf8359312399e653aa",
            "9de9667844304f79934a0c5a3d39b167",
            "f24d9e99b5304ce89b3663c6375f6b35",
            "2896b145c18d4730913fc84cb5cc9293",
            "25715a9babcf44e28cbfe03004ed70b2"
          ]
        },
        "id": "mmHtDn4X7zV5",
        "outputId": "144cf7e7-8098-4d62-dc80-993044ca508a"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(  \n",
        "    'digitalepidemiologylab/covid-twitter-bert-v2', # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 3, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        "     return_dict=False)\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "16e3119b45ce4f87bf5e7af9a745d62a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.25G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at digitalepidemiologylab/covid-twitter-bert-v2 were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at digitalepidemiologylab/covid-twitter-bert-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 1024)\n",
              "      (token_type_embeddings): Embedding(2, 1024)\n",
              "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (12): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (13): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (14): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (15): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (16): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (17): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (18): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (19): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (20): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (21): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (22): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (23): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=1024, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaXJyp7V8Q3q"
      },
      "source": [
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBvN8r5Q8U8i"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n"
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqUBzeqX8dmY"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XO7427a8nay"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dtoxpP0IP9B"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "bfFm5LZq8q9o",
        "outputId": "1fdfc8ce-0f4e-489c-9edf-ee6f9276c1ac"
      },
      "source": [
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        loss, logits = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            (loss, logits) = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-158-c75b6910a8d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m                              \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                              \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb_input_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                              labels=b_labels)\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;31m# Accumulate the training loss over all of the batches so that we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1537\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1538\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1539\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1540\u001b[0m         )\n\u001b[1;32m   1541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1004\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m         )\n\u001b[1;32m   1008\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    588\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m                 )\n\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m         layer_output = apply_chunking_to_forward(\n\u001b[0;32m--> 512\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m         )\n\u001b[1;32m    514\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2360\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 15.90 GiB total capacity; 14.66 GiB already allocated; 19.75 MiB free; 14.77 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "qDejhFUhR8I5",
        "outputId": "1cd87050-1dc9-46a6-d955-9f7a3c57f1ed"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-beaab40dc594>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Create a DataFrame from our training statistics.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdf_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_stats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Use the 'epoch' as the row index.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'training_stats' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMeY1Yq_V2Bq"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NE1BkmVZgvPZ"
      },
      "source": [
        "## Loading test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5u0KsRVkV14B"
      },
      "source": [
        "## Performance on test set\n",
        "df3 = pd.read_csv(\"drive/MyDrive/covid-twitter-bert/data/finetune/originals/crowdbreaks/test.tsv\", delimiter='\\t', header=0, names=['id', 'label', 'sentence'])\n",
        "df3.loc[df3['label']==-1,'label']=2\n",
        "# pre-processes special characters\n",
        "df3['sentence'] = df3['sentence'].apply(lambda x: preprocess_bert(x,args,do_lower_case=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4XJRd9EWVK4"
      },
      "source": [
        "df3['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2cumvgZWXrM"
      },
      "source": [
        "test_sentences = df3.sentence.values\n",
        "test_labels = df3.label.values\n",
        "\n",
        "test_input_ids = []\n",
        "test_attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in test_sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 96,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    test_input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    test_attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "batch_size=32\n",
        "\n",
        "input_ids = torch.cat(test_input_ids, dim=0)\n",
        "attention_masks = torch.cat(test_attention_masks, dim=0)\n",
        "labels = torch.tensor(test_labels)\n",
        "\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igvfT1qhceAi"
      },
      "source": [
        "## Prediction on test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaa8VSUIdlQC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpW1yPXyXt3v"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions.\n",
        "      result = model(b_input_ids, \n",
        "                     token_type_ids=None, \n",
        "                     attention_mask=b_input_mask,\n",
        "                     return_dict=True)\n",
        "\n",
        "  logits = result.logits\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjA9VyOTX1g_"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating F1 Score. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "  \n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  \n",
        "  # Calculate and store the coef for this batch.  \n",
        "  f1 = f1_score(true_labels[i], pred_labels_i, average=None)                \n",
        "  f1_set.append(f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8tyGdHvY_zR"
      },
      "source": [
        "len(f1_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8puCnvCZCJ0"
      },
      "source": [
        "f1_set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQwMcZEzZSx4"
      },
      "source": [
        "true_labels[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wl7wdJYBZV9c"
      },
      "source": [
        "predictions[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oV6pyByGZcN9"
      },
      "source": [
        "# Combine the results across all batches. \n",
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "# For each sample, pick the label (0 or 1) with the higher score.\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m57dVWbDbn-l"
      },
      "source": [
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fk6QM0hfboz1"
      },
      "source": [
        "# Calculate the f1 for each class\n",
        "f1 = f1_score(flat_true_labels, flat_predictions, average=None)\n",
        "\n",
        "print(f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTNxxVdneecV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGHWeyf_hsiJ"
      },
      "source": [
        "## Training on full dataset with best settings (batch_size=16 and two epochs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bYjpHW_cEBh"
      },
      "source": [
        "import pandas as pd \n",
        "df = pd.read_csv(\"drive/MyDrive/covid-twitter-bert/data/finetune/originals/crowdbreaks/train.tsv\", delimiter='\\t', header=0, names=['id', 'label', 'sentence'])\n",
        "df2 = pd.read_csv(\"drive/MyDrive/covid-twitter-bert/data/finetune/originals/crowdbreaks/dev.tsv\", delimiter='\\t', header=0, names=['id', 'label', 'sentence'])\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCu7PTRDjAF2"
      },
      "source": [
        "df=df.append(df2)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WoalktTWjBrg",
        "outputId": "8e0a08af-adcb-4fea-af8b-ecda911df66c"
      },
      "source": [
        "df['label'].value_counts()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 0    915\n",
              " 1    909\n",
              "-1    897\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wk9pAzjdjK_t"
      },
      "source": [
        "df.loc[df['label']==-1,'label']=2"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYuQo_QajSlw",
        "outputId": "bb3ce5a8-a38f-4509-e594-c6a0cac7e73a"
      },
      "source": [
        "df['label'].value_counts()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    915\n",
              "1    909\n",
              "2    897\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwjLLnWUjUek"
      },
      "source": [
        "df['sentence'] = df['sentence'].apply(lambda x: preprocess_bert(x,args,do_lower_case=True))\n",
        "\n",
        "# Get the lists of sentences and their labels.\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162,
          "referenced_widgets": [
            "586a6c603b86434f9ed6eea3525f1f5a",
            "c7bfdea8715b42f6af75006fe0e94ef2",
            "da274e51284c46f6a821e9786befa444",
            "24376e15d6dc4214aee7f057cbef5809",
            "8a2c207e7bed4b5886ff827d769d2110",
            "37c44222573c473d8590d3106cb2d109",
            "af4c59f74c0649dc9d88cde63cb2bb0f",
            "91ab071374f2427bb5b2382597e1a3ac",
            "54f55e680b554e22bbd8d51273747a68",
            "55f5a2ac4628403aaac968cdc4c754c9",
            "1aee9cd2512644ac859ac23709af1c4d",
            "73d74be2a6f649f3b3ff12253a85dd75",
            "183ec665162240ad9f72263a15f6186c",
            "1f4e5b5411ad4d01a129a21b2486f3ae",
            "7a90d565f9c046fc9bc265eda6664193",
            "67465051fc704058ab38bfd431e2a192",
            "881d3cbc510242a98632784784b35c02",
            "c62c9d5ea90748408d50df94132e4387",
            "8c81f28f97a34b9aa69c758b0ff7f2ce",
            "f6ab4c40143b4198a7988c84884ba50a",
            "1997ecb0ecd94480a757e91c9614dfa3",
            "e8fa9b690c8747039cd8e673baea0435",
            "3538607d8ecb42fb8eca5162be3c6d0f",
            "9c46c25a3e16400aacf62e7237b7bd10",
            "d2b1754986ee42b0aa3bff70bdf2f342",
            "922a33ae2d86467888c416a958e917d0",
            "4eec8c6cf8ab4b32b3bad40c2267a0c9",
            "c0261d8fb5bf4d28ae3a7f366505aaad",
            "72dd60eec15b42f28cbc7078d0649495",
            "0dbc675437c148c9b491a5cd73d9d2a8",
            "2e9df63f0ca8442c9b6a7efd4b5573cd",
            "d9057ee5952849acb086834f2970b76c",
            "e85588cb398b42cab82323ebd580bfa8",
            "07537ac5ad0f46ae97ebed023b1ac7ec",
            "bf40c3db5ea14626b635b573d82c465b",
            "3d904236d3304db49fa0ea707cf47cd4",
            "41b0de6e9156499a8fddff85fce0a126",
            "73265974f5d94c3bb4d70fa9dfcadd27",
            "7bbd2f535b8d4f319e11e10ecd4d1747",
            "ddd2ce97589d4a13a6bff6e48ab70e8d",
            "8774baf30b7546c48bc9527e4c5cb72c",
            "258c5a16e6344198aeb05eeb1e45ae43",
            "4093e33adf9d4ee4b0f20edc0f8275ed",
            "632077d8c13d4a9899e0171a1021c1bd"
          ]
        },
        "id": "elQrY2n5r-CU",
        "outputId": "297c09d5-fb8e-4264-edc4-d412c044430f"
      },
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "model_name = 'digitalepidemiologylab/covid-twitter-bert-v2'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, do_lower_case=True)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "586a6c603b86434f9ed6eea3525f1f5a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/62.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "73d74be2a6f649f3b3ff12253a85dd75",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/421 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3538607d8ecb42fb8eca5162be3c6d0f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "07537ac5ad0f46ae97ebed023b1ac7ec",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDZBL3yNjue3",
        "outputId": "1ce66525-4009-42f2-c84c-710aea0ab079"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 96,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqN4sc3KkjSO"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "dataloader = DataLoader(\n",
        "            dataset,  # The training samples.\n",
        "            sampler = RandomSampler(dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "5ac3444c5c8d45ce98b36478b5eda5f9",
            "007fdcfb04324a8f9d90774630aade21",
            "0c8ce004315944a39d784fdc8ea02fdc",
            "49b95d20386742e2a87d06c34eab1f19",
            "d1eaf7ec92ba408395e77e024d455e27",
            "d19471b5950542bf850868607a3d9b26",
            "3401bddabe3f4dfd9dda7f4ff5dc6d61",
            "b966e01d246346a996428654c1531938",
            "67420fbffe3d4890bbade1f35f7190bc",
            "4d47f6677a6e49048bfe6d54f8186c48",
            "bdb1f336c9824460b43ad4812aeb59ef"
          ]
        },
        "id": "mlB0N0OakyI6",
        "outputId": "b9c7cde4-f4ab-44cf-ada7-57bd98576398"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(  \n",
        "    'digitalepidemiologylab/covid-twitter-bert-v2', # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 3, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        "     return_dict=False)\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5ac3444c5c8d45ce98b36478b5eda5f9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.25G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at digitalepidemiologylab/covid-twitter-bert-v2 were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at digitalepidemiologylab/covid-twitter-bert-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 1024)\n",
              "      (token_type_embeddings): Embedding(2, 1024)\n",
              "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (12): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (13): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (14): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (15): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (16): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (17): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (18): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (19): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (20): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (21): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (22): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (23): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=1024, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUqD3nYawD5f"
      },
      "source": [
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHa_oQw6vrZA"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "epochs = 2\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPKpNqg-v-Rx"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQwfUs8lscaX"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4BOnLVmshdd"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GRnB628sve4",
        "outputId": "285db48b-5474-4ca2-a8fa-407334e7a684"
      },
      "source": [
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        loss, logits = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\"\"\"\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            (loss, logits) = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\"\"\"\n",
        "    # Record all statistics from this epoch.\n",
        "training_stats.append(\n",
        "    {\n",
        "        'epoch': epoch_i + 1,\n",
        "        'Training Loss': avg_train_loss,\n",
        "        #'Valid. Loss': avg_val_loss,\n",
        "        #'Valid. Accur.': avg_val_accuracy,\n",
        "        'Training Time': training_time,\n",
        "        #'Validation Time': validation_time\n",
        "    }\n",
        ")\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 2 ========\n",
            "Training...\n",
            "  Batch    40  of    171.    Elapsed: 0:00:21.\n",
            "  Batch    80  of    171.    Elapsed: 0:00:42.\n",
            "  Batch   120  of    171.    Elapsed: 0:01:04.\n",
            "  Batch   160  of    171.    Elapsed: 0:01:25.\n",
            "\n",
            "  Average training loss: 0.91\n",
            "  Training epcoh took: 0:01:30\n",
            "\n",
            "======== Epoch 2 / 2 ========\n",
            "Training...\n",
            "  Batch    40  of    171.    Elapsed: 0:00:21.\n",
            "  Batch    80  of    171.    Elapsed: 0:00:42.\n",
            "  Batch   120  of    171.    Elapsed: 0:01:03.\n",
            "  Batch   160  of    171.    Elapsed: 0:01:25.\n",
            "\n",
            "  Average training loss: 0.55\n",
            "  Training epcoh took: 0:01:30\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:06:06 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEmbzmtAt-eA",
        "outputId": "4ddfc8a5-62e3-4c87-d8ba-fdaaef205dce"
      },
      "source": [
        "import os\n",
        "\n",
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = 'drive/MyDrive/covid-twitter-bert/model_save/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to drive/MyDrive/covid-twitter-bert/model_save/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ts9I4AqQsVhe"
      },
      "source": [
        "# Test set stats for final trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8EgezpEuqP-"
      },
      "source": [
        "## Performance on test set\n",
        "df3 = pd.read_csv(\"drive/MyDrive/covid-twitter-bert/data/finetune/originals/crowdbreaks/test.tsv\", delimiter='\\t', header=0, names=['id', 'label', 'sentence'])\n",
        "df3.loc[df3['label']==-1,'label']=2\n",
        "# pre-processes special characters\n",
        "df3['sentence'] = df3['sentence'].apply(lambda x: preprocess_bert(x,args,do_lower_case=True))"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gApoifxxu2zc",
        "outputId": "d4380495-f206-4d5d-dcb9-afeb3ef56594"
      },
      "source": [
        "df3['label'].value_counts()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    237\n",
              "1    225\n",
              "0    219\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgYAe2UEu45o",
        "outputId": "bb21a421-a6f7-4d47-a00e-496bbfc954ec"
      },
      "source": [
        "test_sentences = df3.sentence.values\n",
        "test_labels = df3.label.values\n",
        "\n",
        "test_input_ids = []\n",
        "test_attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in test_sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 96,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    test_input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    test_attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "batch_size=32\n",
        "\n",
        "input_ids = torch.cat(test_input_ids, dim=0)\n",
        "attention_masks = torch.cat(test_attention_masks, dim=0)\n",
        "labels = torch.tensor(test_labels)\n",
        "\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VYnHTBUu_5F",
        "outputId": "1f00841d-de75-4705-a97f-9c0db0988067"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions.\n",
        "      result = model(b_input_ids, \n",
        "                     token_type_ids=None, \n",
        "                     attention_mask=b_input_mask,\n",
        "                     return_dict=True)\n",
        "\n",
        "  logits = result.logits\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for 681 test sentences...\n",
            "    DONE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKG28lBavFn-",
        "outputId": "148afb00-9b77-497f-aea2-165e23ae4dce"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating F1 Score. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "  \n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  \n",
        "  # Calculate and store the coef for this batch.  \n",
        "  f1 = f1_score(true_labels[i], pred_labels_i, average=None)                \n",
        "  f1_set.append(f1)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating F1 Score. Coef. for each batch...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFbzWf-BvS70"
      },
      "source": [
        "# Combine the results across all batches. \n",
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "# For each sample, pick the label (0 or 1) with the higher score.\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53PX9JDRveDT",
        "outputId": "cb499ee5-01c2-401d-d88c-ede8b69fe9e6"
      },
      "source": [
        "# Calculate the f1 for each class\n",
        "f1 = f1_score(flat_true_labels, flat_predictions, average=None,labels=[2,0,1]) # 2 is negtive, 0 is neutral, 1 is positive\n",
        "\n",
        "print(f1)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.78207739 0.77002584 0.7107438 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJx-8TEhCMxi"
      },
      "source": [
        "## Training on full dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuMl2P3Rwm_K"
      },
      "source": [
        "## Training on full dataset"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YTwio-0CMBD"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"drive/MyDrive/train.csv\")\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "7QLvrPd5DEqw",
        "outputId": "35ab06e0-415d-4d4e-802e-3c07cb9c3fba"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>created_at</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>564984221203431424</td>\n",
              "      <td>Disneyland is spreading measles 121 cases in 1...</td>\n",
              "      <td>1</td>\n",
              "      <td>2015-02-10 03:08:29+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>564984308096438272</td>\n",
              "      <td>California measles outbreak: 123 cases, latest...</td>\n",
              "      <td>0</td>\n",
              "      <td>2015-02-10 03:08:50+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>564985199700611072</td>\n",
              "      <td>Why isn't the news talking about how measles w...</td>\n",
              "      <td>1</td>\n",
              "      <td>2015-02-10 03:12:23+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>564985637321703425</td>\n",
              "      <td>No link to autism from vaccines, says expert: ...</td>\n",
              "      <td>1</td>\n",
              "      <td>2015-02-10 03:14:07+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>564986465822580736</td>\n",
              "      <td>We need a @VaccinatorX assembly at my kids' sc...</td>\n",
              "      <td>1</td>\n",
              "      <td>2015-02-10 03:17:25+00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   id  ...                 created_at\n",
              "0  564984221203431424  ...  2015-02-10 03:08:29+00:00\n",
              "1  564984308096438272  ...  2015-02-10 03:08:50+00:00\n",
              "2  564985199700611072  ...  2015-02-10 03:12:23+00:00\n",
              "3  564985637321703425  ...  2015-02-10 03:14:07+00:00\n",
              "4  564986465822580736  ...  2015-02-10 03:17:25+00:00\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4KqFLu_DFye",
        "outputId": "e098b403-808e-4ab6-975f-5c8314ace32f"
      },
      "source": [
        "len(df)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9000"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlfVT_8LDIAD",
        "outputId": "a3600e01-003e-454f-8175-6607b78037e9"
      },
      "source": [
        "df['label'].value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 1    4037\n",
              " 0    4029\n",
              "-1     934\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGP14InTDLSi"
      },
      "source": [
        "df.loc[df['label']==-1,'label']=2"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vfxeOuMEH-4",
        "outputId": "7c1127da-23aa-4fa8-d6a8-891ddfc872a3"
      },
      "source": [
        "df['label'].value_counts()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    4037\n",
              "0    4029\n",
              "2     934\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1US6bgVREJwS"
      },
      "source": [
        "import numpy as np\n",
        "\"\"\"\n",
        "    60% - train set,\n",
        "    20% - dev/validation set,\n",
        "    20% - test set\"\"\"\n",
        "\n",
        "train, dev, test = np.split(df.sample(frac=1, random_state=42), \n",
        "                       [int(.6*len(df)), int(.8*len(df))])\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrJqH02gEcfu",
        "outputId": "aa8caf18-afa2-426d-87e2-e75b4cd4cb86"
      },
      "source": [
        "train['label'].value_counts()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2421\n",
              "1    2409\n",
              "2     570\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8hhOHRnEgj0",
        "outputId": "ddb000e4-a13c-40de-ea4c-c647bbec6aa6"
      },
      "source": [
        "dev['label'].value_counts()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    795\n",
              "1    794\n",
              "2    211\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gf0P4VNBEjtC",
        "outputId": "fb9c0fb2-ec8e-4d54-9c1f-97f33af7c193"
      },
      "source": [
        "test['label'].value_counts()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    834\n",
              "0    813\n",
              "2    153\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7fX7X8cFWp8"
      },
      "source": [
        "train=train.loc[:,['id','label','text']]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJUqwQWYFTco"
      },
      "source": [
        "train.columns=['id','label','sentence']"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6x7y7tvFGJ8"
      },
      "source": [
        "train['sentence'] = train['sentence'].apply(lambda x: preprocess_bert(x,args,do_lower_case=True))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "J-Ycu_N4FJsQ",
        "outputId": "db27dc5f-a583-411d-bf34-2c563707469e"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7940</th>\n",
              "      <td>111791385274892289</td>\n",
              "      <td>1</td>\n",
              "      <td>i do not understand why any sane adult living ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1162</th>\n",
              "      <td>630008333378818048</td>\n",
              "      <td>1</td>\n",
              "      <td>aids n : here's how the hpv vaccine can help c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>582</th>\n",
              "      <td>561022351291060224</td>\n",
              "      <td>1</td>\n",
              "      <td>twitteruser yeah, this is terrifying when you ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4081</th>\n",
              "      <td>570138703986708482</td>\n",
              "      <td>1</td>\n",
              "      <td>beautifully written! twitteruser heartbreaking...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8412</th>\n",
              "      <td>662997344284098561</td>\n",
              "      <td>1</td>\n",
              "      <td>health officials urge vaccinations after flu h...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      id  ...                                           sentence\n",
              "7940  111791385274892289  ...  i do not understand why any sane adult living ...\n",
              "1162  630008333378818048  ...  aids n : here's how the hpv vaccine can help c...\n",
              "582   561022351291060224  ...  twitteruser yeah, this is terrifying when you ...\n",
              "4081  570138703986708482  ...  beautifully written! twitteruser heartbreaking...\n",
              "8412  662997344284098561  ...  health officials urge vaccinations after flu h...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIf2PajUFlms"
      },
      "source": [
        "sentences = train.sentence.values\n",
        "labels = train.label.values\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLPVemzeGLjM",
        "outputId": "f8bf4585-6708-4c28-ac19-500bd2b5677c"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 96,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt', \n",
        "                        truncation=True    # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGiKNKHgGRJb"
      },
      "source": [
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcNfkK7SGV47"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split        \n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "train_dataset = TensorDataset(input_ids, attention_masks, labels)\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "At6w5nYgGXxw",
        "outputId": "456fdc8e-b702-423f-a6e2-378bf0b9984d"
      },
      "source": [
        "len(train_dataset)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5400"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZYQm017GsGN"
      },
      "source": [
        "dev.loc[dev['label']==-1,'label']=2\n",
        "dev=dev.loc[:,['id','label','text']]\n",
        "\n",
        "dev.columns=['id','label','sentence']\n",
        "# pre-processes special characters\n",
        "dev['sentence'] = dev['sentence'].apply(lambda x: preprocess_bert(x,args,do_lower_case=True))"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MKDu5cpG6ie"
      },
      "source": [
        "test_sentences = dev.sentence.values\n",
        "test_labels = dev.label.values\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkaBW0R-HHdc",
        "outputId": "ffee6966-7ba5-4599-8cfc-8921024ce2ed"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "test_input_ids = []\n",
        "test_attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in test_sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 96,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',\n",
        "                        truncation=True,     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    test_input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    test_attention_masks.append(encoded_dict['attention_mask'])\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZ6xKLgGHZJ1"
      },
      "source": [
        "# Convert the lists into tensors.\n",
        "test_input_ids = torch.cat(test_input_ids, dim=0)\n",
        "test_attention_masks = torch.cat(test_attention_masks, dim=0)\n",
        "test_labels = torch.tensor(test_labels)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLfEd2fPHdbc"
      },
      "source": [
        "val_dataset = TensorDataset(test_input_ids, test_attention_masks, test_labels)\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N91ca0awHiLT"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 8\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2an4UtptKJRt",
        "outputId": "b9b08124-51eb-4e09-9fba-52c6d58702e9"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(  \n",
        "    'digitalepidemiologylab/covid-twitter-bert-v2', # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 3, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        "     return_dict=False)\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()\n"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at digitalepidemiologylab/covid-twitter-bert-v2 were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at digitalepidemiologylab/covid-twitter-bert-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 1024)\n",
              "      (token_type_embeddings): Embedding(2, 1024)\n",
              "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (12): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (13): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (14): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (15): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (16): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (17): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (18): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (19): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (20): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (21): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (22): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (23): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=1024, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFHi5zhsH11W"
      },
      "source": [
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDRxZgT4H5aY"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)\n"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-R2pCpNIJ-c"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDyju_bFIO3e"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hD28VdLKJm6i"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cltD6DtPIZtf",
        "outputId": "078a3a0d-1ca4-4b1c-ad39-20491ef5a326"
      },
      "source": [
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        loss, logits = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            (loss, logits) = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    675.    Elapsed: 0:00:12.\n",
            "  Batch    80  of    675.    Elapsed: 0:00:25.\n",
            "  Batch   120  of    675.    Elapsed: 0:00:37.\n",
            "  Batch   160  of    675.    Elapsed: 0:00:50.\n",
            "  Batch   200  of    675.    Elapsed: 0:01:02.\n",
            "  Batch   240  of    675.    Elapsed: 0:01:15.\n",
            "  Batch   280  of    675.    Elapsed: 0:01:27.\n",
            "  Batch   320  of    675.    Elapsed: 0:01:39.\n",
            "  Batch   360  of    675.    Elapsed: 0:01:52.\n",
            "  Batch   400  of    675.    Elapsed: 0:02:04.\n",
            "  Batch   440  of    675.    Elapsed: 0:02:17.\n",
            "  Batch   480  of    675.    Elapsed: 0:02:29.\n",
            "  Batch   520  of    675.    Elapsed: 0:02:42.\n",
            "  Batch   560  of    675.    Elapsed: 0:02:54.\n",
            "  Batch   600  of    675.    Elapsed: 0:03:06.\n",
            "  Batch   640  of    675.    Elapsed: 0:03:19.\n",
            "\n",
            "  Average training loss: 0.59\n",
            "  Training epcoh took: 0:03:30\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "  Validation Loss: 0.45\n",
            "  Validation took: 0:00:19\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    675.    Elapsed: 0:00:12.\n",
            "  Batch    80  of    675.    Elapsed: 0:00:25.\n",
            "  Batch   120  of    675.    Elapsed: 0:00:37.\n",
            "  Batch   160  of    675.    Elapsed: 0:00:50.\n",
            "  Batch   200  of    675.    Elapsed: 0:01:02.\n",
            "  Batch   240  of    675.    Elapsed: 0:01:15.\n",
            "  Batch   280  of    675.    Elapsed: 0:01:27.\n",
            "  Batch   320  of    675.    Elapsed: 0:01:39.\n",
            "  Batch   360  of    675.    Elapsed: 0:01:52.\n",
            "  Batch   400  of    675.    Elapsed: 0:02:04.\n",
            "  Batch   440  of    675.    Elapsed: 0:02:17.\n",
            "  Batch   480  of    675.    Elapsed: 0:02:29.\n",
            "  Batch   520  of    675.    Elapsed: 0:02:42.\n",
            "  Batch   560  of    675.    Elapsed: 0:02:54.\n",
            "  Batch   600  of    675.    Elapsed: 0:03:06.\n",
            "  Batch   640  of    675.    Elapsed: 0:03:19.\n",
            "\n",
            "  Average training loss: 0.35\n",
            "  Training epcoh took: 0:03:30\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.50\n",
            "  Validation took: 0:00:19\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    675.    Elapsed: 0:00:12.\n",
            "  Batch    80  of    675.    Elapsed: 0:00:25.\n",
            "  Batch   120  of    675.    Elapsed: 0:00:37.\n",
            "  Batch   160  of    675.    Elapsed: 0:00:50.\n",
            "  Batch   200  of    675.    Elapsed: 0:01:02.\n",
            "  Batch   240  of    675.    Elapsed: 0:01:15.\n",
            "  Batch   280  of    675.    Elapsed: 0:01:27.\n",
            "  Batch   320  of    675.    Elapsed: 0:01:39.\n",
            "  Batch   360  of    675.    Elapsed: 0:01:52.\n",
            "  Batch   400  of    675.    Elapsed: 0:02:04.\n",
            "  Batch   440  of    675.    Elapsed: 0:02:17.\n",
            "  Batch   480  of    675.    Elapsed: 0:02:29.\n",
            "  Batch   520  of    675.    Elapsed: 0:02:42.\n",
            "  Batch   560  of    675.    Elapsed: 0:02:54.\n",
            "  Batch   600  of    675.    Elapsed: 0:03:07.\n",
            "  Batch   640  of    675.    Elapsed: 0:03:19.\n",
            "\n",
            "  Average training loss: 0.20\n",
            "  Training epcoh took: 0:03:30\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.50\n",
            "  Validation took: 0:00:19\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    675.    Elapsed: 0:00:12.\n",
            "  Batch    80  of    675.    Elapsed: 0:00:25.\n",
            "  Batch   120  of    675.    Elapsed: 0:00:37.\n",
            "  Batch   160  of    675.    Elapsed: 0:00:50.\n",
            "  Batch   200  of    675.    Elapsed: 0:01:02.\n",
            "  Batch   240  of    675.    Elapsed: 0:01:15.\n",
            "  Batch   280  of    675.    Elapsed: 0:01:27.\n",
            "  Batch   320  of    675.    Elapsed: 0:01:40.\n",
            "  Batch   360  of    675.    Elapsed: 0:01:52.\n",
            "  Batch   400  of    675.    Elapsed: 0:02:05.\n",
            "  Batch   440  of    675.    Elapsed: 0:02:17.\n",
            "  Batch   480  of    675.    Elapsed: 0:02:29.\n",
            "  Batch   520  of    675.    Elapsed: 0:02:42.\n",
            "  Batch   560  of    675.    Elapsed: 0:02:54.\n",
            "  Batch   600  of    675.    Elapsed: 0:03:07.\n",
            "  Batch   640  of    675.    Elapsed: 0:03:19.\n",
            "\n",
            "  Average training loss: 0.11\n",
            "  Training epcoh took: 0:03:30\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.90\n",
            "  Validation Loss: 0.57\n",
            "  Validation took: 0:00:19\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:15:16 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmZbexyJF18R"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "7Sg2sIOiQjCF",
        "outputId": "044d9bcf-b821-4419-c462-cf18c375cf05"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.59</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0:03:30</td>\n",
              "      <td>0:00:19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.35</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0:03:30</td>\n",
              "      <td>0:00:19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.20</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0:03:30</td>\n",
              "      <td>0:00:19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.11</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0:03:30</td>\n",
              "      <td>0:00:19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.59         0.45           0.85       0:03:30         0:00:19\n",
              "2               0.35         0.50           0.88       0:03:30         0:00:19\n",
              "3               0.20         0.50           0.90       0:03:30         0:00:19\n",
              "4               0.11         0.57           0.90       0:03:30         0:00:19"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "rxAQYdgpQrYV",
        "outputId": "53128db8-bb2c-48b1-a29c-35fb15dc418c"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuUAAAGaCAYAAACopj13AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd1yT5/o/8E9CQtg7AWWLMmQJKGrVuqrits621l2157Rn9Jy26rfDan89Pcfava2janGLe1etra2K1laroFVUBFGI7E1Cnt8fQCQMDQo8AT7v1zmvkmfcuRJ45OLO9Vy3RBAEAUREREREJBqp2AEQEREREbV1TMqJiIiIiETGpJyIiIiISGRMyomIiIiIRMaknIiIiIhIZEzKiYiIiIhExqSciFqt1NRUBAQE4NNPP33oMebPn4+AgIBGjKr1qu/9DggIwPz5840a49NPP0VAQABSU1MbPb64uDgEBATg1KlTjT42EdGjkokdABG1HQ1Jbg8fPgwPD48mjKblKSoqwldffYW9e/ciIyMDTk5OiIqKwl//+lf4+fkZNcbf//53HDhwANu3b0dQUFCdxwiCgIEDByIvLw/Hjx+HhYVFY76MJnXq1CnEx8dj2rRpsLOzEzucWlJTUzFw4EBMnjwZb775ptjhEJEJYVJORM1myZIlBo9//fVXbNy4EZMmTUJUVJTBPicnp0d+Pnd3d5w/fx5mZmYPPcbbb7+NRYsWPXIsjeH111/Hnj17MGLECERHR0OtVuPIkSM4d+6c0Un5+PHjceDAAWzduhWvv/56ncecPHkSt27dwqRJkxolIT9//jyk0ub5YDY+Ph6fffYZnnzyyVpJ+ejRozF8+HDI5fJmiYWIqCGYlBNRsxk9erTB4/LycmzcuBFdunSpta+mgoIC2NjYNOj5JBIJFApFg+OszlQSuOLiYuzfvx+9e/fG+++/r9/+4osvoqyszOhxevfujXbt2mHXrl149dVXYW5uXuuYuLg4ABUJfGN41O9BYzEzM3ukP9CIiJoSa8qJyOQMGDAAU6ZMQUJCAmbNmoWoqCiMGjUKQEVy/uGHH2LChAno3r07QkJCMGjQICxduhTFxcUG49RV41x929GjRzFu3DiEhoaid+/e+N///getVmswRl015VXb8vPzsXDhQvTs2ROhoaF46qmncO7cuVqvJzs7GwsWLED37t0RERGBqVOnIiEhAVOmTMGAAQOMek8kEgkkEkmdfyTUlVjXRyqV4sknn0ROTg6OHDlSa39BQQEOHjwIf39/hIWFNej9rk9dNeU6nQ5ff/01BgwYgNDQUIwYMQI7d+6s8/ykpCS89dZbGD58OCIiIhAeHo6xY8di8+bNBsfNnz8fn332GQBg4MCBCAgIMPj+11dTnpWVhUWLFqFv374ICQlB3759sWjRImRnZxscV3X+iRMnsGLFCjzxxBMICQnBkCFDsG3bNqPei4a4dOkSXnjhBXTv3h2hoaEYNmwYvvnmG5SXlxscd/v2bSxYsAD9+/dHSEgIevbsiaeeesogJp1Oh2+//RYjR45EREQEIiMjMWTIEPzf//0fNBpNo8dORA3HmXIiMklpaWmYNm0aYmJiMHjwYBQVFQEA0tPTsWXLFgwePBgjRoyATCZDfHw8li9fjsTERKxYscKo8Y8dO4Z169bhqaeewrhx43D48GGsXLkS9vb2eP75540aY9asWXBycsILL7yAnJwcrFq1CnPmzMHhw4f1s/plZWWYMWMGEhMTMXbsWISGhuLy5cuYMWMG7O3tjX4/LCwsMGbMGGzduhW7d+/GiBEjjD63prFjx+LLL79EXFwcYmJiDPbt2bMHJSUlGDduHIDGe79revfdd7FmzRp069YN06dPR2ZmJhYvXgxPT89ax8bHx+PMmTPo168fPDw89J8avP7668jKysLcuXMBAJMmTUJBQQEOHTqEBQsWwNHREcD972XIz8/H008/jeTkZIwbNw6dO3dGYmIi1q9fj5MnT2Lz5s21PqH58MMPUVJSgkmTJsHc3Bzr16/H/Pnz4eXlVasM62H98ccfmDJlCmQyGSZPngwXFxccPXoUS5cuxaVLl/Sflmi1WsyYMQPp6el45pln4OPjg4KCAly+fBlnzpzBk08+CQD48ssv8cknn6B///546qmnYGZmhtTUVBw5cgRlZWUm84kQUZsmEBGJZOvWrYK/v7+wdetWg+39+/cX/P39hU2bNtU6p7S0VCgrK6u1/cMPPxT8/f2Fc+fO6belpKQI/v7+wieffFJrW3h4uJCSkqLfrtPphOHDhwu9evUyGHfevHmCv79/ndsWLlxosH3v3r2Cv7+/sH79ev227777TvD39xe++OILg2Ortvfv37/Wa6lLfn6+MHv2bCEkJETo3LmzsGfPHqPOq8/UqVOFoKAgIT093WD7xIkTheDgYCEzM1MQhEd/vwVBEPz9/YV58+bpHyclJQkBAQHC1KlTBa1Wq99+4cIFISAgQPD39zf43hQWFtZ6/vLycuHZZ58VIiMjDeL75JNPap1fpern7eTJk/ptH3zwgeDv7y989913BsdWfX8+/PDDWuePHj1aKC0t1W+/c+eOEBwcLLz00ku1nrOmqvdo0aJF9z1u0qRJQlBQkJCYmKjfptPphL///e+Cv7+/8MsvvwiCIAiJiYmCv7+/sGzZsvuON2bMGGHo0KEPjI+IxMPyFSIySQ4ODhg7dmyt7ebm5vpZPa1Wi9zcXGRlZeGxxx4DgDrLR+oycOBAg+4uEokE3bt3h1qtRmFhoVFjTJ8+3eBxjx49AADJycn6bUePHoWZmRmmTp1qcOyECRNga2tr1PPodDr84x//wKVLl7Bv3z48/vjjePnll7Fr1y6D49544w0EBwcbVWM+fvx4lJeXY/v27fptSUlJ+P333zFgwAD9jbaN9X5Xd/jwYQiCgBkzZhjUeAcHB6NXr161jreystJ/XVpaiuzsbOTk5KBXr14oKCjAtWvXGhxDlUOHDsHJyQmTJk0y2D5p0iQ4OTnh+++/r3XOM888Y1Ay5OrqCl9fX9y4ceOh46guMzMTv/32GwYMGIDAwED9dolEgr/85S/6uAHof4ZOnTqFzMzMese0sbFBeno6zpw50ygxElHjY/kKEZkkT0/Pem/Ki42NxYYNG3D16lXodDqDfbm5uUaPX5ODgwMAICcnB9bW1g0eo6pcIicnR78tNTUVKpWq1njm5ubw8PBAXl7eA5/n8OHDOH78ON577z14eHjg448/xosvvohXX30VWq1WX6Jw+fJlhIaGGlVjPnjwYNjZ2SEuLg5z5swBAGzduhUA9KUrVRrj/a4uJSUFANChQ4da+/z8/HD8+HGDbYWFhfjss8+wb98+3L59u9Y5xryH9UlNTUVISAhkMsNfhzKZDD4+PkhISKh1Tn0/O7du3XroOGrGBAAdO3asta9Dhw6QSqX699Dd3R3PP/88li1bht69eyMoKAg9evRATEwMwsLC9Of961//wgsvvIDJkydDpVIhOjoa/fr1w5AhQxp0TwIRNR0m5URkkiwtLevcvmrVKvz3v/9F7969MXXqVKhUKsjlcqSnp2P+/PkQBMGo8e/XheNRxzD2fGNV3ZjYrVs3ABUJ/WeffYa//OUvWLBgAbRaLQIDA3Hu3Dm88847Ro2pUCgwYsQIrFu3DmfPnkV4eDh27twJNzc39OnTR39cY73fj+Lf//43fvjhB0ycOBHdunWDg4MDzMzMcOzYMXz77be1/lBoas3V3tFYL730EsaPH48ffvgBZ86cwZYtW7BixQo899xzeOWVVwAAEREROHToEI4fP45Tp07h1KlT2L17N7788kusW7dO/wcpEYmHSTkRtSg7duyAu7s7vvnmG4Pk6McffxQxqvq5u7vjxIkTKCwsNJgt12g0SE1NNWqBm6rXeevWLbRr1w5ARWL+xRdf4Pnnn8cbb7wBd3d3+Pv7Y8yYMUbHNn78eKxbtw5xcXHIzc2FWq3G888/b/C+NsX7XTXTfO3aNXh5eRnsS0pKMnicl5eHH374AaNHj8bixYsN9v3yyy+1xpZIJA2O5fr169BqtQaz5VqtFjdu3KhzVrypVZVVXb16tda+a9euQafT1YrL09MTU6ZMwZQpU1BaWopZs2Zh+fLlmDlzJpydnQEA1tbWGDJkCIYMGQKg4hOQxYsXY8uWLXjuueea+FUR0YOY1p/7REQPIJVKIZFIDGZotVotvvnmGxGjqt+AAQNQXl6ONWvWGGzftGkT8vPzjRqjb9++ACq6flSvF1coFPjggw9gZ2eH1NRUDBkypFYZxv0EBwcjKCgIe/fuRWxsLCQSSa3e5E3xfg8YMAASiQSrVq0yaO938eLFWol21R8CNWfkMzIyarVEBO7VnxtbVvPEE08gKyur1libNm1CVlYWnnjiCaPGaUzOzs6IiIjA0aNH8eeff+q3C4KAZcuWAQAGDRoEoKJ7TM2WhgqFQl8aVPU+ZGVl1Xqe4OBgg2OISFycKSeiFiUmJgbvv/8+Zs+ejUGDBqGgoAC7d+9uUDLanCZMmIANGzbgo48+ws2bN/UtEffv3w9vb+9afdHr0qtXL4wfPx5btmzB8OHDMXr0aLi5uSElJQU7duwAUJFgff755/Dz88PQoUONjm/8+PF4++238dNPPyE6OrrWDGxTvN9+fn6YPHkyvvvuO0ybNg2DBw9GZmYmYmNjERgYaFDHbWNjg169emHnzp2wsLBAaGgobt26hY0bN8LDw8Ogfh8AwsPDAQBLly7FyJEjoVAo0KlTJ/j7+9cZy3PPPYf9+/dj8eLFSEhIQFBQEBITE7Flyxb4+vo22QzyhQsX8MUXX9TaLpPJMGfOHLz22muYMmUKJk+ejGeeeQZKpRJHjx7F8ePHMWLECPTs2RNARWnTG2+8gcGDB8PX1xfW1ta4cOECtmzZgvDwcH1yPmzYMHTp0gVhYWFQqVRQq9XYtGkT5HI5hg8f3iSvkYgaxjR/ixER1WPWrFkQBAFbtmzBO++8A6VSiaFDh2LcuHEYNmyY2OHVYm5ujtWrV2PJkiU4fPgw9u3bh7CwMHz77bd47bXXUFJSYtQ477zzDqKjo7FhwwasWLECGo0G7u7uiImJwcyZM2Fubo5JkybhlVdega2tLXr37m3UuCNHjsSSJUtQWlpa6wZPoOne79deew0uLi7YtGkTlixZAh8fH7z55ptITk6udXPle++9h/fffx9HjhzBtm3b4OPjg5deegkymQwLFiwwODYqKgovv/wyNmzYgDfeeANarRYvvvhivUm5ra0t1q9fj08++QRHjhxBXFwcnJ2d8dRTT+Fvf/tbg1eRNda5c+fq7Fxjbm6OOXPmIDQ0FBs2bMAnn3yC9evXo6ioCJ6ennj55Zcxc+ZM/fEBAQEYNGgQ4uPjsWvXLuh0OrRr1w5z5841OG7mzJk4duwY1q5di/z8fDg7OyM8PBxz58416PBCROKRCM1xlw4RERkoLy9Hjx49EBYW9tAL8BARUevBmnIioiZW12z4hg0bkJeXV2dfbiIiantYvkJE1MRef/11lJWVISIiAubm5vjtt9+we/dueHt7Y+LEiWKHR0REJoDlK0RETWz79u2IjY3FjRs3UFRUBGdnZ/Tt2xf/+Mc/4OLiInZ4RERkApiUExERERGJjDXlREREREQiY1JORERERCQy3uhZKTu7EDpd81byODvbIDOzoFmfk6gl4rVCZBxeK0TGEetakUolcHS0rnMfk/JKOp3Q7El51fMS0YPxWiEyDq8VIuOY2rXC8hUiIiIiIpExKSciIiIiEpmoSXlZWRnee+899O7dG2FhYZg4cSJOnDhh9Pm7du3C+PHj0aVLF0RHR+PZZ5/F+fPnmzBiIiIiIqLGJ2pN+fz583Hw4EFMnToV3t7e2LZtG2bPno21a9ciIiLivud++OGHWL58OUaNGoVJkyahqKgIly5dglqtbqboiYiIiIgah2hJ+fnz57Fnzx4sWLAA06dPBwCMGTMGI0aMwNKlSxEbG1vvuWfPnsXXX3+NTz/9FIMGDWqmiImIiIiImoZo5Sv79++HXC7HhAkT9NsUCgXGjx+PX3/9FRkZGfWeu2bNGoSGhmLQoEHQ6XQoLCxsjpCJiIiIiJqEaEl5YmIifH19YW1t2KsxLCwMgiAgMTGx3nNPnDiB0NBQfPDBB4iKikJkZCQGDBiAnTt3NnXYRERERESNTrTyFbVaDVdX11rblUolANQ7U56bm4ucnBzs2bMHZmZmePnll+Hg4IDY2Fi88sorsLS0ZEkLEREREbUooiXlJSUlkMvltbYrFAoAQGlpaZ3nFRUVAQBycnKwadMmhIeHAwAGDRqEQYMG4fPPP3+opNzZ2abB5zQGpdJWlOclaml4rRAZh9cKkXFM7VoRLSm3sLCARqOptb0qGa9Kzmuq2u7h4aFPyAHA3NwcQ4YMwZo1a1BYWFirLOZBMjMLmm1lpxMX7yDuWBKy8krhZKfA2L5+6Bns1izPTdQSKZW2UKvzxQ6DyOTxWiEyjljXilQqqXciWLSacqVSWWeJSlVLQ5VKVed5Dg4OMDc3h4uLS619Li4uEAQBBQUFjRtsIzpx8Q5W77uEzLxSCAAy80qxet8lnLh4R+zQiIiIiEgkoiXlgYGBuH79eq3OKefOndPvr4tUKkVQUBDS09Nr7btz5w7MzMxgb2/f+AE3krhjSSjT6gy2lWl1iDuWJFJERERERCQ20ZLymJgYaDQabN68Wb+trKwMcXFxiIyM1N8EmpaWhqSkpFrn3r59Gz///LN+W0FBAfbt24eIiAhYWFg0z4t4CJl5ddfK17ediIiIiFo/0WrKw8PDERMTg6VLl0KtVsPLywvbtm1DWloa3n33Xf1x8+bNQ3x8PC5fvqzf9vTTT2Pz5s3429/+hunTp8POzg5bt25Ffn4+/vWvf4nxcozmbKeoMwGXy6TILyqDrZW5CFERERERkZhEmykHgCVLlmDKlCnYsWMH/t//+3/QarVYtmwZoqKi7nuepaUl1qxZg4EDB+K7777DBx98ABsbG6xateqB54ptbF8/mMsM33YzqQTach0WroxHYnK2SJERERERkVgkgiA0T8sREyd29xV3F2t8teMi0rOKMPwxH4zu7QMzqah/MxGZDHaUIDIOrxUi45hi9xUm5ZWaMymvUvMHorSsHLHf/4nj52/Dz90Oc0cGw8XBslljIjJFTDSIjMNrhcg4ppiUcyrWhCjMzTBzWBDmjgpG2t1CLFx1Gqcv1b2yKRERERG1HkzKTVD3zq54a0Y02jtb4cvtF/DtvkSUlpWLHRYRERERNREm5SZK6WCJeZMjMbynN346dxuLV59GSobpLopERERERA+PSbkJk5lJMa6vH/79VBcUlWrx9uozOPxrKngbABEREVHrwqS8Bejs44RFM6PR2ccRsYf+xKdb/0BBsUbssIiIiIiokTApbyHsrMzxj/FheHpgJ1y4nomFK+NxiT3NiYiIiFoFJuUtiEQiwaBunnhtSleYy83w3vrfEPfjNZTrdGKHRkRERESPQCZ2ANRw3m62WDi9K9YduoLdv9zApeRszBnVGS727GlOREREVJ/4O2exM2k/ckpz4KBwwCi/GES7RYodFgDOlLdYFuYyzBwehDmjOiNVXYC3Vp7GGfY0JyIiIqpT/J2zWHdpK7JLcyAAyC7NwbpLWxF/56zYoQFgUt7i9ejshrdmRsPVyQpfbL+A1fsvoVTDnuZEREREOkGH9CI14u+cxYbL26DRGTbK0Og02Jm0X6ToDLF8pRVQOVhiwbOR2P7Tdew7mYw/U3Lw/OgQeKrqXsaViIiIqDXKLc1Hct5NJOel4EZeCpLzU1GsLb7vOdmlOc0U3f0xKW8lZGZSjO/nhyAfRyzflYC3V5/BpAEdMSDSHRKJROzwiIiIiBpVibYEN/Nv3UvA81L0CbZUIkV7azdEqsLgY+cJbztPfHluVZ0JuKPCoblDrxOT8lYm2McJi2ZFY+WeRMQe+hMJN7IwY1gQbCzlYodGRERE9FDKdeW4VXjbIAG/U5gBARULKrpYOKGDvTd87HrD284LnrbtYW5mbjDGKL8YrLu01aCERS6VY5RfTLO+lvpIBC4PCQDIzCyATte8b4VSaQu1Or9JxhYEAYfOpGLz0auwszbHnJGdEeDl2CTPRdTUmvJaIWpNeK1QayAIAtTFmUiuTL5v5KUgteAWNDotAMBGbg3vytlvHztPeNt6wsbc2qixxe6+IpVK4Oxcd3kxk/JKrS0pr5J8Jx9f7biAjJxijHzMByN7+cBMyvt7qWVhokFkHF4r1BLlleUbJODJeSkoqqwDl0vl8LJ1v5eA23nB2cLxkUtzxbpW7peUs3yllfN2s8XCGd0Qe+hP7Pz5BhKSszFnJHuaExERUfMr0ZYiJf8WkvPvJeBZJRUrlEsgQXsbN3RRhurrwNtZu8JMaiZy1M2DM+WVWutMeXUnL97BmgOXIZVIMH1oILoGqprtuYkeBWf/iIzDa4VMSbmuHGmF6QbdUG4XpuvrwJ0tHKuVoXjB09Ydihp14E2FM+Ukqh7Bbujgbo+vd1zEF9svoG+X9nhqYCco5G3jL1AiIiJqGoIgILMkSz/7fSMvBSn5t/Q3VVrLrOBt54lwZYh+FtzWnK2bq2NS3sZU9TTf9tM17Dt5E1dSc/H8qGB4sKc5ERERGSm/rOBeHXh+xX8LNUUAALlUBk9bd/R27w4f24o6cBdLJ7ZofgAm5W2QzEyKCf06orO3E77ZnYC315zBUwM6ol8Ee5oTERGRobLyMn0/8KpZ8MySLAAVdeDtrF0R5hKsvxmzvbVbm6kDb0xMytuwYF8nLJ4ZjeV7ErD24J+4cJ09zYmIiNqycl057hRl4EaNOnCdoANQsdCOj50n+rj3gI+dJzxt3WEhsxA56taBSXkbZ2dtjn9OCMf3p1Ow+YckLFwZz57mREREbYAgCMgqya5RB56Ksso6cEuZJXzsPBHq0hk+dp7wsvWEvcJW5KhbLyblBKlEgsHRXgjwcsRXOy5gyfrf2NOciIiolSnQFCI5L9WgG0qBphAAIJPK4GnTHo+1j9aXoSgtXVjW2oyYlJOevqf5wYqe5onJ2ZgzMhjO9vxYioiIqCUpK9cgteCWwSz43eJMABV14K7WKoQ4B92rA7dxg0zKtFBMfPfJgIW5DLNGdEZnXyesPXAZC1fGY8awQEQFsKc5ERGRKdIJOtwpzKhMwCtmwW8V3tHXgTso7OFj54le7aMr68A9YMk6cJPDpJzq1DPYDX7t7fD1zov4fNsF9Itwx1MDOsKcPc2JiIhEIwgCsktz9DPgyXkpSM5PRVl5GQDAUmYBb1tPDPLqV7kwjwccFPYiR03GYFJO9VI5WmHBs1HY9uM17Dt1E1dScjB3dDA8lOxpTkRE1BwKNUW4mZdakYTn38SNvBTklxUAAGQSM3jYuqNnu27wtvWoqAO3coFUwvvBWiIm5XRfMjMpJvTviCAfRyzfnYi3V7OnORERUVPQlGuQWpBmMAueUXxXv9/VSoXOTgHV6sDbQc468FaD30kySoivs0FP84s3sjF9aCB7mhMRET0EnaBDepG6WgJ+E6kFt/V14PbmdvCx80SPdl31ZSiWMkuRo6amJBEEQRA7CFOQmVkAna553wql0hZqdX6zPuej0gkCDp1OwZYfkmBnbY65o4Lh7+kgdljUyrXEa4VIDLxWTJMgCMgpzdV3QUnOS8HN/FSUlJcCACzMLOBt56GfAfe282QdeBMT61qRSiVwdq67DJgz5dQgUokEQ6K94O/pgK93XsT/1p3FqF6+GPGYN3uaExERASjSFONmfqrBLHhuWUUCaCYxg4dNe0S7RekTcBXrwAlMyukh+bazw8Lp3RB76E/sOH4diTeyMGdUMJzs2GKJiIjaDo1Oi1s16sDTi9T6/a5WSgQ4ddLPgrvbtGcdONWJPxX00CwVMjw3ojOCfZyw5mBFT/PpQ4MQFaAUOzQiIqJGpxN0yCi6a1CGklqQhnKhHABgZ24LHzsv/Sy4l60HrOSsAyfjMCmnR9YzxA0d3O3w9Y6L+HzbH+gf4Y5J7GlOREQtXM068OS8VJSUlwAAFGbm8Lb1xADPPgZ14OxMRg+LSTk1CldHK/zflCjE/XgN+0/dxJ/saU5ERC1IsbYYyXmpFT3B8yuS8JzSXACAVCKFh007dHOL0JehuFopWQdOjYpJOTUamZkUE/t3RGdvRyzfnVDR03xgJ/Tr0p4zB0REZDI0Oi3SCm7rZ8Bv5KUgvShDv19l6YJODh30CbiHTXvIzdgCmJoWk3JqdCEdnLFoVnes2J2AtQcuI+F6FqaxpzkREYlAJ+igLrpbuSJmRQJ+Kz8N2so6cFu5DXzsPdHNNaKiDtzOA9ZyK5GjpraISTk1CXtrc/xzYjgOxqdg67EkXF8Vjzkj2dOciIiaVm5pnkEnlOT8VBRriwEA5mbm8Lb1QD/P3vpZcEeFAz/NJZPApJyajFQiQUx3LwR43etpPrqXL0Y85gOplP8AEhHRoynWliClWj/wGzXqwN2t3RClCoO3nRd87DzhZq1iHTiZLCbl1OSqepp/d/BPbD9+HQnJ2ZgzsjN7mhMRkdG0Oi3SCu7cS8DzU5BemAEBFatxu1g6o6ODr0EduLmZuchRExmPSTk1C0uFDLNHdkawryPWHvwTC1fGY8awIET6s6c5EREZEgQB6uK7BmUoKQVp0Oq0AAAbuTV87Dz1s+Dedh6wkVuLHDXRo2FSTs3qsZB28Gtvj692XsRncX+gf6Q7JvVnT3MiorYsryy/Rj/wFBRV1YFL5fC09UBf98f0s+BOFo6sA6dWh0k5NTtXJyu8NiUKcceuYX98RU/z50cFw509zYmIWr0SbWmtOvDs0hwAgAQStLdxQ4QqtDIB94KblQpmUk7cUOvHpJxEITOTYuKAjujsU62n+ROd0DecPc2JiFqLcl050grvGMyA3y5M19eBO1s4oYO9N7ztKrqheNq6Q8E6cGqjmJSTqEI6OGPRzGgs35OINfsv4+L1LEwfGghrC/Y0JyJqSQRBwN3iLCTn3dSviJmSfwuayjpwa7kVvO080e9xJgsAACAASURBVEUZAu/KZeltzfkJKVEVJuUkOnsbBV6aGI4D8TcRd+waFt5mT3MiIlOXX1ZQqw68UFsEAJBLZfC09UAf9576OnBnCyd+Ekp0H0zKySRIJRIM7e6NQC9HfL2DPc2JiExJaXkZUvJv4UbeTX0CnlmSDaCiDrydtSvClcGVM+BeaG/tyjpwogYSNSkvKyvDxx9/jB07diAvLw+BgYF46aWX0LNnz/ue9+mnn+Kzzz6rtd3FxQU///xzU4VLzcC3nR0WzuiGtQcvY/vx60hMzsZs9jQnImo25bpy3C5MvzcLnp+CtII7+jpwJwtHeNt54nGPx+BtW1EHbiFTiBw1UcsnalI+f/58HDx4EFOnToW3tze2bduG2bNnY+3atYiIiHjg+YsXL4aFxb1krfrX1HJZKmSYMzIYIb5OWHugoqf5zGFBiGBPcyKiRiUIAjJLsivqwCtnwG/m34JGpwEAWMks4W3niTCfzvo6cDtzW5GjJmqdREvKz58/jz179mDBggWYPn06AGDMmDEYMWIEli5ditjY2AeOMXToUNjZ2TVxpCQWfU/zHRfxadwfGBDpjonsaU5EVEv8nbPYmbQfOaU5cFA4YJRfDKLdImsdV1BWiOR8wzrwAk0hAEAmlcHTxh2923fXJ+BKS2fWgRM1E9GS8v3790Mul2PChAn6bQqFAuPHj8eHH36IjIwMqFSq+44hCAIKCgpgbW3NfzRaKVcnK7w2NQpbjyXhQHwK/kzJwdzRIXB34cptbYGxiQZRWxZ/5yzWXdqqn93OLs3BuktbodVp4WqlMpgFv1uSBaCiDtzNWoUQlyD4VCbg7tbtWAdOJCLRkvLExET4+vrC2towuQoLC4MgCEhMTHxgUt6vXz8UFRXB2toaQ4YMwbx58+DgwI4drY3MTIpJAzohyNsJK/Yk4O1vT7OneRtQX6IBgIk5GUUQBH0ddNXXQsUD/deCIACVj4SKndBBQMX/DLdXfF05XuXX+keC/sw6xjc8XoCunvFrxqyrMX7lPgGVz1Qx5tYru/TXSRWNToPYS1v0jx0VDvC280Rv9x7wtvOEl607LGQs+SQyJaIl5Wq1Gq6urrW2K5UVdcMZGRn1nmtnZ4cpU6YgPDwccrkcJ0+exMaNG5GQkIDNmzfD3JwLD7RGYX7OWDwzGst3J2DN/stIuJ6Faexp3mrtTNpfZ6Kx9couWJgpaiRY95IeGCQ/tRMywySsZlJ1L+m593XN8WskePpxao5fX1JYc/zayZmu+vNWH6/OpPD+SSeqJYJ1Jp3Vx0NFImg4fn3vj67G+PfGMojfIAFtgvenvu9R5bht3dzQafC284S9gqWeRKZOtKS8pKQEcnntZEqhqLiDu7S0tN5zp02bZvA4JiYGnTp1wuLFi7F9+3ZMnDixwfE4O4uzgIFSyRtmGkKptMV/XuiD7ceuYs3eRCRnnMErk7siyNdJ7NDoIel0OtwtykJafgZu56cjLT8dt/Mz9Mtu11SgKcTXf6xu5igbTgIJJBIJJAAgkUAKCVD5WCKRVvwXEkCCavvunSOp3CatPObevvrGrNp3/zGrjtOPKb03plQigUQirXr2e2NKAAmkqPhgyvA1GB9HXa9b+oDXVntf9ec1GLNarKiKoGZMlZ+sGYxZ47VJ6znm3r66x5RKpNXOu7ffYMwa3w+DMavFUbX33r7qsdYe873jXyGnJK/Wz6CLlRMGdu7xED+9RG2DqeVgoiXlFhYW0Gg0tbZXJeNVybmxnn76abz33ns4ceLEQyXlmZkF0Omad2ZFqbSFWp3frM/ZWvQJcYO7kxW+3nkB8z8/jtG9fTC8J3uamypBEFCgKUR6kRoZRXeRUaRGRvFdpBepcbfoLrRCuf5YCzMLqKxcYC6Vo0xX+98IO3Nb/CV8hj45qZ4gATBInPRJaY2EpurrupI0VBtPv7euJKpyfGnNc1hSRc1BuPff0R2GGZR6AYBcKsdwn8H8HUNUD7FyMKlUUu9EsGhJuVKprLNERa1WA8AD68lrkkqlcHV1RW5ubqPER6avQ3s7vDUjGmsPXMa2n64j4QZ7mouttLzsXtJdVJF0ZxRXfF2sLdYfZyYxg9LSGSorJUKcA6GycoGrlQoqKxfYym0gkUhq1ZQDFYnGkx2Hw8vWQ4yXR2SSqu6x4E3RRC2baEl5YGAg1q5di8LCQoObPc+dO6ff3xAajQa3b99GSEhIo8ZJps1SIcPskZ0R7OuE7w5W9jQfHoSITuxp3lTKdeXILMmuTLzVSC++q0/Ec0oN/yh2VDhAZeWCrq5d4GqlhMrKBSpLJZwsHB7Y5YGJBpHxot0iEe0WyU9giVow0ZLymJgYrFy5Eps3b9b3KS8rK0NcXBwiIyP1N4GmpaWhuLgYfn5++nOzsrLg5GRYQ7xixQqUlpaiT58+zfYayDRIJBL0Cm0HP3d7fLXjAj7d+gcGRnpg4gA/yGVs7/UwBEFAXln+vRnvYrX+a3VxJnSVNwMCFYuLuFopEeDYsSLptlLC1UoJpaUzzM0e7aZrJhpERNRWiJaUh4eHIyYmBkuXLoVarYaXlxe2bduGtLQ0vPvuu/rj5s2bh/j4eFy+fFm/rX///hg2bBj8/f1hbm6OU6dO4cCBA4iKisKIESPEeDlkAtycrPDalK7YeiwJB0+n4HJKDp4fHYz27Gler2JtCdRVZSaVdd5VyXdJ+b2brWVSGVSWLmhn7YpwZUhl4l0x620tt2IdNRER0SMSLSkHgCVLluCjjz7Cjh07kJubi4CAACxbtgxRUVH3PW/kyJE4e/Ys9u/fD41GA3d3d/z1r3/F3LlzIZOJ+pJIZHKZFE8N7ITOPo5YsScRi789jWcG+aNPWLs2mzhqdVrcLc4ySLqrbrjMK7s3+yyBBE4WDlBZKdG9nU9FnbelEiorJRwt7PXdJYiIiKjxSYSqpq5tHLuvtD45BaVYvjsBCTey0TVQhekxAbBqpT3NBUFATmlurZsrM4rUyCzJNig3sZFbQ1VZ311R562EytIFSktnyM1M8/3htUJkHF4rRMZh9xWiZuRgo8C/JnXB/lM3se3Ha7ieloe5o4LR0cNe7NAeWpGmCOnVWgpWzXqri+4atA+US+VQWbnA09YdUa5doLJ00ZecWMmtRHwFREREVBcm5dSqSSUSDOvhjQAvB3y94yL+G3sWo/v4YngPb5Ptaa4p10BdnFmRdBeqK2+yrEjACzSF+uOkEimcLRyhslLC39GvYtbbsmIG3F5hx3ITIiKiFoRJObUJfu3tK3qaH7yMbT9eQ+KNLMweGQxH24YtUtVYdIIO2SU51Tqb3NW3GMwqyTFYItzO3BYqKxeEK4P1pSYqKyVcLJ0gk/ISJiIiag1YU16JNeVtgyAI+PmPO4g99CfkMilmDgtCl04uTfZchZoiZBSr75WcVK1oWXwXWp1Wf6zCzNygvrvqa6WVCyxlXAyJ1wqRcXitEBmHNeVEIpNIJOgd1g5+7nb4eudFfLL1PAZGeWBi/4fvaV5WtYplcY2VLIvUKKq2iqVUIq1cxdIFQc7+lZ1NKma97cxt22x3GCIiImJSTm1UO2drw57mN+/f07xcV46skhx9V5P0arPe2aU5Bsc6KOyhslIi0jUcrpWlJiorJZwtHB+4iiURERG1TUzKqc2q3tN8+e5ELF4dj7EDPODrI62c9b63fLy6OBPlQrn+XEuZBVRWSnRy7KC/uVJVuYqlhUycOnUiIiJquZiUU5tToi2plnSrkV6ihlsPNdLyM7AjWwNkVxwnk5hBaeUCV2sVQl0665ePV1m5wEZuzXITIiIiajRMyqlVKteV425JlsHqlVU3WubWWMXS0cIBKksX9PHshrsZUvx+oQT2ckfMiekKfw9HEV8FERERtRVMyqnFEgQBuWV5lYm3YXeTuyVZBqtYWsut4GqlRJBTgL7UxNVKCRdLZ5hXX8UyAEjqkIuvd17EktjfMaaPL4aZcE9zIiIiah2YlJPJK9IUQ11seHNlRpEa6cV3UVZepj+uahVLd5t2iFSF6ZeSV1aWmxjLz72ip/maA5cQ9+M1JIjc05yIiIhaPyblZBI0Oi3uFmfWaimYUXQX+ZoC/XESSCpWsbRWoqNDB4NZ78ZcxdLKQoa5o4IR7OuE2EN/YuHKeMwcHoQuHZumpzkRERG1bUzKqdnoBB1ySnNrJd0ZRWpklmQbrGJpa24DlaUSoS5B+paCrlYucLZ0hryZVrGUSCToE9YeHd3t8fWOi/hky3k8EeWBCY/Q05yIiIioLkzKqdEVaAqr3Vh5V3+zpbr4LjQ1VrFUWSnhbeeJbm6RUFm56LubWMosRXwFhto5W+O1qV2x+Yer+P5MKv5MycHc0cFo52x8SQwRERHR/TApp4dSVq6BurKtoMGsd7EahZoi/XFSiRQulk5QWSoR6NTp3lLyVi6wN7drMW0F5TIpnnnCH519nLByTyIWfXsak5/wR++wdi3mNRAREZHpYlJO9dIJOmSVZFfrbHJv1rvmKpb25nZwtVIiQhmqT7pVVkq4WDi1qlUsu3R0waKZ0Vi+OwGr9l3CxRtZmDokEFYWvJSIiIjo4TGTaOMEQUCBprBWL+/04ru4W3QX2mqrWFqYWcDVSomODr7VSk2UUFq6tKlVLB1tFfj3pC7YdyoZ2368jmtpeZg7Khh+7vZih0ZEREQtFJPyNqK0vMygj7d+9rtYjWJtif44M4kZlJbOcLVSItQ5yKC7CVexvEcqlWB4Tx8Eejni650X8e53Z/Hk474Y2sMbUr5HRERE1EBMyluRcl05Mkuy6qjzvouc0lyDYx0VDnC1UqKba4RBdxNHhUOrKjdpatV7mm89dg0JN7Lx3IjO7GlOREREDcKkvIURBAF5Zfm1bq5ML1LjbrHhKpZWMku4WikR4NhRX+ftaqWE0tIZ5mbmIr6K1kXf09zHCbHfV/Q0nzU8COHsaU5ERERGYlIugvg7Z7EzaT9ySnPgoHDAKL8YRLtFGhxTrC2pdXNlRnHF16UGq1jKoLR0QXvrduhSeZNlVVvBhqxiSY9GIpGgT3h7dPSwx1c7LuLjLefxRFcPTOjXEXJZ4yxoRERERK2XRBAE4cGHtX6ZmQXQ6Zr+rYi/cxbrLm2FRqfRb5NJzBCuDIHCTKGf9c4vM1zF0snC0eDmSpWVC1SWSjha2DfaKpbUODTacmz+IQnfn0mFl8qGPc0bgVJpC7U6X+wwiEwerxUi44h1rUilEjg729S5j0l5peZKyl//+T+12glWsZFbGybdlbPeLhZOkJvJmzw2aly/X72LlXsSUaYtx+RB/ugdyp7mD4uJBpFxeK0QGccUk3KWrzSz+hJyAPhfn4XNGAk1taqe5t/suohVey/h4nX2NCciIqK6se6hmTkqHBq0nVo2R1sFXn4qAmMf74Azl9R4a1U8ktJyH3wiERERtSlMypvZKL8YyKWGpShyqRyj/GJEioiamlQqwYjHfDD/2UgIAvDf785iz4kb0LFyjIiIiCoxKW9m0W6ReCZwHBwVDpCgYob8mcBxtbqvUOvT0d0ei2Z2Q6S/EluPXcP7G35HTkGp2GERERGRCeCNnpWa60bP6nhDTtskCAJ+On8b677/E+YyMzw3Ighhfuxpfj+8VoiMw2uFyDimeKMnZ8qJmplEIsHj4e3x5rRucLBR4KPN57H++yvQaHUPPpmIiIhaJSblRCJp72KNN6ZFYWCUBw6dScE7a8/gTlaR2GERERGRCJiUE4lILjPD5EH++Pu4MGTllWLRqtM4fv42WFVGRETUtjApJzIBXTpV9DT3bWeLlXsTsWxXAopLtWKHRURERM2ESTmRiajqaf7k4x1wOjEDC1eypzkREVFbwaScyIRIpRKMfMwH8yff62m+92Qye5oTERG1ckzKiUxQR4+KnuYR/kps+SEJH2xkT3MiIqLWjEk5kYmyspDjL6ODMX1oIK6m5mLhynicT8oUOywiIiJqAkzKiUyYvqf59G6wt1bgo83nsOEwe5oTERG1NkzKiVoAfU/zSA8cPJ2C/6z9lT3NiYiIWhEm5UQthFxmhsmD/fG3caG4m1uMRatO4+c/2NOciIioNWBSTtTCRHRSYtHMaPi42WLFnkR8w57mRERELR6TcqIWyMnOAq88HYEn+/giPjEDb62Kx7W0PLHDIiIioofEpJyohZJKJRjZyxfzJkdApxPw7ne/Yh97mhMREbVITMqJWrhOHg54a2Y0Ijq5YPMPSfhw4+/IZU9zIiKiFoVJOVErYG0hx1/GhGBaTACupObiTfY0JyIialGYlBO1EhKJBH27uOON6d1gb22u72muLWdPcyIiIlPHpJyolXF3scbrU7tiQKQ7Dp5OwTtrf0U6e5oTERGZNCblRK2QudwMzw4OwN/GhuJuTjHequxpTkRERKaJSTlRKxbhX7On+UX2NCciIjJBoiblZWVleO+999C7d2+EhYVh4sSJOHHiRIPHmT17NgICAvDOO+80QZRELVtVT/MxfXxxMiEdi1adxvXb7GlORERkSkRNyufPn4/Vq1dj1KhReO211yCVSjF79mz89ttvRo/xww8/4MyZM00YJVHLJ5VKMKqXL+ZPjkS5Tof/rP0V+06xpzkREZGpEC0pP3/+PPbs2YOXX34Zr776KiZNmoTVq1ejXbt2WLp0qVFjlJWV4d1338WsWbOaOFqi1qGqp3mXTi7YfDQJH246x57mREREJkC0pHz//v2Qy+WYMGGCfptCocD48ePx66+/IiMj44FjrFmzBiUlJUzKiRrA2kKOv44JwdSYAPyZkoOFK+Nx4Rp7mhMREYlJtKQ8MTERvr6+sLa2NtgeFhYGQRCQmJh43/PVajW++OILvPTSS7C0tGzKUIlaHYlEgn5d3PHmtK6wtTbHB5vOYdORq+xpTkREJBLRknK1Wg2VSlVru1KpBIAHzpR/8MEH8PX1xejRo5skPqK2wF1pgzemdkX/SHfsj7/JnuZEREQikYn1xCUlJZDL5bW2KxQKAEBpaf11rufPn8f27duxdu1aSCSSRonH2dmmUcZpKKXSVpTnJaruX5O7omeYOz7Z+BsWrz6N58eGY0BXT7HDMsBrhcg4vFaIjGNq14poSbmFhQU0Gk2t7VXJeFVyXpMgCHjnnXcwePBgdO3atdHiycwsgE7XvJ0olEpbqNX5zfqcRPXp6GaDt2Z0w7JdCfhw/VmcPH8Lzw4OgKVCtH8m9HitEBmH1wqRccS6VqRSSb0TwaKVryiVyjpLVNRqNQDUWdoCAIcOHcL58+fx9NNPIzU1Vf9/ACgoKEBqaipKSkqaLnCiVszJzgKvPh2BMb0re5p/y57mREREzUG0pDwwMBDXr19HYWGhwfZz587p99clLS0NOp0O06ZNw8CBA/X/B4C4uDgMHDgQ8fHxTRs8USsmlUowqrcv5j0TCW15RU/z/adusqc5ERFRExLtc+mYmBisXLkSmzdvxvTp0wFU9B2Pi4tDZGQkXF1dAVQk4cXFxfDz8wMADBgwAB4eHrXGe+GFF9C/f3+MHz8ewcHBzfY6iForf08HvDUjGqv3XcKmo1eRcCMLs0Z0hr21udihERERtTqiJeXh4eGIiYnB0qVLoVar4eXlhW3btiEtLQ3vvvuu/rh58+YhPj4ely9fBgB4eXnBy8urzjE9PT3xxBNPNEv8RG2BjaUcf30yBMd+T8P6w1ewcMUpPDeiM0I6OIsdGhERUasi6h1cS5YswUcffYQdO3YgNzcXAQEBWLZsGaKiosQMi4iqkUgk6Bfhjk4e9vhqx0V8sOkcYqK9MLZvB8jMRKuAIyIialUkgsBCUYDdV4iMUaYpx8YjV3H0t1vwcbPF3NHBcHW0avLn5bVCZBxeK0TGYfcVImrRzOVmmDIkAC88GQp1TjHeWnUaJy7eETssIiKiFo9JORE1WFSAEm/NiIa3ygbf7ErA8t0JKC7Vih0WERFRi8WknIgeirO9BV55JgKje/vixMU7WPTtady4w57mRERED4NJORE9NDOpFKMre5prtDq8s4Y9zYmIiB5GoyTlWq0WBw4cwKZNm/QrchJR2+Hv6YBFM6MR3tEFm45exUebzyG3sEzssIiIiFqMBrdEXLJkCU6dOoWtW7cCAARBwIwZM3DmzBkIggAHBwds2rSp3l7iRNQ62VjK8cKTIfjh9zRsOHwFC1fGY/aIzgj2dRI7NCIiIpPX4Jnyn376CV27dtU/PnLkCE6fPo1Zs2bh/fffBwAsW7as8SIkohZDIpGgf4Q73pjWFbaWcry/8XdsPnoV2nKd2KERERGZtAbPlN+5cwfe3t76x0ePHoWHhwdefvllAMCVK1ewa9euxouQiFocD6UNXp/WFRuPXMW+Uzdx6WY25o4KhqoZepoTERG1RA2eKddoNJDJ7uXyp06dwmOPPaZ/7OnpybpyIoJCboapQwLwwpMhSM9iT3MiIqL7aXBS7ubmht9++w1Axax4SkoKunXrpt+fmZkJKyvOhhFRhagAFRbNjIYne5oTERHVq8HlK8OHD8cXX3yBrKwsXLlyBTY2Nujbt69+f2JiIm/yJCIDzvYWePWZCOz6+QZ2/XIDSbdyMXd0MHzc7MQOjYiIyCQ0eKZ87ty5ePLJJ/H7779DIpHgf//7H+zsKn6x5ufn48iRI+jZs2ejB0pELZuZVIoxfTrg1acjUFbZ0/xgPHuaExERAYBEEBrvN6JOp0NhYSEsLCwgl8sba9hmkZlZAJ2ueZMDpdIWanV+sz4nkSkoKNZg1d5E/HblLkI7OGPW8CDYWZvXezyvFSLj8FohMo5Y14pUKoGzs03d+xrzibRaLWxtbVtcQk5EzcvGUo4Xx4ZiymB/JCZn482V8bh4PUvssIiIiETT4KT82LFj+PTTTw22xcbGIjIyEl26dMG///1vaDSaRguQiFoniUSC/pEeeHNaV9iwpzkREbVxDU7KV6xYgWvXrukfJyUl4T//+Q9UKhUee+wx7N27F7GxsY0aJBG1Xh4qG7wxrSv6dWmPfadu4t3vziIjp1jssIiIiJpVg5Pya9euISQkRP947969UCgU2LJlC5YvX45hw4Zh+/btjRokEbVuCrkZpsYE4q9jQpCeVYS3VsbjZAJ7mhMRUdvR4JaIubm5cHR01D/+5Zdf0KNHD9jYVBStR0dH49ixY40XIRG1GV0DVfBpZ4tluxKwbGcCjp5NRWZuKbLzS+Fkp8DYvn7oGewmdphERESNrsEz5Y6OjkhLSwMAFBQU4I8//kDXrl31+7VaLcrLyxsvQiJqU1zsLTHvmQhEdnLBldQ8ZOWXQgCQmVeK1fsucVVQIiJqlRo8U96lSxds2LABHTt2xI8//ojy8nI8/vjj+v3JyclQqVSNGiQRtS1mUimS02u3qirT6hB3LImz5URE1Oo0eKb873//O3Q6Hf75z38iLi4OY8aMQceOHQEAgiDg+++/R2RkZKMHSkRtS2Zeab3br6bmNnM0RERETavBM+UdO3bE3r17cfbsWdja2qJbt276fXl5eZg2bRq6d+/eqEESUdvjbKeoMzGXSID/fPcr/D0dMKKnN4J9nSCRSESIkIiIqPE06oqeLRlX9CQyLScu3sHqfZdQpr3Xt9xcJsXkQf4oLivHgfibyM4vhZerDYb39EGUvxJSKZNzatv4e4XIOKa4omeDZ8qr3Lx5E4cPH0ZKSgoAwNPTEwMHDoSXl9fDDklEpFdVNx53LAlZebW7r/SPcMeJi3ew72Qyvtx+Aa5OVhjW3Qs9Q9wgM2vUxYqJiIia3EPNlH/00Uf45ptvanVZkUqlmDt3Lv7xj380WoDNhTPlRKbrfteKTifgzOUM7D2RjJsZBXC0VWBItBf6hreHwtysmSMlEhd/rxAZp1XMlG/ZsgVfffUVIiIi8Nxzz6FTp04AgCtXrmDFihX46quv4OnpibFjxz5a1ERERpBKJYgOckW3QBUuXM/CnhPJ2HD4Cnb/cgNPdPXAwCgPWFvIxQ6TiIjovho8Uz527FjI5XLExsZCJjPM6bVaLSZPngyNRoO4uLhGDbSpcaacyHQ19Fq5kpqDPSeScT4pEwpzM/Tv4o7B0Z5wsFE0YZRE4uPvFSLjmOJMeYMLL5OSkjBs2LBaCTkAyGQyDBs2DElJSQ2PkoiokXTycMA/J4TjrRndEO7njAOnb+LVL3/Bmv2XkJFTLHZ4REREtTS4fEUul6OoqKje/YWFhZDL+VExEYnPy9UWz48OwZOPF2H/qZs4/sdtHDuXhu5BrhjWwxseqrpnK4iIiJpbg2fKQ0NDsXHjRty9e7fWvszMTGzatAnh4eGNEhwRUWNwdbTCtJhA/O/5xzC4myd+u3IXb66Mx8ebz+HqLS5ERERE4mtwTfnp06cxffp0WFtbY9y4cfrVPK9evYq4uDgUFhbi22+/RdeuXZsk4KbCmnIi09XY10pBsQZHfk3FoTMpKCzRIsDTAcO5EBG1Avy9QmQcU6wpf6iWiEeOHMHbb7+N27dvG2xv37493nzzTfTr1++hAhUTk3Ii09VU10pJmRY//p6GA6dTkJ1fCm9XWwzv6Y1ILkRELRR/rxAZp9Uk5QCg0+lw4cIFpKamAqhYPCg4OBibNm3CmjVrsHfv3oePWARMyolMV1NfKxqtDicu3sHek8nIyC7mQkTUYvH3CpFxTDEpf+gVPaVSKcLCwhAWFmawPTs7G9evX3/YYYmImp1cJsXj4e3RO7SdfiGiVfsuYfvx64iJ9sLjXIiIiIia2EMn5URErU31hYj+uJaFvSduYP3hK9j1yw0M6uqBAVyIiIiImgiTciKiGiQSCcL8nBHm54w/U3Kw92Qytv10HXtP3UT/CHcM7saFiIiIqHExKSciug9/Twf4ezrgZno+9p5MxoH4m/j+TCp6h7VDTHcvqBwsxQ6RiIhaASblRERGqL4Q0b6TN3H8fBp+/D0N0UEqLkRERESPxAq+/gAAIABJREFUzKikfNWqVUYPePbs2YcOhojI1Lk6WmH60ECM7u2Lg6dv4off0nAyIR1dOrpgWE9vdHS3FztEIiJqgYxqiRgYGNiwQSUSJCYmPnRQYmBLRCLTZcrXSkGxBod/TcX3lQsRBXo5YFhPbwT7cCEian6mfK0QmZIW2xJxzZo1jRoQEVFrYWMpx+jevhgS7Yljv6fhQPxNfLDxHLzdbDG8hzciA5SQMjknIqIHeOjFg1obzpQTma6WdK3UXIjIzckKQ3t4oWcwFyKipteSrhUiMbXYmXIiIjJOzYWI9pxIxqq9l7Dj+HUMqVqISM6FiIiIyBCTciKiJlBzIaI9J25g/fdXsOtnLkRERES1MSknImpC9S1EtK/aQkT2XIiIiKjNY1JORNRMai5EtD/+Jg6dSUWfyoWIlFyIiIiozWJSTkTUzGouRPTjuTQc+z0N0Z0rFyJSciEiIqK2hkk5EZFIqi9EdCD+Jo79noaTFysWIhre0xt+XIiIiKjNELUlYllZGT7++GPs2LEDeXl5CAwMxEsvvYSePXve97ydO3diy5YtSEpKQm5uLlQqFbp3744XX3wR7u7uDxULWyISma62cq0UFGvw/ZkUHP41Vb8Q0fCePujs48iFiMgobeVaIXpUptgSUdSk/F//+hcOHjyIqVOnwtvbG9u2bcOFCxewdu1aRERE1HvekiVLoFarERgYCHt7e6SlpWHTpk0oLy/Hzp07oVQqGxwLk3Ii09XWrpWSMq1+IaKcgjIuRERGa2vXCtHDYlJezfnz5zFhwgQsWLAA06dPBwCUlpZixIgRUKlUiI2NbdB4Fy9exNixY/Hqq69i1qxZDY6HSTmR6Wqr14pGq8MvF25j38mbyMgpRjtnKwzt7o0ewa5ciIjq1FavFaKGMsWkXLR/1ffv3w+5XI4JEybotykUCowfPx6//vorMjIyGjRe+/btAQB5eXmNGicRkVjkMin6dnHHO3O6Y+6oYJhJpVi5NxHzvz6B78+koFRTLnaIRETUSES70TMxMRG+vr6wtrY22B4WFgZBEJCYmAiVSnXfMXJyclBeXo60tDR8/vnnAPDAenQiopbGTCpF986uiA5S4Y9rmdh9Ihnrvr+CXb/cwBNdPTEw0h1WXIiIiKhFEy0pV6vVcHV1rbW9qh7cmJnyIUOGICcnBwDg4OCAN998Ez169GjcQImITETFQkQuCPNzwZ8pOdhzIhnbfryGfSeT0T/SHf+/vTsPqLrM+///PAcO+74JshwUFXAJ0QpJrcwlXMpqLKfFultsymUqv800yz3fu7lnmvqVU5aVUzrfe8xpam63cN+1xTWXXEESBUVEEdlEZT2/P8CjBCoW+DnA6/Ef1/l8zucNesGbi+t6v4fdrEZEIiKtlWFJ+YULF7BYGq7suLrW/kApLy+/5nu8//77nDt3jiNHjrBo0SLKysp+dDxX2t/T0oKDvQ15rkhro7lSX3CwN/37RJKZU8S8dd+zYutR1mzPYcitUTxwZxdCAz2v/SbSJmmuiDSNo80Vw5JyNzc3KisrG4xfTMYvJudXc8sttwBwxx13MHjwYO655x48PDx47LHHrjseHfQUcVyaK1fm4+rEU8PjGJkUxfKt2azaks3Kzdkk1TUiClcjonZFc0WkaXTQ8zLBwcGNblHJz88HuOZ+8h+KjIykR48eLF68uFniExFpTToEePAfw+P5/55LZsjNEezIyOcPf9/G9Pl7yMwtNjo8ERG5BsNWyuPi4pgzZw5lZWX1Dnvu3r3b/vr1unDhAufPn2+2GEVEWpsAHzd+Prgro26Ltjci2vX9aTUiEhFxcIatlKekpFBZWcncuXPtYxUVFSxYsIA+ffrYD4Hm5uaSmZlZ794zZ840eL99+/aRnp5Ojx49WjZwEZFWwMvdwn0DO/Pm87fx0KAunDhzjr/++zv+NHs7Ow6eosa4vnEiItIIw1bKExISSElJYerUqeTn5xMVFcXChQvJzc3l9ddft1/3yiuvsG3bNg4ePGgfGzRoEMOHD6dbt254eHhw6NAh5s+fj6enJxMmTDDi0xERcUjurs6kJEUxuG8EG/edYMWWo3ywcB9hgR6M6GclqbsaEYmIOALDknKAN998k2nTppGamkpxcTGxsbF8/PHH9O3b96r3PfLII2zevJk1a9Zw4cIFgoODSUlJYcKECURGRt6g6EVEWg+Ls5k7e4cz8KYwtqfns3RzNn9fmsYXXx/m7lujGJjQEVeLk9Fhioi0WyabTX/DBFVfEXFkmivNz2azsSezgKVbsjmUU4y3h4WhN0dylxoRtWqaKyJN44jVVwxdKRcREWOYTCYSugSR0KW2EdGSzVks+Oowy7dmMygxgqG3ROLr6WJ0mCIi7YaSchGRdq5bpB9TInuTnVfKsi3ZLN+SzertxxhwUxjDb40iyM/d6BBFRNo8JeUiIgKANdSb5+/rSd6Zcyzfks1X3+Xy5a5ckrp3YES/KDUiEhFpQUrKRUSkntAAD54cEc/oAZ1Yue0YX+4+zub9eSR2DWJEspWYjr5Ghygi0uYoKRcRkUYF+Ljx8JCujLrNytodOazZXtuIKN7qz4hkK92takQkItJcVH2ljqqviDguzRXHcL68ii+/y2Xlt0cpPltBpzBvRvSLJrFbEGYl5w5Bc0WkaVR9RUREWq1LjYjC2bgvj+Vbsvlg4V41IhIRaQZaKa+jlXIRx6W54piqa2r4Nv0UyzZnk5NfRqCPKylJVgbeFIaLGhEZQnNFpGm0Ui4iIm2Gk9lMv+6hJMV3YHdmAcs2Z/Pp6gwWbTzCsFsiGZQYgYebfsyIiDSFvluKiMhPYjKZ6N0liISYQDKOFbF0SzbzvzzMsi1qRCQi0lRKykVEpFmYTCZio/yJjfInO6+UpZc1Ihp4UxgpakQkInJFSspFRKTZWUO9mXBfT04UlLF861G+/C6XDRcbESVbCQ/yNDpEERGHoqRcRERaTFigJ0+NiOe+RhoRjUyOpnNHH6NDFBFxCErKRUSkxV3eiGjN9hzW7shh1/fbibf6MzLZSrwaEYlIO6eSiHVUElHEcWmutD32RkTbjlJcVtuIaGRyNL27qhHRT6G5ItI0KokoIiLCDxoR7c1j2ZZs3l+wl45BngxPilIjIhFpd7RSXkcr5SKOS3Ol7auuqeHbtFMs23KxEZEbKUlRakR0nTRXRJpGK+UiIiKNcDKb6dcjlKTutY2Ilm7O4tPVGSzeeIShakQkIu2AvsOJiIjDaNCIaPOlRkR39Ylg6M2R+KgRkYi0QUrKRUTE4VzeiCgrr4Rlm7NZtjmbVd8e4/abOnJ3UiRBvmpEJCJth5JyERFxaNGhPky4v5e9EdGG746z4bvjJHXvwPB+akQkIm2DknIREWkVLm9EtGLbUb76LpdN+/Lo0y2YkclWOoWpEZGItF5KykVEpFUJ8HHjkSHdGHVbNGu257BuRw47M/KJt/ozKtlKnBoRiUgrpJKIdVQSUcRxaa7I1Zwvr2LDd8dZte1YXSMiH0YmW9tlIyLNFZGmUUlEERGRZubu6szwJCtD+kbwzd48ll/WiGhEvyhujVcjIhFxfFopr6OVchHHpbki1+NiI6KlW7I53s4aEWmuiDSNVspFRERa2MVGRLd278CeQwUs3aJGRCLi+PRdSURE2iSzyUTvrkEkdKltRLTE3ojoKHf1CVcjIhFxKErKRUSkTbtSI6LV3x5joBoRiYiDUFIuIiLtRr1GRFsuNSLqV9eIqKMaEYmIQZSUi4hIuxMW6MlTI+MZPaATK7cd5avdlxoRjVAjIhExgJJyERFptwJ93XhkaDdG9a9tRLR2Rw47MvLpHu3PyORo4qL81IhIRG4IlUSso5KIIo5Lc0VulPPlVWzYdZyV3x6jpKyCzh19GNnPSkIraUSkuSLSNCqJKCIi4sDcXZ0Z3s/KkJsj+GbPCZZvPcr0BXsJD/JkRD8rt3YPwcmsRkQi0vy0Ul5HK+UijktzRYxSXVPDtrRTLKtrRBTkW9uIaEAvx2xEpLki0jRaKRcREWlFnMxmknuEktS9A7sPnWbZ5mz+uSqDRRuzGHZLJIMSw3F31Y9SEfnp9J1ERETkGswmE4ldg+ndJYiDR4tYujmLeRsyWbo5W42IRKRZKCkXERFpIpPJRJzVnzirP0dOlLBsy2WNiBI6knJrFIG+bkaHKSKtkJJyERGRH6FTmA8T6xoRLduSzYZdx9mw6zj9enRgRD8rYYFqRCQiTaekXERE5CcIC/Tk6ZHduW9A50uNiPaqEZGIXB8l5SIiIs2gfiOiY6zdcZwdGfn0iPZnhBoRicg1qCRiHZVEFHFcmivSGp0vr2L9ruOsqmtEFNPRhxHJVhK6tFwjIs0VkaZRSUQREZF2wt3VmRH9rAzpG8HGvXWNiObXNSJKtnJrvBoRicglWimvo5VyEceluSJtQXVNDdsO1DUiOl3biGh4UhQDbgrD4tw8jYg0V0SaRivlIiIi7ZST2Uxyz1CSetQ2Ilq6OZs5qzJI3ZjF3bdEcqcaEYm0a5r9IiIiN9DljYjSjxaxbHMWcy82IuobzpCbI/HxUCMikfZGSbmIiIgBTCYT8VZ/4i82ItqczdJN2azadozbEzqSkhRFgI8aEYm0F4Ym5RUVFbz77rukpqZSUlJCXFwcL730EsnJyVe9b9WqVSxbtow9e/ZQUFBAWFgYgwYNYsKECXh7e9+g6EVERJpHpzAfJj7Qi9zTZSzfks36XcdZr0ZEIu2KoQc9p0yZwqpVq3j88cexWq0sXLiQffv2MWfOHBITE694X1JSEiEhIQwZMoSOHTty8OBBPv/8c6Kjo5k/fz6urq7XHYsOeoo4Ls0VaW9OF59n5bZjfL07l8qqGvrEBjMy2Up06NUbEWmuiDSNIx70NCwp37NnDw8++CC//e1v+Y//+A8AysvLGTVqFCEhIXz66adXvHfr1q0kJSXVG/viiy945ZVXeP3113nggQeuOx4l5SKOS3NF2quSsgpWbz/Gup3HOV9eRY9OAYzsZyX2Co2INFdEmsYRk3LDCqSuWLECi8XCgw8+aB9zdXVlzJgx7Nixg1OnTl3x3h8m5ABDhgwBIDMzs/mDFRERMYCPpws/uyOGt56/jTF3xnDsZClvfraLv8zZwa7v86lRVWORNsOwPeVpaWl06tQJT8/6++RuuukmbDYbaWlphISENPn9Tp8+DYC/v3+zxikiImI0D7dLjYi+2XuCFRcbEQV7MqKflRqbjS++OsyZknICfFx54I4YknuEGh22iFwHw5Ly/Px8OnTo0GA8ODgY4Kor5Y2ZOXMmTk5ODBs2rFniExERcTQuFifu6hPB7Qkd+TbtFEu3ZDNz8YF61xSUlDN7eTqAEnORVsSwpPzChQtYLJYG4xcPaZaXlzf5vRYvXsy8efP4xS9+QVRU1I+K50r7e1pacLCqxYg0heaKSH33hvoy6o4ujHt1BSVlFfVeq6iqYd6XmdxzR5dG956LiOP9XDEsKXdzc6OysrLB+MVkvKkVVLZv387vf/977rzzTl544YUfHY8Oeoo4Ls0VkSv7YUJ+UWFJOeP+a4W9Fnp8tD9Bvu43ODoRx+SIBz0NS8qDg4Mb3aKSn58P0KT95Onp6Tz//PPExsbyzjvv4OTk1OxxioiIOLJAH1cKShr+ddnTzZnYKD8OZJ1hy4GTAAT7uRFvDSDe6k+c1R9fT3UOFXEUhiXlcXFxzJkzh7KysnqHPXfv3m1//WqOHj3KM888Q0BAAB999BEeHh4tGm9lZQWlpUVUVVVQU1PdLO956pSZmpqaZnkvcQxOTs54efnh7q5GHyJyYzxwRwyzl6dTUXXp54mLs5lHhnYjuUcoNpuN46fLSMsqJC27kG/TT/LV7lwAwoM97SvpsZH+eLip0beIUQyrU757924eeuihenXKKyoqGDVqFIGBgXz22WcA5Obmcv78eWJiYuz35ufn8/DDD1NeXs5nn31GRETET47nattXzp8vo7S0EC8vX1xd3TGbnZplj56zs5mqKiXlbYXNZqOysoKiony8vf2VmDcjbV8RubrN+/NY8GVmk6qvVNfUkJ13lrTsM6RlF/J9TjGVVTWYTBAd6kP36NpV9K7hvrhY9BdoaZsccfuKoR09X3jhBdauXcsTTzxBVFSUvaPn7Nmz6du3LwDjxo1j27ZtHDx40H7f6NGjSU9P55lnnqFbt2713jMqKuqq3UCv5GpJeX5+Lr6+Abi4uF33+16NkvK2qaKinOLi0wQHhxsdSpuhpFykaX7MXKmsqibzeAkHsgtJzy7kcG4JNTYbzk4muoT71q2kBxAd5o2zk2HtTUSalSMm5Yb+nerNN99k2rRppKamUlxcTGxsLB9//LE9Ib+S9PTaUk+zZs1q8Nr999//o5Lyq6mursRiadrBUxGLxYXq6iqjwxARaRKLsxNxdXvMAc6XV/F9ThEHsmqT9IVfH2Hh10dwdXEiNtLPvt0lIsQLsyq7iDQbQ1fKHcnVVsrz8rIJDbU2+zO1Ut52tdT/mfZKK+UiTdMSc6X0XAUHjxZxILt2T/rJM+cA8HK3EBflR3x07cHRDv7uKr8orYZWykVERKRV8fZw4ea4EG6Oq62KdqbkAml1CXpadiHbD9ZWTfP3dr1UftHqT4BP8275FGnrlJRLi5o06VkA3n//4xt6r4iItIwAHzf69wqjf68wbDYbJwvP1yboWWfYk1nApn15AHQI8CDe6k93qz+xUX54e6j8osjVKClvpwYMuLlJ182du4iwsI4tHI2IiLRGJpOJ0AAPQgM8GJQYTo3NRs6ps/ZV9M3789iw6zgAUSFexFn96R7tT9cIP9xdlYKIXE57yuu0tz3lK1cuq/fx//7vZ5w8eYLJk6fUG7/99kG4u//4DnAXu7ZaLJYbeq/RtKe8eWlPuUjTONpcqaquIetEqb384qHjxVRV23Aym+gU5lObpFv9iQn3weKs8oty42hPuTiMu+8eUe/jDRvWUlxc1GD8hy5cuICbW9P3Cf6UhLo1JuMiInKJs5OZLhG+dInw5Z7+naiorOb748WkZxdyIKuQpZuzWLIpC4uzma4Rl8ovWkO9cDKr/KK0L0rK5YomTXqWs2fP8utf/47p09/h4MF0Hn30cZ5++hd8/fUGFi1aSEbGQUpKigkODmHEiHsYN+5JnJyc6r0HXNoXvnPndn75y+d47bU3OXLkMF98MZ+SkmJ69UrgV7/6HRERkc1yL8D8+f/L559/SkHBaWJiYpg06SVmzpxR7z1FROTGcbE40SM6gB7RAfzsDjh3oYqDxy4dGp3/5WHgMO6uzrXlF6NrD42GB3mqsou0eUrKDbJ5fx4LvjpMQfEFAq/Rfc1IRUWF/PrXLzFsWAopKSPp0KE2xmXLluDu7sHYsY/i4eHOjh3bmTXrb5SVlTFx4gvXfN/Zs/+O2ezEI488TmlpCZ99Noc//vE/mTlzdrPcu3DhPN5550169+7D2LEPc+LECX7725fx9vYmODjkx39BRESk2Xi4OZPYNZjErsEAFJdVkG6v7HKG7w6dBsDHw1K3Hz2AOKs/IX4/fluliKNSUm6AzfvzmL08nYq6/eQFJeXMXl7bEMnREvPTp/P5zW/+wKhRo+uNv/rqn3F1vbSN5b77xvDWW39h4cK5jB//PC4uVz9lX1VVxf/7f7Nxdq79L+jj48u7707l8OFDdO7c5SfdW1lZyaxZM+jRoxfTpn1ov65Ll6689tqrSspFRByUr6cLSd07kNS9AwCni+oquxwtJC2rkG1ppwAI8nWz70ePs/rj56UGf9L6KSn/CTbuPcE3e05c932ZubUHXS5XUVXD/yxL46vvcq/7/QbcVFuaqiW4ubmRkjKywfjlCfm5c2VUVFSSkJBIauoCsrOz6Nq121Xfd+TIe+3JMkBCQm8AcnOPXzMpv9a96ekHKC4uZsKE++tdN3RoCu+99/ZV31tERBxHkJ87A/3cGZjQEZvNxomCc/atLjsP5tt/BncM8iQ+yp/46Nryi55uOpMkrY+ScgP8MCG/1riRgoND6iW2Fx0+nMnMmTPYufNbysrK6r1WVnb2mu97cRvMRd7ePgCUll77JPS17s3Lq/0m/cM95s7OzoSFtcwvLyIi0rJMJhMdgzzpGOTJ4L4R1NTYOHqqlLSs2iT96725rN2Zg8kE1g7etYdGo/3pGu6Hq4squ4jjU1L+E1xsnnC9fvXhRgpKyhuMB/q48sqjfZojtGZz+Yr4RaWlpUye/CweHl48/fRzhIdH4OLiQkZGOjNmTKem5tplHs3mxr9BNqVC50+5V0RE2gaz2UR0qA/RoT4M72elqrqGw7klHMg6Q3p2Iau+PcbyrUdxMpuICfe1dxrt3NEHZydVdhHHo6TcAA/cEVNvTzmAi7OZB+6IMTCqptu1awfFxcW89tpb9O596ZeIEyeuf+tNSwgNrf1FKSfnGAkJifbxqqoqTpw4QUzM1bfHiIhI6+PsZKZbpB/dIv1gIJRXVPN9ThEH6ra7LPrmCKnfHMHV4kTXSN+6bqMBRIZ4YTarsosYT0m5AS4e5mwN1VcaY66rHXv5ynRlZSULF841KqR64uK64+vry6JFC7n77hH27TerV6+gtLTE4OhERORGcHVxomfnQHp2DgTg7PlKDh4tsjcymrs+E8jE082ZuCh/e7fR0AAPlV8UQygpN0hyj1AGJnQ0rKPnT9Gr1014e/vw2muvMmbMWEwmEytXLsNRdo9YLBaeeupZ3nnnLV58cQKDBg3mxIkTLF++mPDwCH2zFRFph7zcLfSNDaZvbG35xcLSctLrqrqkZZ9hR0Y+AH5eLsTXVXXpbg0g0LfpDfNEfgol5XLdfH39ePPNd3j//WnMnDkDb28fhg0bzs0338qUKZOMDg+An/1sLDabjc8//5QPPniXmJiuvPHG20ybNhUXF5XOEhFp7/y9XUnuEUpyj1BsNhv5F8svZhey78gZNu8/CUCIn7u9iVGc1R8fj6uX/BX5sUw2nY4DoKDgLDU1jX8p8vKyCQ21NvsznZ3NrXKlvLWqqalh1Kih3HHHIF555T9b9Fkt9X+mvQoO9iY//9qVeUTaO82V5mGz2TieX2ZP0g8eK+R8eTUAEcFe9kOjsVF+uLtqfbM1MmqumM0mAgO9Gn1N/5OkTSovL8fVtf6K+IoVSykpKSYxsa9BUYmISGtgMpmICPEiIsSLobdEUl1TQ1ZeKenZhRzIKmTDd8dZvf0YZpOJ6DBve5LeJdwXF4vKL8qPo6Rc2qQ9e75jxozp3HnnXfj4+JKRkc7SpYvo3DmGQYOGGB2eiIi0Ik5mMzEdfYnp6MvI5Ggqq6o5dLykbiX9DMu3HGXp5mycncx0jfC1dxuNDvPGyazyi9I0SsqlTerYMZygoGDmzfs3JSXF+Pj4kpIykueem4TFok5vIiLy41mcneyr49CZ8+VVZBwrsm93WfjVYRYCbi5OxEb61TUyCiA82BOzig3IFSgplzYpPDyCN998x+gwRESkHXB3dSahSxAJXYIAKD1XQfrRuiQ96wy7MwuA2gowF5P5+Gh/QvzcVRFM7JSUi4iIiDQjbw8XbokL4Za4EADOlFywr6KnZRfybfopAAJ8XC8l6dYA/L1VHaw9U1IuIiIi0oICfNzo3yuM/r3CsNlsnCw8T1pWbROj3YcK2Lg3D4DQAI/a8ot1zYy83LXdsj1RUi4iIiJyg5hMJkIDPAgN8GBQnwhqbDZyTp3lQFYh6UcL2bQ3j/U7j2MCIjt40d0aQJzVn26Rvri5KG1ry/SvKyIiImIQs8lEVAdvojp4k5IURVV1DVknSjmQfYb07ELW7DjGim1HcTKb6NTRh+512106d/TF4qzKLm2JknIRERERB+HsZKZLhC9dIny5t38nyiurOXS8mLSs2v3oizdlsWhjFi7OteUX46MDiLf6Y+3gjdmsQ6OtmZJyEREREQflanGiR3QAPaIDADh3oZKDx4pqk/SjhczbkAnUVoCJi/KzHxztGOSpyi6tjJJyERERkVbCw81CYtdgErsGA1BcVkF6XROjtOxCdn1/GgAfT5fLKrv4E+znbmTY0gRKykVERERaKV9PF5K6dyCpewcAThedr1d+ceuBkwAE+brZ66PHR/nj66Xyi45GJwSkWSxbtpgBA27mxIlc+9iYMffw2muv/qh7f6qdO7czYMDN7Ny5vdneU0RExNEF+bkzMKEjz97bg7cn9edPzyTx6NBuRIZ4seNgPh8vOsBL72/kD7O28unqDHZl5HPuQqXRYQtaKW+3fv3rl9i581sWL16Nu3vjf9KaMmUS+/fvZdGiVbi6OuZv1GvWrOTMmQIeeugRo0MRERFxKCaTifAgT8KDPBncN4KaGhvZJ0tJzy7kQHYhX+/OZe2OHEwmiA71Jt5ae2i0S4QvrhYno8Nvd5SUt1NDh97Npk1f8803XzJ0aEqD1wsLz7Bjx7cMGzb8Ryfk//rXfMzmlv1jzNq1q/j++4wGSXnv3n1Yu3YjFosaL4iIiACYzSY6hfnQKcyH4f2sVFbVcDi32L7VZeW2oyzbko2zk4mYjr727S6dwnxwdtLmipampLydGjjwTtzdPVizZmWjSfm6dWuorq5m2LCGrzWVi4vLTwnxJzGbzQ67ui8iIuIILM5mYqP8iY3y576BcKGiiu9z6pL0rEJSvznCF98cwdXiRLfIS5VdIjt4YVZll2anpLydcnNzY+DAO1i/fg0lJSX4+PjUe33NmpUEBgYSGWll6tQ32LFjGydPnsTNzY0+fW5m4sQXCAvreNVnjBlzD4mJffn971+1jx0+nMm0aW+xb99efH19GT36AYKCghvc+/XXG1i0aCEZGQcpKSkmODiEESPuYdy4J3Fyqv2T2qRJz/LddzsBGDDgZgBCQ8OYN28xO3du55e/fI733vsbffrcbH/ftWtX8c9//oPs7CwMx4x3AAAVuklEQVQ8PDzp338gzz//S/z8/OzXTJr0LGfPnuX//t//5u233yQtbT/e3j48+ODPefTRJ67vCy0iItJKuLk406tzIL06BwJw9nwlB49eOjT6v+sLAPB0cybO6k93qz9xVn9CAzxUfrEZKCk3yLa8nSw+vIIzF4rwd/Xj3pgUbg3tc0NjGDo0hVWrlrNhw1ruvfd++3he3gn27dvDmDE/Jy1tP/v27WHIkLsJDg7hxIlcvvhiPpMn/4J//nMubm5uTX5eQcFpfvnL56ipqeGxx57Azc2dRYsWNrqivWzZEtzdPRg79lE8PNzZsWM7s2b9jbKyMiZOfAGAJ554ivPnz3Py5AkmT54CgLu7xxWfv2zZYv7ylz/So0cvnn/+l5w6dZL58/9NWtp+Zs78pF4cJSXF/J//80sGDRrM4MHDWL9+DTNmTKdz5y4kJ/dv8ucsIiLSWnm5W+gbG0Lf2BAACkvL68ov1pZg3HEwHwB/b1fiovzpHl27kh7g0/TcQC5RUm6AbXk7+Vf6fCprak87F5YX8a/0+QA3NDG/5ZYk/Pz8WbNmZb2kfM2aldhsNoYOvZuYmC4MGjSk3n39+9/Oc889yYYNa0lJGdnk53366WyKi4uYNWsOsbFxAAwfPoqHH76/wbWvvvpnXF0vTer77hvDW2/9hYUL5zJ+/PO4uLhwyy39WLBgLsXFRdx994irPruqqooZM6bTpUs3pk//yL61JjY2jldf/T2LFy9kzJif268/deok//Vff7Zv7Rk1ajRjxoxi6dJUJeUiItIu+Xu7ktwzlOSeodhsNvKLznMgu5D07EL2HSlg8/48ADr4u9ftRw8gNsoPHw/jtrO2JkrKf4KtJ3aw+cS3133fkeKjVNmq6o1V1lTyado8NuVuu+73Sw67haSwvtd9n7OzM3fdNYQvvpjP6dOnCQoKAmDNmlVERETSvXvPetdXVVVRVnaWiIhIvLy8ychIv66kfPPmjfTqlWBPyAH8/f0ZOnQ4CxfOrXft5Qn5uXNlVFRUkpCQSGrqArKzs+jatdt1fa7p6QcoLDxjT+gvuuuuoXzwwbts2rSxXlLu5eXFkCF32z+2WCzEx/cgN/f4dT1XRESkLTKZTIT4exDi78GdvcOpsdk4nl9Wtx/9DFsOnGTDd7WljiNDvOz70btF+uHuqvSzMfqqGOCHCfm1xlvS0KEpLFgwl3XrVvHQQ4+QlXWEQ4cyePLJ8QCUl19gzpx/sGzZYvLzT2Gz2ez3nj179rqedfJkHr16JTQYj4qyNhg7fDiTmTNnsHPnt5SVldV7razs+p4LtVtyGnuW2WwmIiKSkydP1BsPCenQYH+ct7cPmZmHrvvZIiIibZ3ZZCIyxIvIEC+G3RJJdU0NWSdK7fvR1+08zqpvj2E2mejU0bsuSQ+gS7gPFmeVXwQl5T9JUljfH7VC/Z8b/0JheVGDcX9XP17s81xzhNZkvXolEBYWzurVK3jooUdYvXoFgH3bxjvvvMWyZYt58MGH6dmzF15eXoCJV1/9Xb0EvTmVlpYyefKzeHh48fTTzxEeHoGLiwsZGenMmDGdmpqaFnnu5czmxr9BtNTnLCIi0pY4mc3EhPsSE+7LqNuiqayq5lBOMWlHayu7LNt8lCWbsrE4m+kSfqn8YnSoN04tXE7ZUSkpN8C9MSn19pQDWMwW7o358eUHf4ohQ4YxZ87/kJNzjLVrVxEbG29fUb64b3zy5Jfs15eXl1/3KjlAhw6h5OQcazB+9Gh2vY937dpBcXExr732Fr17X9pj33jHz6ad9g4NDbM/6/L3tNls5OQco1OnmCa9j4iIiFw/i7MT8dEBxEcHwO1wvryKg8eK7AdHF3x1GL4Cd1cnYiP97dVdOgZ7tpvyi0rKDXDxMKfR1VcuGjZsOHPm/A/vv/8OOTnH6iXgja0Yz5//b6qrq6/7OcnJ/Zk793MOHky37ysvLCxk9erl9a672HDo8lXpysrKBvvOAdzd3Zv0C0JcXHf8/QP44ot5DB8+yt5UaP36teTnn+LRRx+/7s9HREREfhx3V2d6dwmid5fa82wl5ypIrzs0eiC7kO8OnQbA28NCvPVSkh7s595myy8qKTfIraF9uC3iZqqqWn4rxrV06tSZLl268c03X2E2mxk8+NIBx9tuG8DKlcvw9PQiOroT+/fvZfv2bfj6+l73cx555AlWrlzGlCkTGTPm57i6urFo0UI6dAjj7Nnv7df16nUT3t4+vPbaq4wZMxaTycTKlctobOdIbGwcq1YtZ/r0t4mL6467uwcDBtze4DpnZ2eef34yf/nLH5k8+RcMGTKMU6dOMm/ev+ncOYZ77mlYAUZERERuDB8PF26N78Ct8R0AKCi+YN+PnpZ9hm1ppwAI9HEl3hpAfLQ/cVH++Hu3nUaBSsoFgGHDUjh0KIPExL72KiwAL7zwMmazmdWrl1NeXkGvXglMm/YBU6ZMvu5nBAUF8d57H/HOO28yZ84/6jUPeuONP9mv8/X148033+H996cxc+YMvL19GDZsODfffCtTpkyq956jR/+MjIx0li1bwr///S9CQ8MaTcoBRoy4BxcXFz79dDYffPAunp6eDB2awnPPTVb3TxEREQcS6OvGgJvCGHBTGDabjbwz5+xJ+q7v8/lmb22BhrBAD/uh0dgoP7zcLQZH/uOZbDq5BkBBwVlqahr/UuTlZRMa2rBCyE/l7Gx2iJVyaX4t9X+mvQoO9iY/v9ToMEQcnuaKtAc1NhvHTp61J+kZx4oor6zGBER18CY+unarS9cIP1xd6m/D3bw/jwVfZnKmpJwAH1ceuCOG5B6hNyx2s9lEYKBXo69ppVxEREREWg2zyYQ11BtrqDcpSVFUVddw5EQJaVm1Sfqa7cdYsfUoTmYTMR19avejRweQX3SeOSsPUlG3IFpQUs7s5ekANzQxvxIl5SIiIiLSajk7meka4UfXCD/uHdCJ8sra8osHss+Qnl3I4k1ZLNqY1ei9FVU1LPgyU0m5iIiIiEhzcrU40aNTAD06BQBw7kIlB48WMX3B3kavLygpv5HhXVH7rM4uIiIiIu2Ch5uFxG7BBPo0XtThSuM3mpJyEREREWnzHrgjBhfn+qmvi7OZB+5wjAaChm5fqaio4N133yU1NZWSkhLi4uJ46aWXSE5Ovup9e/bsYcGCBezZs4eMjAwqKys5ePDgDYpaRERERFqbi/vGjay+cjWGJuW/+c1vWLVqFY8//jhWq5WFCxcyfvx45syZQ2Ji4hXv+/LLL5k7dy6xsbFERkZy+PDhFo/VZrO12Q5S0rxUZVRERMQxJfcIJblHqEOWDzVs+8qePXtYunQpL7/8Mr/+9a8ZO3Yss2fPJiwsjKlTp1713ocffpgdO3awYMECBgwY0OKxOjlZqKx0jEMA4vgqKytwctIZahEREWk6w5LyFStWYLFYePDBB+1jrq6ujBkzhh07dnDq1Kkr3hsUFISbm9uNCBMALy9fiopOU1ZWSnV1lVZCpVE2m42KinKKivLx8vIzOhwRERFpRQxbzktLS6NTp054enrWG7/pppuw2WykpaUREhJiUHT1ubt74uxs4ezZIsrKiqmpqW6W9zWbzdTUqKNnW+Lk5Iy3tz/u7p7XvlhERESkjmFJeX5+Ph06dGgwHhwcDHDVlXIjWCwu+Ps37y8JjrifSURERERuPMOS8gsXLmCxWBqMu7rW1oosL7+xe7gDA71u6PMuCg72NuS5Iq2N5opI02iuiDSNo80Vw5JyNzc3KisrG4xfTMYvJuc3SkHBWWpqbuxeca2UizSN5opI02iuiDSNUXPFbDZdcSHYsIOewcHBjW5Ryc/PB3CY/eQiIiIiIi3NsKQ8Li6OI0eOUFZWVm989+7d9tdFRERERNoDw5LylJQUKisrmTt3rn2soqKCBQsW0KdPH/sh0NzcXDIzM40KU0RERESkxRm2pzwhIYGUlBSmTp1Kfn4+UVFRLFy4kNzcXF5//XX7da+88grbtm3j4MGD9rHjx4+TmpoKwN69ewH48MMPgdoV9rvuuuu64zGbjenWadRzRVobzRWRptFcEWkaI+bK1Z5pshnYCae8vJxp06axePFiiouLiY2NZcqUKdx22232a8aNG9cgKd+6dSuPP/54o+95//3388Ybb7R47CIiIiIizcXQpFxERERERAzcUy4iIiIiIrWUlIuIiIiIGExJuYiIiIiIwZSUi4iIiIgYTEm5iIiIiIjBlJSLiIiIiBhMSbmIiIiIiMGUlIuIiIiIGExJuYiIiIiIwZyNDqC9OXXqFJ988gm7d+9m3759nDt3jk8++YSkpCSjQxNxGHv27GHhwoVs3bqV3Nxc/Pz8SExM5MUXX8RqtRodnojD2Lt3L3/72984cOAABQUFeHt7ExcXx8SJE+nTp4/R4Yk4tJkzZzJ16lTi4uJITU01Ohwl5TfakSNHmDlzJlarldjYWHbt2mV0SCIOZ9asWezcuZOUlBRiY2PJz8/n008/5b777mPevHnExMQYHaKIQzh27BjV1dU8+OCDBAcHU1payuLFi3nssceYOXMm/fv3NzpEEYeUn5/PjBkz8PDwMDoUO5PNZrMZHUR7cvbsWSorK/H392fNmjVMnDhRK+UiP7Bz50569uyJi4uLfSwrK4t77rmHkSNH8sYbbxgYnYhjO3/+PEOGDKFnz5589NFHRocj4pB+85vfkJubi81mo6SkxCFWyrWn/Abz8vLC39/f6DBEHFqfPn3qJeQA0dHRdO3alczMTIOiEmkd3N3dCQgIoKSkxOhQRBzSnj17WLRoEb/97W+NDqUeJeUi0irYbDZOnz6tX2pFGnH27FnOnDnD4cOHefvtt8nIyCA5OdnosEQcjs1m409/+hP33Xcf8fHxRodTj/aUi0irsGjRIk6ePMlLL71kdCgiDud3v/sdK1euBMBisfDzn/+c5557zuCoRBzPF198waFDh/jggw+MDqUBJeUi4vAyMzP57//+b/r27cvo0aONDkfE4UycOJGxY8eSl5dHamoqFRUVVFZWNtgGJtKenT17lr/+9a88++yzhISEGB1OA9q+IiIOLT8/n1/84hf4+vry7rvvYjbr25bID8XGxtK/f39+9rOf8fe//539+/c73H5ZEaPNmDEDi8XCk08+aXQojdJPNxFxWKWlpYwfP57S0lJmzZpFcHCw0SGJODyLxcLgwYNZtWoVFy5cMDocEYdw6tQpZs+ezSOPPMLp06fJyckhJyeH8vJyKisrycnJobi42NAYtX1FRBxSeXk5zz33HFlZWfzjH/+gc+fORock0mpcuHABm81GWVkZbm5uRocjYriCggIqKyuZOnUqU6dObfD64MGDGT9+PC+//LIB0dVSUi4iDqe6upoXX3yR7777jg8//JDevXsbHZKIQzpz5gwBAQH1xs6ePcvKlSsJCwsjMDDQoMhEHEtERESjhzunTZvGuXPn+N3vfkd0dPSND+wySsoN8OGHHwLY6y2npqayY8cOfHx8eOyxx4wMTcQhvPHGG6xbt45BgwZRVFRUr6mDp6cnQ4YMMTA6Ecfx4osv4urqSmJiIsHBwZw4cYIFCxaQl5fH22+/bXR4Ig7D29u70Z8ds2fPxsnJySF+rqijpwFiY2MbHQ8PD2fdunU3OBoRxzNu3Di2bdvW6GuaJyKXzJs3j9TUVA4dOkRJSQne3t707t2bp556iltvvdXo8EQc3rhx4xymo6eSchERERERg6n6ioiIiIiIwZSUi4iIiIgYTEm5iIiIiIjBlJSLiIiIiBhMSbmIiIiIiMGUlIuIiIiIGExJuYiIiIiIwZSUi4iIYcaNG8ddd91ldBgiIoZzNjoAERFpXlu3buXxxx+/4utOTk4cOHDgBkYkIiLXoqRcRKSNGjVqFLfffnuDcbNZfyQVEXE0SspFRNqo7t27M3r0aKPDEBGRJtByiYhIO5WTk0NsbCzTp09nyZIl3HPPPfTq1Ys777yT6dOnU1VV1eCe9PR0Jk6cSFJSEr169WLEiBHMnDmT6urqBtfm5+fz5z//mcGDB9OzZ0+Sk5N58skn2bhxY4NrT548yZQpU7jllltISEjg6aef5siRIy3yeYuIOCKtlIuItFHnz5/nzJkzDcZdXFzw8vKyf7xu3TqOHTvGo48+SlBQEOvWreP9998nNzeX119/3X7d3r17GTduHM7OzvZr169fz9SpU0lPT+evf/2r/dqcnBwefvhhCgoKGD16ND179uT8+fPs3r2bTZs20b9/f/u1586d47HHHiMhIYGXXnqJnJwcPvnkEyZMmMCSJUtwcnJqoa+QiIjjUFIuItJGTZ8+nenTpzcYv/POO/noo4/sH6enpzNv3jx69OgBwGOPPcakSZNYsGABY8eOpXfv3gC89tprVFRU8PnnnxMXF2e/9sUXX2TJkiWMGTOG5ORkAP74xz9y6tQpZs2axcCBA+s9v6ampt7HhYWFPP3004wfP94+FhAQwFtvvcWmTZsa3C8i0hYpKRcRaaPGjh1LSkpKg/GAgIB6H9922232hBzAZDLxzDPPsGbNGlavXk3v3r0pKChg165dDB061J6QX7z2+eefZ8WKFaxevZrk5GSKior4+uuvGThwYKMJ9Q8PmprN5gbVYvr16wdAdna2knIRaReUlIuItFFWq5XbbrvtmtfFxMQ0GOvSpQsAx44dA2q3o1w+frnOnTtjNpvt1x49ehSbzUb37t2bFGdISAiurq71xvz8/AAoKipq0nuIiLR2OugpIiKGutqecZvNdgMjERExjpJyEZF2LjMzs8HYoUOHAIiMjAQgIiKi3vjlDh8+TE1Njf3aqKgoTCYTaWlpLRWyiEibo6RcRKSd27RpE/v377d/bLPZmDVrFgBDhgwBIDAwkMTERNavX09GRka9az/++GMAhg4dCtRuPbn99tv56quv2LRpU4PnafVbRKQh7SkXEWmjDhw4QGpqaqOvXUy2AeLi4njiiSd49NFHCQ4OZu3atWzatInRo0eTmJhov+73v/8948aN49FHH+WRRx4hODiY9evX88033zBq1Ch75RWAP/zhDxw4cIDx48dz33330aNHD8rLy9m9ezfh4eH86le/arlPXESkFVJSLiLSRi1ZsoQlS5Y0+tqqVavse7nvuusuOnXqxEcffcSRI0cIDAxkwoQJTJgwod49vXr14vPPP+e9997js88+49y5c0RGRvLyyy/z1FNP1bs2MjKS+fPn88EHH/DVV1+RmpqKj48PcXFxjB07tmU+YRGRVsxk098RRUTapZycHAYPHsykSZOYPHmy0eGIiLRr2lMuIiIiImIwJeUiIiIiIgZTUi4iIiIiYjDtKRcRERERMZhWykVEREREDKakXERERETEYErKRUREREQMpqRcRERERMRgSspFRERERAympFxERERExGD/P5SSKDTqhytYAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}